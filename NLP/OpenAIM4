import pandas as pd
from transformers import MarianMTModel, MarianTokenizer
from langdetect import detect
from openai import OpenAI
import os

# ‚úÖ Initialize OpenAI client with environment variable
client = OpenAI(api_key=os.getenv(REMOVED_SECRETOPENAI_API_KEYREMOVED_SECRET))

# ‚úÖ Semantic expansion using OpenAI v1+ SDK
def expand_query_with_chatgpt(query):
    response = client.chat.completions.create(
        model=REMOVED_SECRETgpt-3.5-turboREMOVED_SECRET,
        messages=[{
            REMOVED_SECRETroleREMOVED_SECRET: REMOVED_SECRETuserREMOVED_SECRET,
            REMOVED_SECRETcontentREMOVED_SECRET: fREMOVED_SECRETGenerate a list of 5 semantically similar search queries or related product types for: '{query}'REMOVED_SECRET
        }],
        temperature=0.7
    )
    suggestions = response.choices[0].message.content.split(REMOVED_SECRET\nREMOVED_SECRET)
    return [s.strip(REMOVED_SECRET- REMOVED_SECRET).strip() for s in suggestions if s.strip()]

# ‚úÖ Load datasets
amazon_df = pd.read_csv(REMOVED_SECRETC:\\Users\\65988\\Desktop\\Folders\\EE6405C22\\NLP\\dataset\\Amazon_en_to_es.csvREMOVED_SECRET)
shopee_df = pd.read_csv(REMOVED_SECRETC:\\Users\\65988\\Desktop\\Folders\\EE6405C22\\NLP\\dataset\\Shopee_CN_to_EN.csvREMOVED_SECRET)
italian_df = pd.read_csv(REMOVED_SECRETC:\\Users\\65988\\Desktop\\Folders\\EE6405C22\\NLP\\dataset\\target_en_to_it.csvREMOVED_SECRET)

# ‚úÖ Define MarianMT translation models
models = {
    REMOVED_SECRETen‚ÜízhREMOVED_SECRET: REMOVED_SECRETHelsinki-NLP/opus-mt-en-zhREMOVED_SECRET,
    REMOVED_SECRETzh‚ÜíenREMOVED_SECRET: REMOVED_SECRETHelsinki-NLP/opus-mt-zh-enREMOVED_SECRET,
    REMOVED_SECRETen‚ÜíitREMOVED_SECRET: REMOVED_SECRETHelsinki-NLP/opus-mt-en-itREMOVED_SECRET,
    REMOVED_SECRETit‚ÜíenREMOVED_SECRET: REMOVED_SECRETHelsinki-NLP/opus-mt-mul-enREMOVED_SECRET,
    REMOVED_SECRETen‚ÜífrREMOVED_SECRET: REMOVED_SECRETHelsinki-NLP/opus-mt-en-frREMOVED_SECRET,
    REMOVED_SECRETes‚ÜíenREMOVED_SECRET: REMOVED_SECRETHelsinki-NLP/opus-mt-es-enREMOVED_SECRET,
    REMOVED_SECRETen‚ÜíesREMOVED_SECRET: REMOVED_SECRETHelsinki-NLP/opus-mt-en-esREMOVED_SECRET
}

# ‚úÖ Load translation pipelines
translation_pipelines = {}
for key, model_name in models.items():
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    model = MarianMTModel.from_pretrained(model_name)
    translation_pipelines[key] = (tokenizer, model)

# ‚úÖ Translation function
def translate(text, direction):
    tokenizer, model = translation_pipelines[direction]
    inputs = tokenizer(text, return_tensors=REMOVED_SECRETptREMOVED_SECRET, padding=True)
    outputs = model.generate(**inputs)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ‚úÖ User input
user_input = input(REMOVED_SECRETEnter your product search query: REMOVED_SECRET)
detected_lang = detect(user_input)
print(fREMOVED_SECRETüîç Detected language: {detected_lang}REMOVED_SECRET)

# ‚úÖ Language handling
supported_langs = [REMOVED_SECRETzhREMOVED_SECRET, REMOVED_SECRETitREMOVED_SECRET, REMOVED_SECRETesREMOVED_SECRET, REMOVED_SECRETfrREMOVED_SECRET]
if detected_lang not in supported_langs:
    print(fREMOVED_SECRET‚ö†Ô∏è Detected unsupported language '{detected_lang}', defaulting to English.REMOVED_SECRET)
    detected_lang = REMOVED_SECRETenREMOVED_SECRET

# ‚úÖ Translate query to English if needed
if detected_lang == REMOVED_SECRETzhREMOVED_SECRET:
    search_query_en = translate(user_input, REMOVED_SECRETzh‚ÜíenREMOVED_SECRET)
elif detected_lang == REMOVED_SECRETitREMOVED_SECRET:
    search_query_en = translate(user_input, REMOVED_SECRETit‚ÜíenREMOVED_SECRET)
elif detected_lang == REMOVED_SECRETesREMOVED_SECRET:
    search_query_en = translate(user_input, REMOVED_SECRETes‚ÜíenREMOVED_SECRET)
else:
    search_query_en = user_input

print(fREMOVED_SECRETüîé Searching for: {search_query_en}REMOVED_SECRET)

# ‚úÖ Semantic query expansion
expanded_queries = [search_query_en] + expand_query_with_chatgpt(search_query_en)
print(fREMOVED_SECRETüß† Semantic Variants: {expanded_queries}REMOVED_SECRET)

# ‚úÖ Search across datasets
def semantic_search(df, column):
    return pd.concat([
        df[df[column].str.contains(q, case=False, na=False)]
        for q in expanded_queries
    ]).drop_duplicates()

results = []
results.append(semantic_search(amazon_df, REMOVED_SECRETtitleREMOVED_SECRET))
results.append(semantic_search(shopee_df, REMOVED_SECRETtranslation_outputREMOVED_SECRET))
results.append(semantic_search(italian_df, REMOVED_SECRETtitleREMOVED_SECRET))

combined = pd.concat(results)
print(REMOVED_SECRET‚úÖ Search Results:REMOVED_SECRET)
print(combined.head())

# ‚úÖ Translate results back to user's language (if not English)
if detected_lang != REMOVED_SECRETenREMOVED_SECRET:
    def get_display_title(row):
        return row[REMOVED_SECRETtitleREMOVED_SECRET] if REMOVED_SECRETtitleREMOVED_SECRET in row and pd.notna(row[REMOVED_SECRETtitleREMOVED_SECRET]) else row.get(REMOVED_SECRETtranslation_outputREMOVED_SECRET, REMOVED_SECRETREMOVED_SECRET)
    
    display_titles = [get_display_title(row) for _, row in combined.head().iterrows()]
    translated_titles = [translate(title, fREMOVED_SECRETen‚Üí{detected_lang}REMOVED_SECRET) for title in display_titles]
    
    print(REMOVED_SECRET\nüåç Translated Results:REMOVED_SECRET)
    for original, translated in zip(display_titles, translated_titles):
        print(fREMOVED_SECRET- {original} ‚Üí {translated}REMOVED_SECRET)
else:
    print(REMOVED_SECRET\nüåç All results already in English.REMOVED_SECRET)
