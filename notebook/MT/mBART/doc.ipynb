{
 REMOVED_SECRETcellsREMOVED_SECRET: [
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET6d9ae35dREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET# Overview of MT PipelineREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETac4ff736REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### Step 1: Query Expansion CODE LOCATED IN queryexpansion.py\nREMOVED_SECRET,
    REMOVED_SECRETWe first use DeepSeek v3 to carry out query expansion on our queries. This is implemented as a function in queryexpansion.py, but will be demonstrated here:REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 57,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETab33f134REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom openai import OpenAI\nREMOVED_SECRET,
    REMOVED_SECRETfrom dotenv import load_dotenv\nREMOVED_SECRET,
    REMOVED_SECRETimport os\nREMOVED_SECRET,
    REMOVED_SECRETimport json\nREMOVED_SECRET,
    REMOVED_SECRETimport re\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#load API key\nREMOVED_SECRET,
    REMOVED_SECRETload_dotenv(dotenv_path='../.env')\nREMOVED_SECRET,
    REMOVED_SECRETapi_key = os.getenv('deepseek_API_KEY')\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#set up connection\nREMOVED_SECRET,
    REMOVED_SECRETclient = OpenAI(api_key=api_key, base_url=\REMOVED_SECREThttps://openrouter.ai/api/v1\REMOVED_SECRET)\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET235c12d4REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETWe define a function to expand our query:REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 58,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET1fe9f19eREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETdef get_expanded_queries(user_query):\nREMOVED_SECRET,
    REMOVED_SECRET    prompt=f'''You are an expert search query optimizer. Your task is to expand the following e-commerce search query to improve retrieval of relevant products. Generate a list of semantically related terms, synonyms, and common user variations while preserving the original intent.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Rules:**\nREMOVED_SECRET,
    REMOVED_SECRET1. Prioritize **contextual relevance** (e.g., \REMOVED_SECRETrunning shoes\REMOVED_SECRET → \REMOVED_SECRETjogging sneakers\REMOVED_SECRET).\nREMOVED_SECRET,
    REMOVED_SECRET2. Include **common misspellings** (e.g., \REMOVED_SECRETearbuds\REMOVED_SECRET → \REMOVED_SECRETairbuds\REMOVED_SECRET).\nREMOVED_SECRET,
    REMOVED_SECRET3. Add **technical/layman variants** (e.g., \REMOVED_SECRET4K TV\REMOVED_SECRET → \REMOVED_SECRETultra HD television\REMOVED_SECRET).\nREMOVED_SECRET,
    REMOVED_SECRET4. For non-English queries, provide **translations/transliterations** if applicable (e.g., \REMOVED_SECRETスマホ\REMOVED_SECRET → \REMOVED_SECRETsmartphone\REMOVED_SECRET).\nREMOVED_SECRET,
    REMOVED_SECRET5. Output in JSON format for easy parsing.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Input Query:** \REMOVED_SECRET{user_query}\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Output Format:**  \nREMOVED_SECRET,
    REMOVED_SECRET{{\nREMOVED_SECRET,
    REMOVED_SECRET  \REMOVED_SECREToriginal_query\REMOVED_SECRET: \REMOVED_SECRET...\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET  \REMOVED_SECRETexpanded_terms\REMOVED_SECRET: [\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRET...\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRET...\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETmisspelling\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRET...\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETtechnical\REMOVED_SECRET}}\nREMOVED_SECRET,
    REMOVED_SECRET  ]\nREMOVED_SECRET,
    REMOVED_SECRET}}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Example Output for \REMOVED_SECRETwireless headphones\REMOVED_SECRET:**\nREMOVED_SECRET,
    REMOVED_SECRET{{\nREMOVED_SECRET,
    REMOVED_SECRET  \REMOVED_SECREToriginal_query\REMOVED_SECRET: \REMOVED_SECRETwireless headphones\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET  \REMOVED_SECRETexpanded_terms\REMOVED_SECRET: [\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETBluetooth headphones\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETcordless earphones\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETwireless headsets\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETairbuds\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETmisspelling\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETnoise-cancelling headphones\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETtechnical\REMOVED_SECRET}}\nREMOVED_SECRET,
    REMOVED_SECRET  ]\nREMOVED_SECRET,
    REMOVED_SECRET}}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Now process this query:** \REMOVED_SECRET{user_query}\REMOVED_SECRET'''\nREMOVED_SECRET,
    REMOVED_SECRET    response = client.chat.completions.create(\nREMOVED_SECRET,
    REMOVED_SECRET        model=\REMOVED_SECRETdeepseek/deepseek-chat-v3-0324:free\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET        messages=[\nREMOVED_SECRET,
    REMOVED_SECRET            {\REMOVED_SECRETrole\REMOVED_SECRET: \REMOVED_SECRETuser\REMOVED_SECRET, \REMOVED_SECRETcontent\REMOVED_SECRET: prompt},\nREMOVED_SECRET,
    REMOVED_SECRET        ],\nREMOVED_SECRET,
    REMOVED_SECRET        temperature=0.3,\nREMOVED_SECRET,
    REMOVED_SECRET    )\nREMOVED_SECRET,
    REMOVED_SECRET    print(response) #debug\nREMOVED_SECRET,
    REMOVED_SECRET    expanded_queries_raw=response.choices[0].message.content\nREMOVED_SECRET,
    REMOVED_SECRET    if not expanded_queries_raw or expanded_queries_raw.strip() == \REMOVED_SECRET\REMOVED_SECRET:\nREMOVED_SECRET,
    REMOVED_SECRET      raise ValueError(\REMOVED_SECRETAPI returned an empty response\REMOVED_SECRET)\nREMOVED_SECRET,
    REMOVED_SECRET    expanded_queries_raw = re.search(r'```json\\n({.*?})\\n```', expanded_queries_raw, re.DOTALL)\nREMOVED_SECRET,
    REMOVED_SECRET    if expanded_queries_raw:\nREMOVED_SECRET,
    REMOVED_SECRET      expanded_queries_raw = expanded_queries_raw.group(1)\nREMOVED_SECRET,
    REMOVED_SECRET    else:\nREMOVED_SECRET,
    REMOVED_SECRET      expanded_queries_raw = expanded_queries_raw.strip()  # fallback to raw response\nREMOVED_SECRET,
    REMOVED_SECRET      \nREMOVED_SECRET,
    REMOVED_SECRET    #print(expanded_queries_raw)\nREMOVED_SECRET,
    REMOVED_SECRET    expanded_queries=json.loads(expanded_queries_raw)\nREMOVED_SECRET,
    REMOVED_SECRET    return expanded_queriesREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET2840849eREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETThis query should return us an expanded version of the user's original query, accounting for misspellings, vague queries, etcREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 59,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETeafbc2baREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRETChatCompletion(id='gen-1745148844-DAke1KpC3PwiP7GkudfC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \REMOVED_SECREToriginal_query\REMOVED_SECRET: \REMOVED_SECRETrunning shoos\REMOVED_SECRET,\\n  \REMOVED_SECRETexpanded_terms\REMOVED_SECRET: [\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETrunning shoes\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETmisspelling\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETjogging shoes\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETsneakers\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETathletic shoes\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETtrainers\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETrunning sneakers\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETrunning footwear\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETtrail running shoes\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETtechnical\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETroad running shoes\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETtechnical\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETperformance running shoes\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETtechnical\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETrunning shooes\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETmisspelling\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETruning shoes\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETmisspelling\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETrunnin shoes\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETmisspelling\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETスポーツシューズ\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETtranslation\REMOVED_SECRET},\\n    {\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETcorrer zapatos\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETtranslation\REMOVED_SECRET}\\n  ]\\n}\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='stop')], created=1745148844, model='deepseek/deepseek-chat-v3-0324', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=273, prompt_tokens=373, total_tokens=646, completion_tokens_details=None, prompt_tokens_details=None), provider='Targon')\nREMOVED_SECRET
     ]
    },
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET{'original_query': 'running shoos',\nREMOVED_SECRET,
       REMOVED_SECRET 'expanded_terms': [{'term': 'running shoes', 'type': 'misspelling'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'jogging shoes', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'sneakers', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'athletic shoes', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'trainers', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'running sneakers', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'running footwear', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'trail running shoes', 'type': 'technical'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'road running shoes', 'type': 'technical'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'performance running shoes', 'type': 'technical'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'running shooes', 'type': 'misspelling'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'runing shoes', 'type': 'misspelling'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'runnin shoes', 'type': 'misspelling'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'スポーツシューズ', 'type': 'translation'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'correr zapatos', 'type': 'translation'}]}REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 59,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETquery=\REMOVED_SECRETrunning shoos\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#demo with misspelling\nREMOVED_SECRET,
    REMOVED_SECRETexpanded_queries=get_expanded_queries(query)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETexpanded_queriesREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET534d7700REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETWe then rank these expanded queries based on their types, giving the most importance to the original queryREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 60,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET64dd2c27REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#weight the different output types\nREMOVED_SECRET,
    REMOVED_SECRETdef assign_weights(term_type):\nREMOVED_SECRET,
    REMOVED_SECRET    weights = {\nREMOVED_SECRET,
    REMOVED_SECRET        \REMOVED_SECRETsynonym\REMOVED_SECRET: 0.8,\nREMOVED_SECRET,
    REMOVED_SECRET        \REMOVED_SECRETmisspelling\REMOVED_SECRET: 0.3,\nREMOVED_SECRET,
    REMOVED_SECRET        \REMOVED_SECRETtechnical\REMOVED_SECRET: 0.7,\nREMOVED_SECRET,
    REMOVED_SECRET        \REMOVED_SECRETtranslation\REMOVED_SECRET: 0.6\nREMOVED_SECRET,
    REMOVED_SECRET    }\nREMOVED_SECRET,
    REMOVED_SECRET    return weights.get(term_type, 0.5)  #default weight\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef return_weighted_dict(expanded_queries, include_translations): #option to remove translations for certain pipelines\nREMOVED_SECRET,
    REMOVED_SECRET    weighted_terms = [\nREMOVED_SECRET,
    REMOVED_SECRET    {\REMOVED_SECRETterm\REMOVED_SECRET: expanded_queries[\REMOVED_SECREToriginal_query\REMOVED_SECRET], \REMOVED_SECRETweight\REMOVED_SECRET: 1.0}  # Original query (highest priority)\nREMOVED_SECRET,
    REMOVED_SECRET    ]\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    if include_translations:\nREMOVED_SECRET,
    REMOVED_SECRET      for item in expanded_queries[\REMOVED_SECRETexpanded_terms\REMOVED_SECRET]:\nREMOVED_SECRET,
    REMOVED_SECRET          weighted_terms.append({\nREMOVED_SECRET,
    REMOVED_SECRET              \REMOVED_SECRETterm\REMOVED_SECRET: item[\REMOVED_SECRETterm\REMOVED_SECRET],\nREMOVED_SECRET,
    REMOVED_SECRET              \REMOVED_SECRETweight\REMOVED_SECRET: assign_weights(item[\REMOVED_SECRETtype\REMOVED_SECRET])\nREMOVED_SECRET,
    REMOVED_SECRET          })\nREMOVED_SECRET,
    REMOVED_SECRET    else:\nREMOVED_SECRET,
    REMOVED_SECRET       for item in expanded_queries[\REMOVED_SECRETexpanded_terms\REMOVED_SECRET]:\nREMOVED_SECRET,
    REMOVED_SECRET          if item[\REMOVED_SECRETtype\REMOVED_SECRET]!=\REMOVED_SECRETtranslation\REMOVED_SECRET:\nREMOVED_SECRET,
    REMOVED_SECRET            weighted_terms.append({\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETterm\REMOVED_SECRET: item[\REMOVED_SECRETterm\REMOVED_SECRET],\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETweight\REMOVED_SECRET: assign_weights(item[\REMOVED_SECRETtype\REMOVED_SECRET])\nREMOVED_SECRET,
    REMOVED_SECRET            })\nREMOVED_SECRET,
    REMOVED_SECRET    return weighted_termsREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 61,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETeae29f1bREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET[{'term': 'running shoos', 'weight': 1.0},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'running shoes', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'jogging shoes', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'sneakers', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'athletic shoes', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'trainers', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'running sneakers', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'running footwear', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'trail running shoes', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'road running shoes', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'performance running shoes', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'running shooes', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'runing shoes', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'runnin shoes', 'weight': 0.3}]REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 61,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#demo with the above expansions\nREMOVED_SECRET,
    REMOVED_SECRETweighted_queries=return_weighted_dict(expanded_queries, include_translations=False)\nREMOVED_SECRET,
    REMOVED_SECRETweighted_queriesREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETff99aecaREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### Step 2: Fine-tuning of mBART model\nREMOVED_SECRET,
    REMOVED_SECRETWe first fine-tune an mBART model on our spanish, italian and chinese dataset to carry out our machine translation task. The code for fine-tuning can be found at finetune.py, while the model is saved in ./finalREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0e4d7643REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### Step 3: Machine Translation of expanded queries\nREMOVED_SECRET,
    REMOVED_SECRETWe then translate these queries using our finetuned mBART model. Similarly, this is implemented in translate.py but showcased here. REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 62,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET97a7137aREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETimport torch\nREMOVED_SECRET,
    REMOVED_SECRETfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETlang_code_map = {\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRETen\REMOVED_SECRET: \REMOVED_SECRETen_XX\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRETes\REMOVED_SECRET: \REMOVED_SECRETes_XX\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRETit\REMOVED_SECRET: \REMOVED_SECRETit_IT\REMOVED_SECRET, \nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRETcn\REMOVED_SECRET: \REMOVED_SECRETzh_CN\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#function to load model and tokenizer\nREMOVED_SECRET,
    REMOVED_SECRETdef load_model_and_tokenizer(model_path):\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRETLoad the model and tokenizer from the saved checkpoint\REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    model = MBartForConditionalGeneration.from_pretrained(model_path)\nREMOVED_SECRET,
    REMOVED_SECRET    tokenizer = MBart50TokenizerFast.from_pretrained(model_path)\nREMOVED_SECRET,
    REMOVED_SECRET    return model, tokenizer\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#translation function.\nREMOVED_SECRET,
    REMOVED_SECRETdef translate_sentence(model, tokenizer, text, src_lang, tgt_lang):\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRETTranslate a single sentence\REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    # Set source and target languages\nREMOVED_SECRET,
    REMOVED_SECRET    tokenizer.src_lang = lang_code_map[src_lang]\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Tokenize input\nREMOVED_SECRET,
    REMOVED_SECRET    inputs = tokenizer(text, return_tensors=\REMOVED_SECRETpt\REMOVED_SECRET, padding=True, truncation=True, max_length=64)\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Generate translation\nREMOVED_SECRET,
    REMOVED_SECRET    with torch.no_grad():\nREMOVED_SECRET,
    REMOVED_SECRET        outputs = model.generate(\nREMOVED_SECRET,
    REMOVED_SECRET            **inputs,\nREMOVED_SECRET,
    REMOVED_SECRET            forced_bos_token_id=tokenizer.lang_code_to_id[lang_code_map[tgt_lang]],\nREMOVED_SECRET,
    REMOVED_SECRET            max_length=64,\nREMOVED_SECRET,
    REMOVED_SECRET            num_beams=4,\nREMOVED_SECRET,
    REMOVED_SECRET            early_stopping=True,\nREMOVED_SECRET,
    REMOVED_SECRET            no_repeat_ngram_size=3,  # Prevent repeating n-grams\nREMOVED_SECRET,
    REMOVED_SECRET            repetition_penalty=2.0,   # Penalize repetition\nREMOVED_SECRET,
    REMOVED_SECRET            length_penalty=1.0,       # Balance between length and score\nREMOVED_SECRET,
    REMOVED_SECRET            temperature=0.7,          # Control randomness\nREMOVED_SECRET,
    REMOVED_SECRET            do_sample=True           # Enable sampling\nREMOVED_SECRET,
    REMOVED_SECRET        )\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET     # Decode the output\nREMOVED_SECRET,
    REMOVED_SECRET    translation = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\nREMOVED_SECRET,
    REMOVED_SECRET    return translation\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef translate_expanded(model, tokenizer, query_list, src_lang, tgt_lang):\nREMOVED_SECRET,
    REMOVED_SECRET    for query in query_list:\nREMOVED_SECRET,
    REMOVED_SECRET        query['term']=translate_sentence(model, tokenizer, query['term'], src_lang, tgt_lang)\nREMOVED_SECRET,
    REMOVED_SECRET    return query_list\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 63,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET7ab51c82REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#demo using expanded queries\nREMOVED_SECRET,
    REMOVED_SECRETtgt_lang='cn'\nREMOVED_SECRET,
    REMOVED_SECRETmodel, tokenizer = load_model_and_tokenizer(\REMOVED_SECRET./final\REMOVED_SECRET)\nREMOVED_SECRET,
    REMOVED_SECRETweighted_queries = translate_expanded(model, tokenizer, weighted_queries, 'en', tgt_lang)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 64,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETd70da652REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET[{'term': '跑鞋', 'weight': 1.0},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '跑鞋', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '慢跑鞋', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '耐鞋', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '運動鞋', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '教练员', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '跑鞋', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '跑鞋', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '路跑鞋', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '路跑鞋', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '性能跑鞋', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '跑鞋', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '耐力鞋', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '蘭寧鞋', 'weight': 0.3}]REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 64,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETweighted_queriesREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET08e461d7REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### Step 4: Hybrid Search of expanded queries\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETc29f5054REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#### 4.1 Data LoadingREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 65,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET34946e9bREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#returns a dicitonary of dfs\nREMOVED_SECRET,
    REMOVED_SECRETimport pandas as pd\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef get_data(data_paths):\nREMOVED_SECRET,
    REMOVED_SECRET    data = {} \nREMOVED_SECRET,
    REMOVED_SECRET    for lang, path in data_paths.items():\nREMOVED_SECRET,
    REMOVED_SECRET        data[lang]=pd.read_pickle(path)\nREMOVED_SECRET,
    REMOVED_SECRET    return dataREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 66,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETcfe4b66fREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETdata_paths={'cn':'en_to_cn_embeddings.pkl', 'es':'en_to_sp_embeddings.pkl', 'it':'en_to_it_embeddings.pkl'}\nREMOVED_SECRET,
    REMOVED_SECRETdata = get_data(data_paths)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETba0ccbfaREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#### BM25 SearchREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 67,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET84d6a6d8REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom rank_bm25 import BM25Okapi\nREMOVED_SECRET,
    REMOVED_SECRETimport pandas as pd\nREMOVED_SECRET,
    REMOVED_SECRETimport jiebaREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 68,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETfebd1b38REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#Build BM_25 corpus\nREMOVED_SECRET,
    REMOVED_SECRETdef build_BM25(data):\nREMOVED_SECRET,
    REMOVED_SECRET    #cn\nREMOVED_SECRET,
    REMOVED_SECRET    entocn_chinese_titles = data['cn']['chinese translation']\nREMOVED_SECRET,
    REMOVED_SECRET    entocn_tokenized_cn = [list(jieba.cut_for_search(title.lower())) for title in entocn_chinese_titles]\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_cn = BM25Okapi(entocn_tokenized_cn)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #es\nREMOVED_SECRET,
    REMOVED_SECRET    entoes_spanish_titles = data['es']['title_spanish']\nREMOVED_SECRET,
    REMOVED_SECRET    entoes_tokenized_es = [title.split() for title in entoes_spanish_titles]\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_es = BM25Okapi(entoes_tokenized_es)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #it\nREMOVED_SECRET,
    REMOVED_SECRET    entoit_italian_titles = data['it']['title_italian']\nREMOVED_SECRET,
    REMOVED_SECRET    entoit_tokenized_it = [title.split() for title in entoit_italian_titles]\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_it = BM25Okapi(entoit_tokenized_it)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_corpus={'cn':bm25_cn, 'es':bm25_es, 'it':bm25_it}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return bm25_corpus\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#Search BM25\nREMOVED_SECRET,
    REMOVED_SECRETdef search_bm25_expanded(query_list, corpus, tgt_lang='cn', top_k=5):\nREMOVED_SECRET,
    REMOVED_SECRET    #init scores as zeros\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    scores = [0.0] * len(corpus[tgt_lang].doc_len)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    for query_dict in query_list:\nREMOVED_SECRET,
    REMOVED_SECRET        term=query_dict['term']\nREMOVED_SECRET,
    REMOVED_SECRET        weight=query_dict['weight']\nREMOVED_SECRET,
    REMOVED_SECRET        if tgt_lang=='cn':\nREMOVED_SECRET,
    REMOVED_SECRET            tokens=jieba.cut_for_search(term.lower())\nREMOVED_SECRET,
    REMOVED_SECRET            term_scores = corpus[tgt_lang].get_scores(tokens)        \nREMOVED_SECRET,
    REMOVED_SECRET        else:\nREMOVED_SECRET,
    REMOVED_SECRET            tokens = term.lower().split()\nREMOVED_SECRET,
    REMOVED_SECRET            term_scores = corpus[tgt_lang].get_scores(tokens)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET        scores = [s + weight * ts for s, ts in zip(scores, term_scores)]\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    # Get top-k ranked indices\nREMOVED_SECRET,
    REMOVED_SECRET    top_k_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\nREMOVED_SECRET,
    REMOVED_SECRET    return top_k_ids, [scores[i] for i in top_k_ids]REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 69,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETb556de8bREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETbm25_corpus = build_BM25(data)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 70,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET9c4f4687REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETtop_ids, top_scores = search_bm25_expanded(weighted_queries, bm25_corpus)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 71,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETdcceebfaREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET39.3637 | New Balance Female 90 Lightweight Running Shoes  | New Balance 女 90轻量跑鞋 慢跑鞋- WSONIBS\nREMOVED_SECRET,
      REMOVED_SECRET37.0750 | Men Running Shoes Lightweight Sneakers Magic Baby ~ Sd8035  | 慢跑鞋 男款輕量運動鞋 魔法Baby~sd8035\nREMOVED_SECRET,
      REMOVED_SECRET36.7351 | Hole Bow Lazy Running Shoes Peach 1Ce28  | 洞洞蝴蝶結懶人慢跑鞋桃色1CE28\nREMOVED_SECRET,
      REMOVED_SECRET34.7104 | Magic Baby Children Girls Running Shoes Light Sneakers ~ Sa68305  | 魔法Baby 兒童慢跑鞋 中大童輕量運動鞋~sa68305\nREMOVED_SECRET,
      REMOVED_SECRET32.9813 | Mizuno Mizuno Running Shoes Female  | MIZUNO 女 美津浓 慢跑鞋- J1GD183001\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#remember our original search was 'shir long sleeve', mispelled on purpose.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETfor i, score in zip(top_ids, top_scores):\nREMOVED_SECRET,
    REMOVED_SECRET    print(f\REMOVED_SECRET{score:.4f} | {data['cn']['title'][i]}  | {data['cn']['chinese translation'][i]}\REMOVED_SECRET)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET1f994cf4REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#### Dense SearchREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 72,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETdf47839dREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom sentence_transformers import SentenceTransformer\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETmodel = SentenceTransformer(\REMOVED_SECRETBAAI/bge-m3\REMOVED_SECRET)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 73,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET8e0843e0REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom pinecone import Pinecone\nREMOVED_SECRET,
    REMOVED_SECRETfrom pinecone import ServerlessSpec\nREMOVED_SECRET,
    REMOVED_SECRETfrom dotenv import load_dotenv\nREMOVED_SECRET,
    REMOVED_SECRETimport os\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#Embeds a dense embedding representing the weighted mean of the expanded queries\nREMOVED_SECRET,
    REMOVED_SECRETdef embed_expanded(query_list, model):\nREMOVED_SECRET,
    REMOVED_SECRET    query_embeddings= []\nREMOVED_SECRET,
    REMOVED_SECRET    #embed expanded queries\nREMOVED_SECRET,
    REMOVED_SECRET    for query_dict in query_list:\nREMOVED_SECRET,
    REMOVED_SECRET        embedding=model.encode(query_dict['term'],  convert_to_tensor=True).cpu().numpy() #size1024\nREMOVED_SECRET,
    REMOVED_SECRET        query_embeddings.append(embedding * query_dict[\REMOVED_SECRETweight\REMOVED_SECRET])\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    query_embedding = sum(query_embeddings) / len(query_embeddings)  # Weighted mean\nREMOVED_SECRET,
    REMOVED_SECRET    return query_embedding\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef init_index(pc, index_name, data, embedding_col, eng_col, tgt_col, tgt_lang):\nREMOVED_SECRET,
    REMOVED_SECRET    index_name = index_name\nREMOVED_SECRET,
    REMOVED_SECRET    dimension = 1024\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    if index_name not in pc.list_indexes().names():\nREMOVED_SECRET,
    REMOVED_SECRET        pc.create_index(\nREMOVED_SECRET,
    REMOVED_SECRET            name=index_name,\nREMOVED_SECRET,
    REMOVED_SECRET            dimension=dimension,\nREMOVED_SECRET,
    REMOVED_SECRET            metric=\REMOVED_SECRETcosine\REMOVED_SECRET,  # by cosine similarity\nREMOVED_SECRET,
    REMOVED_SECRET            spec=ServerlessSpec(\nREMOVED_SECRET,
    REMOVED_SECRET                cloud=\REMOVED_SECRETaws\REMOVED_SECRET,  # or \REMOVED_SECRETgcp\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET                region=\REMOVED_SECRETus-east-1\REMOVED_SECRET \nREMOVED_SECRET,
    REMOVED_SECRET            )\nREMOVED_SECRET,
    REMOVED_SECRET        )\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    index = pc.Index(index_name)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    vectors_to_upsert = []\nREMOVED_SECRET,
    REMOVED_SECRET    for _, row in data.iterrows():\nREMOVED_SECRET,
    REMOVED_SECRET        vectors_to_upsert.append({\nREMOVED_SECRET,
    REMOVED_SECRET            \REMOVED_SECRETid\REMOVED_SECRET: str(_),  # Use index or generate unique IDs\nREMOVED_SECRET,
    REMOVED_SECRET            \REMOVED_SECRETvalues\REMOVED_SECRET: row[embedding_col],  # Using Chinese embeddings\nREMOVED_SECRET,
    REMOVED_SECRET            \REMOVED_SECRETmetadata\REMOVED_SECRET: {\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETtitle\REMOVED_SECRET: row[eng_col],\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETchinese_title\REMOVED_SECRET: row[tgt_col],\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETembedding_type\REMOVED_SECRET: tgt_lang  # Track which embedding was used\nREMOVED_SECRET,
    REMOVED_SECRET            }\nREMOVED_SECRET,
    REMOVED_SECRET        })\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    for i in range(0, len(vectors_to_upsert), 100):\nREMOVED_SECRET,
    REMOVED_SECRET        index.upsert(vectors=vectors_to_upsert[i:i+100])\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef setup_pinecone(data):\nREMOVED_SECRET,
    REMOVED_SECRET    load_dotenv(dotenv_path='../.env')\nREMOVED_SECRET,
    REMOVED_SECRET    pinecone_api_key = os.getenv('pinecone_API_KEY')\nREMOVED_SECRET,
    REMOVED_SECRET    pc = Pinecone(api_key=pinecone_api_key)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    data = data\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    indexes={'cn':'cn-search', 'it':'it-search', 'es':'es-search'}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #setup cn\nREMOVED_SECRET,
    REMOVED_SECRET    init_index(pc, index_name=indexes['cn'], data=data['cn'],\nREMOVED_SECRET,
    REMOVED_SECRET     embedding_col='chinese_embedding',\nREMOVED_SECRET,
    REMOVED_SECRET     eng_col='title',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_col='chinese translation',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_lang='chinese')\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #setup it\nREMOVED_SECRET,
    REMOVED_SECRET    init_index(pc, index_name=indexes['it'], data=data['it'],\nREMOVED_SECRET,
    REMOVED_SECRET     embedding_col='italian_embedding',\nREMOVED_SECRET,
    REMOVED_SECRET     eng_col='title',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_col='title_italian',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_lang='italian')\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #setup es\nREMOVED_SECRET,
    REMOVED_SECRET    init_index(pc, index_name=indexes['es'], data=data['es'],\nREMOVED_SECRET,
    REMOVED_SECRET     embedding_col='spanish_embedding',\nREMOVED_SECRET,
    REMOVED_SECRET     eng_col='title',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_col='title_spanish',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_lang='spanish')\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return indexes\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef search_pinecone(query_list, embedding_model, index_name, top_k=5):\nREMOVED_SECRET,
    REMOVED_SECRET    load_dotenv(dotenv_path='../.env')\nREMOVED_SECRET,
    REMOVED_SECRET    pinecone_api_key = os.getenv('pinecone_API_KEY')\nREMOVED_SECRET,
    REMOVED_SECRET    pc = Pinecone(api_key=pinecone_api_key)\nREMOVED_SECRET,
    REMOVED_SECRET    index = pc.Index(index_name)\nREMOVED_SECRET,
    REMOVED_SECRET    query_embedding=embed_expanded(query_list, embedding_model)\nREMOVED_SECRET,
    REMOVED_SECRET    results = index.query(\nREMOVED_SECRET,
    REMOVED_SECRET            vector=query_embedding.tolist(),\nREMOVED_SECRET,
    REMOVED_SECRET            top_k=top_k,\nREMOVED_SECRET,
    REMOVED_SECRET            include_metadata=False\nREMOVED_SECRET,
    REMOVED_SECRET        )\nREMOVED_SECRET,
    REMOVED_SECRET    id_list = []\nREMOVED_SECRET,
    REMOVED_SECRET    score_list = []\nREMOVED_SECRET,
    REMOVED_SECRET    for dict in results.matches:\nREMOVED_SECRET,
    REMOVED_SECRET        id_list.append(int(dict['id']))\nREMOVED_SECRET,
    REMOVED_SECRET        score_list.append(float(dict['score']))\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return id_list, score_list\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 74,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0f7a2022REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETpinecone_indices=setup_pinecone(data)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 75,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0efad315REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETtop_ids_pc, top_scores_pc =search_pinecone(weighted_queries, model, pinecone_indices['cn'])REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 76,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0cf11e39REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET0.7090 | Men'S Shoes Sports Shoes Shoes Running Shoes Air Cushion Shoes  | 男鞋運動鞋男休閒鞋跑步鞋氣墊鞋子\nREMOVED_SECRET,
      REMOVED_SECRET0.6922 | Running Sports Shoes Shoes Shoes Shoes  | 韓版跑步運動鞋女鞋學生單鞋女球鞋百搭休閒鞋子\nREMOVED_SECRET,
      REMOVED_SECRET0.6707 | New BALANCE 247 sports shoes running shoes black shoes Child ka247t2p no338  | New Balance 247 運動鞋 跑鞋 黑色 中童 童鞋 KA247T2P no338\nREMOVED_SECRET,
      REMOVED_SECRET0.6674 | New Balance Female 90 Lightweight Running Shoes  | New Balance 女 90轻量跑鞋 慢跑鞋- WSONIBS\nREMOVED_SECRET,
      REMOVED_SECRET0.6673 | Skechers Women When - High Running Shoes  | SKECHERS 女 Liv-High 慢跑鞋 - 99830WSL\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#remember our original search was 'shir long sleeve', mispelled on purpose.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETfor i, score in zip(top_ids_pc, top_scores_pc):\nREMOVED_SECRET,
    REMOVED_SECRET    print(f\REMOVED_SECRET{score:.4f} | {data['cn']['title'][i]}  | {data['cn']['chinese translation'][i]}\REMOVED_SECRET)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET7690b596REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#### RRFREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 77,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETa085a8b8REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET[902, 349, 630, 356, 156] [39.36373785264429, 37.07501466149296, 36.735098995178525, 34.71038588022547, 32.981256874273285]\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#recap: Right now, we have BM25 results, returned as\nREMOVED_SECRET,
    REMOVED_SECRETprint(top_ids, top_scores)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 78,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETb655385fREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET[951, 654, 782, 902, 783] [0.708953798, 0.692248642, 0.670711398, 0.66745, 0.667325675]\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#recap: We also have semantic results, returned as\nREMOVED_SECRET,
    REMOVED_SECRETprint(top_ids_pc, top_scores_pc)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 79,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET64a460d6REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETimport numpy as np\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef scores_to_ranking(scores: list[float]) -> list[int]:\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRETConvert float scores into int rankings (1 = best).\REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return np.argsort(scores)[::-1] + 1  # ranks start at 1\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef rrf(keyword_rank: int, semantic_rank: int, k: int = 60) -> float:\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRETCombine keyword rank and semantic rank into a hybrid score using RRF.\REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return 1 / (k + keyword_rank) + 1 / (k + semantic_rank)\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 80,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETf4b0b516REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETdef hybrid_expanded_search(query_list, bm25_corpus, pinecone_indices, embedding_model, tgt_lang='cn', top_k=5 ):\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_top_ids, bm25_top_scores = search_bm25_expanded(query_list, bm25_corpus, top_k=top_k)\nREMOVED_SECRET,
    REMOVED_SECRET    pc_top_ids, pc_top_scores =search_pinecone(query_list, embedding_model, pinecone_indices[tgt_lang], top_k=top_k)\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_ranks = scores_to_ranking(bm25_top_scores)\nREMOVED_SECRET,
    REMOVED_SECRET    pc_ranks = scores_to_ranking(pc_top_scores)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    # Create dictionaries for quick rank lookup\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_rank_dict = {doc_id: rank for doc_id, rank in zip(bm25_top_ids, bm25_ranks)}\nREMOVED_SECRET,
    REMOVED_SECRET    pc_rank_dict = {doc_id: rank for doc_id, rank in zip(pc_top_ids, pc_ranks)}\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Combine all unique document IDs from both methods\nREMOVED_SECRET,
    REMOVED_SECRET    all_doc_ids = list(set(bm25_top_ids) | set(pc_top_ids))\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Calculate RRF scores for each document\nREMOVED_SECRET,
    REMOVED_SECRET    rrf_scores = []\nREMOVED_SECRET,
    REMOVED_SECRET    for doc_id in all_doc_ids:\nREMOVED_SECRET,
    REMOVED_SECRET        # Get ranks from each method (use a high rank if document not found)\nREMOVED_SECRET,
    REMOVED_SECRET        bm25_rank = bm25_rank_dict.get(doc_id, top_k * 2)  # Penalize missing documents\nREMOVED_SECRET,
    REMOVED_SECRET        pc_rank = pc_rank_dict.get(doc_id, top_k * 2)\nREMOVED_SECRET,
    REMOVED_SECRET        \nREMOVED_SECRET,
    REMOVED_SECRET        # Calculate combined RRF score\nREMOVED_SECRET,
    REMOVED_SECRET        score = rrf(bm25_rank, pc_rank)\nREMOVED_SECRET,
    REMOVED_SECRET        rrf_scores.append((doc_id, score))\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Sort documents by RRF score (descending)\nREMOVED_SECRET,
    REMOVED_SECRET    rrf_scores.sort(key=lambda x: -x[1])\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Extract the top_k document IDs\nREMOVED_SECRET,
    REMOVED_SECRET    #hybrid_top_ids = [doc_id for doc_id, score in rrf_scores[:top_k]]\nREMOVED_SECRET,
    REMOVED_SECRET    hybrid_top_ids = [doc_id for doc_id, score in rrf_scores]\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #hybrid_top_scores = [score for doc_id, score in rrf_scores[:top_k]]\nREMOVED_SECRET,
    REMOVED_SECRET    hybrid_top_scores = [score for doc_id, score in rrf_scores]\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    return hybrid_top_ids, hybrid_top_scores\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 81,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET43bd0e40REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECREThybrid_top_id, hybrid_top_scores=hybrid_expanded_search(weighted_queries, bm25_corpus, pinecone_indices, model)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 82,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET3cf19797REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET0.0320 | New Balance Female 90 Lightweight Running Shoes  | New Balance 女 90轻量跑鞋 慢跑鞋- WSONIBS\nREMOVED_SECRET,
      REMOVED_SECRET0.0307 | Men'S Shoes Sports Shoes Shoes Running Shoes Air Cushion Shoes  | 男鞋運動鞋男休閒鞋跑步鞋氣墊鞋子\nREMOVED_SECRET,
      REMOVED_SECRET0.0304 | Running Sports Shoes Shoes Shoes Shoes  | 韓版跑步運動鞋女鞋學生單鞋女球鞋百搭休閒鞋子\nREMOVED_SECRET,
      REMOVED_SECRET0.0304 | Men Running Shoes Lightweight Sneakers Magic Baby ~ Sd8035  | 慢跑鞋 男款輕量運動鞋 魔法Baby~sd8035\nREMOVED_SECRET,
      REMOVED_SECRET0.0302 | New BALANCE 247 sports shoes running shoes black shoes Child ka247t2p no338  | New Balance 247 運動鞋 跑鞋 黑色 中童 童鞋 KA247T2P no338\nREMOVED_SECRET,
      REMOVED_SECRET0.0302 | Hole Bow Lazy Running Shoes Peach 1Ce28  | 洞洞蝴蝶結懶人慢跑鞋桃色1CE28\nREMOVED_SECRET,
      REMOVED_SECRET0.0299 | Magic Baby Children Girls Running Shoes Light Sneakers ~ Sa68305  | 魔法Baby 兒童慢跑鞋 中大童輕量運動鞋~sa68305\nREMOVED_SECRET,
      REMOVED_SECRET0.0297 | Skechers Women When - High Running Shoes  | SKECHERS 女 Liv-High 慢跑鞋 - 99830WSL\nREMOVED_SECRET,
      REMOVED_SECRET0.0297 | Mizuno Mizuno Running Shoes Female  | MIZUNO 女 美津浓 慢跑鞋- J1GD183001\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfor i, score in zip(hybrid_top_id, hybrid_top_scores):\nREMOVED_SECRET,
    REMOVED_SECRET    print(f\REMOVED_SECRET{score:.4f} | {data['cn']['title'][i]}  | {data['cn']['chinese translation'][i]}\REMOVED_SECRET)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 83,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET48db3d24REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom bert_score import score\nREMOVED_SECRET,
    REMOVED_SECRETimport warnings\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef calculate_bertscore(candidate, reference, lang = \REMOVED_SECRETen\REMOVED_SECRET):\nREMOVED_SECRET,
    REMOVED_SECRET    with warnings.catch_warnings():\nREMOVED_SECRET,
    REMOVED_SECRET        warnings.simplefilter(\REMOVED_SECRETignore\REMOVED_SECRET)\nREMOVED_SECRET,
    REMOVED_SECRET        # Compute scores\nREMOVED_SECRET,
    REMOVED_SECRET        P, R, F1 = score(\nREMOVED_SECRET,
    REMOVED_SECRET            [candidate], \nREMOVED_SECRET,
    REMOVED_SECRET            [reference], \nREMOVED_SECRET,
    REMOVED_SECRET            lang=lang,\nREMOVED_SECRET,
    REMOVED_SECRET            model_type=\REMOVED_SECRETbert-base-multilingual-cased\REMOVED_SECRET,  # Multilingual BERT\nREMOVED_SECRET,
    REMOVED_SECRET            verbose=False  # Disable progress messages\nREMOVED_SECRET,
    REMOVED_SECRET        )\nREMOVED_SECRET,
    REMOVED_SECRET    return P.item(), R.item(), F1.item()\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef get_final_output(query, hybrid_top_id, data, tgt_lang='cn'):\nREMOVED_SECRET,
    REMOVED_SECRET    final_output={}\nREMOVED_SECRET,
    REMOVED_SECRET    for ids in hybrid_top_id:\nREMOVED_SECRET,
    REMOVED_SECRET        if tgt_lang=='cn':\nREMOVED_SECRET,
    REMOVED_SECRET            txt=data[tgt_lang]['chinese translation'][ids]\nREMOVED_SECRET,
    REMOVED_SECRET        elif tgt_lang=='es':\nREMOVED_SECRET,
    REMOVED_SECRET            txt=data[tgt_lang]['title_spanish'][ids]\nREMOVED_SECRET,
    REMOVED_SECRET        elif tgt_lang=='it':\nREMOVED_SECRET,
    REMOVED_SECRET            txt=data[tgt_lang]['title_italian'][ids]\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET        acc, precision, f1 = calculate_bertscore(txt, query)\nREMOVED_SECRET,
    REMOVED_SECRET        final_output[txt]=f1\nREMOVED_SECRET,
    REMOVED_SECRET    return final_output\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 84,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETa8a504f8REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETquery=\REMOVED_SECRETshir long sleeve\REMOVED_SECRETREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 85,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETb9f01fb5REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstderrREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfinal_output = get_final_output(query, hybrid_top_id, data, tgt_lang='cn')REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 86,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET5c580dc6REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET{'New Balance 女 90轻量跑鞋 慢跑鞋- WSONIBS': 0.6317388415336609,\nREMOVED_SECRET,
       REMOVED_SECRET '男鞋運動鞋男休閒鞋跑步鞋氣墊鞋子': 0.6080911755561829,\nREMOVED_SECRET,
       REMOVED_SECRET '韓版跑步運動鞋女鞋學生單鞋女球鞋百搭休閒鞋子': 0.6144701242446899,\nREMOVED_SECRET,
       REMOVED_SECRET '慢跑鞋 男款輕量運動鞋 魔法Baby~sd8035': 0.6211652159690857,\nREMOVED_SECRET,
       REMOVED_SECRET 'New Balance 247 運動鞋 跑鞋 黑色 中童 童鞋 KA247T2P no338': 0.6184868812561035,\nREMOVED_SECRET,
       REMOVED_SECRET '洞洞蝴蝶結懶人慢跑鞋桃色1CE28': 0.6251214742660522,\nREMOVED_SECRET,
       REMOVED_SECRET '魔法Baby 兒童慢跑鞋 中大童輕量運動鞋~sa68305': 0.630289614200592,\nREMOVED_SECRET,
       REMOVED_SECRET 'SKECHERS 女 Liv-High 慢跑鞋 - 99830WSL': 0.6048922538757324,\nREMOVED_SECRET,
       REMOVED_SECRET 'MIZUNO 女 美津浓 慢跑鞋- J1GD183001': 0.6235170960426331}REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 86,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfinal_outputREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET2546c887REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### Step 5: Evaluation MetricsREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET00e25715REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETHere, we use the debug mode for the implemented search function to generate some evaluation metrics for our searchesREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET9e0a93feREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#### Testing the final pipelineREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 87,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0c37a464REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom mtpipeline import init_mt_environment, mt_pipeline_searchREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 88,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET23505f20REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETmBART_model_path=\REMOVED_SECRET./final\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdata_paths={'cn':'en_to_cn_embeddings.pkl', 'es':'en_to_sp_embeddings.pkl', 'it':'en_to_it_embeddings.pkl'}\nREMOVED_SECRET,
    REMOVED_SECRETembed_model = \REMOVED_SECRETBAAI/bge-m3\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETenv_path = \REMOVED_SECRET../.env\REMOVED_SECRETREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 89,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET8f184311REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#run once at start of front end\nREMOVED_SECRET,
    REMOVED_SECRETmBART_model, mBART_tokenizer, data, bm25_corpus, dense_embed_model, pinecone_indices = init_mt_environment(mBART_model_path, data_paths, embed_model, env_path)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 90,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETdc4f5f50REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET'OPPO A75 A75s A73 手机壳 软壳 挂绳壳 大眼兔硅胶壳'REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 90,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETdata['cn']['chinese translation'][0]REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 91,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET803fe495REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETquery=\REMOVED_SECRETshort sleeved t-shirt\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETtgt_lang = \REMOVED_SECRETcn\REMOVED_SECRET #should be 'es' for spanish, 'cn' for chinese and 'it' italy\nREMOVED_SECRET,
    REMOVED_SECRETtop_k=5REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 92,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0a00ff14REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRETExpanding queries...\nREMOVED_SECRET,
      REMOVED_SECRETQueries Expanded\nREMOVED_SECRET,
      REMOVED_SECRETTranslating Queries...\nREMOVED_SECRET,
      REMOVED_SECRETSearching...\nREMOVED_SECRET,
      REMOVED_SECRETProcessing Output...\nREMOVED_SECRET
     ]
    },
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstderrREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfinal_output = mt_pipeline_search(query, \nREMOVED_SECRET,
    REMOVED_SECRET                                    env_path,\nREMOVED_SECRET,
    REMOVED_SECRET                                    mBART_model,\nREMOVED_SECRET,
    REMOVED_SECRET                                    mBART_tokenizer,\nREMOVED_SECRET,
    REMOVED_SECRET                                    data,\nREMOVED_SECRET,
    REMOVED_SECRET                                    bm25_corpus,\nREMOVED_SECRET,
    REMOVED_SECRET                                    pinecone_indices,\nREMOVED_SECRET,
    REMOVED_SECRET                                    dense_embed_model,\nREMOVED_SECRET,
    REMOVED_SECRET                                    tgt_lang, #optional\nREMOVED_SECRET,
    REMOVED_SECRET                                    top_k,) #optionalREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 93,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET9ecfe260REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET{'點點荷葉一字領短上衣': 0.674094021320343,\nREMOVED_SECRET,
       REMOVED_SECRET '情侶短袖t 夏季水洗33數字短袖t': 0.6550724506378174,\nREMOVED_SECRET,
       REMOVED_SECRET 'Augelute 兒童 套裝 居家森林護肚短袖套裝 31152': 0.6553329825401306,\nREMOVED_SECRET,
       REMOVED_SECRET '牛仔捲邊破褲 短褲': 0.6830734014511108,\nREMOVED_SECRET,
       REMOVED_SECRET '韩制。针织洞洞感网状透气短袜': 0.6939300894737244,\nREMOVED_SECRET,
       REMOVED_SECRET '0~2歲寶寶短袖居家套裝 魔法baby~k50475': 0.6293430328369141,\nREMOVED_SECRET,
       REMOVED_SECRET '多彩舒適棉素面百搭大尺碼POLO短衫_薰衣紫': 0.6625270247459412,\nREMOVED_SECRET,
       REMOVED_SECRET 'LIYO理優英文字母休閒棉T恤E712003': 0.6467800736427307,\nREMOVED_SECRET,
       REMOVED_SECRET 'iFairies 中大尺碼長袖T恤上衣★ifairies【59000】【59000】': 0.6530770659446716,\nREMOVED_SECRET,
       REMOVED_SECRET '長版口袋開襟針織外套': 0.6996235847473145}REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 93,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfinal_outputREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET1c0bdb48REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### MetricsREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETc76b4b43REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETTo evaluate the semantic relevance of search results we used **BERTScore (F1)**, **Sentence-BERT cosine similarity**, and **METEOR**. We selected these metrics to cover more than just simple lexical overlap, aiming to capture the deeper semantic meaning and contextual alignment between the query and the retrieved results.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**BERTScore (F1)** uses contextual embeddings from a pre-trained BERT model to evaluate the similarity between a candidate sentence and query. Unlike traditional token-based metrics, BERTScore considers word usage in context, making it particularly effective at identifying semantic similarity even when different words or phrasing are used.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Sentence-BERT cosine similarity** compares sentence-level embeddings in a shared vector space. It measures the overall semantic closeness of the query and result pairs, making it a strong indicator of whether two sentences convey similar meanings holistically.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**METEOR** offers a balance between precision and recall at the word level, incorporating stemming, synonym matching through WordNet, and alignment-based evaluation. It helps account for linguistic variation while still rewarding accurate matches, and has shown strong correlation with human judgments in evaluation studies.\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 102,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET80c3e1c0REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRETExpanding queries...\nREMOVED_SECRET,
      REMOVED_SECRETQueries Expanded\nREMOVED_SECRET,
      REMOVED_SECRETTranslating Queries...\nREMOVED_SECRET,
      REMOVED_SECRETSearching...\nREMOVED_SECRET,
      REMOVED_SECRETProcessing Output...\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfinal_output_debug = mt_pipeline_search(query, \nREMOVED_SECRET,
    REMOVED_SECRET                                    env_path,\nREMOVED_SECRET,
    REMOVED_SECRET                                    mBART_model,\nREMOVED_SECRET,
    REMOVED_SECRET                                    mBART_tokenizer,\nREMOVED_SECRET,
    REMOVED_SECRET                                    data,\nREMOVED_SECRET,
    REMOVED_SECRET                                    bm25_corpus,\nREMOVED_SECRET,
    REMOVED_SECRET                                    pinecone_indices,\nREMOVED_SECRET,
    REMOVED_SECRET                                    dense_embed_model,\nREMOVED_SECRET,
    REMOVED_SECRET                                    tgt_lang, #optional\nREMOVED_SECRET,
    REMOVED_SECRET                                    top_k,\nREMOVED_SECRET,
    REMOVED_SECRET                                    debug=True) #optionalREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 103,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET9547ec0eREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/htmlREMOVED_SECRET: [
       REMOVED_SECRET<div>\nREMOVED_SECRET,
       REMOVED_SECRET<style scoped>\nREMOVED_SECRET,
       REMOVED_SECRET    .dataframe tbody tr th:only-of-type {\nREMOVED_SECRET,
       REMOVED_SECRET        vertical-align: middle;\nREMOVED_SECRET,
       REMOVED_SECRET    }\nREMOVED_SECRET,
       REMOVED_SECRET\nREMOVED_SECRET,
       REMOVED_SECRET    .dataframe tbody tr th {\nREMOVED_SECRET,
       REMOVED_SECRET        vertical-align: top;\nREMOVED_SECRET,
       REMOVED_SECRET    }\nREMOVED_SECRET,
       REMOVED_SECRET\nREMOVED_SECRET,
       REMOVED_SECRET    .dataframe thead th {\nREMOVED_SECRET,
       REMOVED_SECRET        text-align: right;\nREMOVED_SECRET,
       REMOVED_SECRET    }\nREMOVED_SECRET,
       REMOVED_SECRET</style>\nREMOVED_SECRET,
       REMOVED_SECRET<table border=\REMOVED_SECRET1\REMOVED_SECRET class=\REMOVED_SECRETdataframe\REMOVED_SECRET>\nREMOVED_SECRET,
       REMOVED_SECRET  <thead>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr style=\REMOVED_SECRETtext-align: right;\REMOVED_SECRET>\nREMOVED_SECRET,
       REMOVED_SECRET      <th></th>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>en</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>tgt</th>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET  </thead>\nREMOVED_SECRET,
       REMOVED_SECRET  <tbody>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>0</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Couple Short-Sleeved T Summer Washed 33 Digita...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>情侶短袖t 夏季水洗33數字短袖t</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>1</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Polka Dots Lotus Leaf word Short Tops</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>點點荷葉一字領短上衣</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>2</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Augelute Kids Set Home Forest Belly Short Slee...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Augelute 兒童 套裝 居家森林護肚短袖套裝 31152</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>3</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Cowboy Curling Jeans Shorts</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>牛仔捲邊破褲 短褲</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>4</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Korean Made. Knitted Hole Sexy Mesh Breathable...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>韩制。针织洞洞感网状透气短袜</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>5</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0 ~ 2 Girls Short Sleeve Home Suit Magic Baby ...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0~2歲寶寶短袖居家套裝 魔法baby~k50475</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>6</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>PolarStar Women Sweat Quick Dry T-shirt Black ...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>PolarStar 女 排汗快干T恤『黑』P18102</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>7</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>LIYO-English letter casual cotton T-shirt</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>LIYO理優英文字母休閒棉T恤E712003</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>8</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Bamboo Cotton Spaghetti Strap Vest</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>竹節棉細肩帶背心</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET  </tbody>\nREMOVED_SECRET,
       REMOVED_SECRET</table>\nREMOVED_SECRET,
       REMOVED_SECRET</div>REMOVED_SECRET
      ],
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET                                                  en  \\\nREMOVED_SECRET,
       REMOVED_SECRET0  Couple Short-Sleeved T Summer Washed 33 Digita...   \nREMOVED_SECRET,
       REMOVED_SECRET1              Polka Dots Lotus Leaf word Short Tops   \nREMOVED_SECRET,
       REMOVED_SECRET2  Augelute Kids Set Home Forest Belly Short Slee...   \nREMOVED_SECRET,
       REMOVED_SECRET3                        Cowboy Curling Jeans Shorts   \nREMOVED_SECRET,
       REMOVED_SECRET4  Korean Made. Knitted Hole Sexy Mesh Breathable...   \nREMOVED_SECRET,
       REMOVED_SECRET5  0 ~ 2 Girls Short Sleeve Home Suit Magic Baby ...   \nREMOVED_SECRET,
       REMOVED_SECRET6  PolarStar Women Sweat Quick Dry T-shirt Black ...   \nREMOVED_SECRET,
       REMOVED_SECRET7          LIYO-English letter casual cotton T-shirt   \nREMOVED_SECRET,
       REMOVED_SECRET8                 Bamboo Cotton Spaghetti Strap Vest   \nREMOVED_SECRET,
       REMOVED_SECRET\nREMOVED_SECRET,
       REMOVED_SECRET                               tgt  \nREMOVED_SECRET,
       REMOVED_SECRET0                情侶短袖t 夏季水洗33數字短袖t  \nREMOVED_SECRET,
       REMOVED_SECRET1                       點點荷葉一字領短上衣  \nREMOVED_SECRET,
       REMOVED_SECRET2  Augelute 兒童 套裝 居家森林護肚短袖套裝 31152  \nREMOVED_SECRET,
       REMOVED_SECRET3                        牛仔捲邊破褲 短褲  \nREMOVED_SECRET,
       REMOVED_SECRET4                   韩制。针织洞洞感网状透气短袜  \nREMOVED_SECRET,
       REMOVED_SECRET5       0~2歲寶寶短袖居家套裝 魔法baby~k50475  \nREMOVED_SECRET,
       REMOVED_SECRET6      PolarStar 女 排汗快干T恤『黑』P18102  \nREMOVED_SECRET,
       REMOVED_SECRET7           LIYO理優英文字母休閒棉T恤E712003  \nREMOVED_SECRET,
       REMOVED_SECRET8                         竹節棉細肩帶背心  REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 103,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfinal_output_debugREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 104,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET883b302dREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstderrREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRETSome weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nREMOVED_SECRET,
      REMOVED_SECRETYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom nltk.translate.meteor_score import meteor_score\nREMOVED_SECRET,
    REMOVED_SECRET#calculate METEOR\nREMOVED_SECRET,
    REMOVED_SECRETfinal_output_debug['meteor'] = final_output_debug['en'].apply(lambda x: meteor_score([query.split()], x.split()))\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#Compute sentenceBERT cosine sim\nREMOVED_SECRET,
    REMOVED_SECRETfrom sentence_transformers import SentenceTransformer, util\nREMOVED_SECRET,
    REMOVED_SECRETmodel = SentenceTransformer('all-MiniLM-L6-v2')\nREMOVED_SECRET,
    REMOVED_SECRETquery_embedding = model.encode(query, convert_to_tensor=True)\nREMOVED_SECRET,
    REMOVED_SECRETen_embeddings = model.encode(final_output_debug['en'].tolist(), convert_to_tensor=True)\nREMOVED_SECRET,
    REMOVED_SECRETcosine_scores = util.cos_sim(query_embedding, en_embeddings)[0]\nREMOVED_SECRET,
    REMOVED_SECRETfinal_output_debug['sbert_cosine'] = cosine_scores.tolist()\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#calculate bertscore\nREMOVED_SECRET,
    REMOVED_SECRETP, R, F1 = score([query] * len(final_output_debug), final_output_debug['en'].tolist(), lang=\REMOVED_SECRETen\REMOVED_SECRET, verbose=False)\nREMOVED_SECRET,
    REMOVED_SECRETfinal_output_debug['bertscore_f1'] = F1.tolist()\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 105,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET7e449c92REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/htmlREMOVED_SECRET: [
       REMOVED_SECRET<div>\nREMOVED_SECRET,
       REMOVED_SECRET<style scoped>\nREMOVED_SECRET,
       REMOVED_SECRET    .dataframe tbody tr th:only-of-type {\nREMOVED_SECRET,
       REMOVED_SECRET        vertical-align: middle;\nREMOVED_SECRET,
       REMOVED_SECRET    }\nREMOVED_SECRET,
       REMOVED_SECRET\nREMOVED_SECRET,
       REMOVED_SECRET    .dataframe tbody tr th {\nREMOVED_SECRET,
       REMOVED_SECRET        vertical-align: top;\nREMOVED_SECRET,
       REMOVED_SECRET    }\nREMOVED_SECRET,
       REMOVED_SECRET\nREMOVED_SECRET,
       REMOVED_SECRET    .dataframe thead th {\nREMOVED_SECRET,
       REMOVED_SECRET        text-align: right;\nREMOVED_SECRET,
       REMOVED_SECRET    }\nREMOVED_SECRET,
       REMOVED_SECRET</style>\nREMOVED_SECRET,
       REMOVED_SECRET<table border=\REMOVED_SECRET1\REMOVED_SECRET class=\REMOVED_SECRETdataframe\REMOVED_SECRET>\nREMOVED_SECRET,
       REMOVED_SECRET  <thead>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr style=\REMOVED_SECRETtext-align: right;\REMOVED_SECRET>\nREMOVED_SECRET,
       REMOVED_SECRET      <th></th>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>en</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>tgt</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>meteor</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>sbert_cosine</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>bertscore_f1</th>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET  </thead>\nREMOVED_SECRET,
       REMOVED_SECRET  <tbody>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>0</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Couple Short-Sleeved T Summer Washed 33 Digita...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>情侶短袖t 夏季水洗33數字短袖t</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.506757</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.703328</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.860155</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>1</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Polka Dots Lotus Leaf word Short Tops</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>點點荷葉一字領短上衣</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.147059</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.327517</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.810884</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>2</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Augelute Kids Set Home Forest Belly Short Slee...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Augelute 兒童 套裝 居家森林護肚短袖套裝 31152</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.520833</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.504298</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.818984</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>3</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Cowboy Curling Jeans Shorts</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>牛仔捲邊破褲 短褲</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.161290</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.365026</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.837606</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>4</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Korean Made. Knitted Hole Sexy Mesh Breathable...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>韩制。针织洞洞感网状透气短袜</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.000000</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.276768</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.822082</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>5</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0 ~ 2 Girls Short Sleeve Home Suit Magic Baby ...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0~2歲寶寶短袖居家套裝 魔法baby~k50475</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.480769</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.304197</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.847186</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>6</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>PolarStar Women Sweat Quick Dry T-shirt Black ...</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>PolarStar 女 排汗快干T恤『黑』P18102</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.138889</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.404821</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.830408</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>7</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>LIYO-English letter casual cotton T-shirt</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>LIYO理優英文字母休閒棉T恤E712003</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.156250</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.550334</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.856207</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET    <tr>\nREMOVED_SECRET,
       REMOVED_SECRET      <th>8</th>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>Bamboo Cotton Spaghetti Strap Vest</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>竹節棉細肩帶背心</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.000000</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.366832</td>\nREMOVED_SECRET,
       REMOVED_SECRET      <td>0.833241</td>\nREMOVED_SECRET,
       REMOVED_SECRET    </tr>\nREMOVED_SECRET,
       REMOVED_SECRET  </tbody>\nREMOVED_SECRET,
       REMOVED_SECRET</table>\nREMOVED_SECRET,
       REMOVED_SECRET</div>REMOVED_SECRET
      ],
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET                                                  en  \\\nREMOVED_SECRET,
       REMOVED_SECRET0  Couple Short-Sleeved T Summer Washed 33 Digita...   \nREMOVED_SECRET,
       REMOVED_SECRET1              Polka Dots Lotus Leaf word Short Tops   \nREMOVED_SECRET,
       REMOVED_SECRET2  Augelute Kids Set Home Forest Belly Short Slee...   \nREMOVED_SECRET,
       REMOVED_SECRET3                        Cowboy Curling Jeans Shorts   \nREMOVED_SECRET,
       REMOVED_SECRET4  Korean Made. Knitted Hole Sexy Mesh Breathable...   \nREMOVED_SECRET,
       REMOVED_SECRET5  0 ~ 2 Girls Short Sleeve Home Suit Magic Baby ...   \nREMOVED_SECRET,
       REMOVED_SECRET6  PolarStar Women Sweat Quick Dry T-shirt Black ...   \nREMOVED_SECRET,
       REMOVED_SECRET7          LIYO-English letter casual cotton T-shirt   \nREMOVED_SECRET,
       REMOVED_SECRET8                 Bamboo Cotton Spaghetti Strap Vest   \nREMOVED_SECRET,
       REMOVED_SECRET\nREMOVED_SECRET,
       REMOVED_SECRET                               tgt    meteor  sbert_cosine  bertscore_f1  \nREMOVED_SECRET,
       REMOVED_SECRET0                情侶短袖t 夏季水洗33數字短袖t  0.506757      0.703328      0.860155  \nREMOVED_SECRET,
       REMOVED_SECRET1                       點點荷葉一字領短上衣  0.147059      0.327517      0.810884  \nREMOVED_SECRET,
       REMOVED_SECRET2  Augelute 兒童 套裝 居家森林護肚短袖套裝 31152  0.520833      0.504298      0.818984  \nREMOVED_SECRET,
       REMOVED_SECRET3                        牛仔捲邊破褲 短褲  0.161290      0.365026      0.837606  \nREMOVED_SECRET,
       REMOVED_SECRET4                   韩制。针织洞洞感网状透气短袜  0.000000      0.276768      0.822082  \nREMOVED_SECRET,
       REMOVED_SECRET5       0~2歲寶寶短袖居家套裝 魔法baby~k50475  0.480769      0.304197      0.847186  \nREMOVED_SECRET,
       REMOVED_SECRET6      PolarStar 女 排汗快干T恤『黑』P18102  0.138889      0.404821      0.830408  \nREMOVED_SECRET,
       REMOVED_SECRET7           LIYO理優英文字母休閒棉T恤E712003  0.156250      0.550334      0.856207  \nREMOVED_SECRET,
       REMOVED_SECRET8                         竹節棉細肩帶背心  0.000000      0.366832      0.833241  REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 105,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfinal_output_debugREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETeb88aca6REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETA high BERTscore suggests strong semantic similarity between the query and target translations, whereas a greater variability in sentence-BERT suggests a potential sensitivity to global smenatic shifts. As METEOR is more reliant on token-level overlap, it scores much lower. However, as the results are still semantically similar, this is alright.REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0de1f12aREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: []
  }
 ],
 REMOVED_SECRETmetadataREMOVED_SECRET: {
  REMOVED_SECRETkernelspecREMOVED_SECRET: {
   REMOVED_SECRETdisplay_nameREMOVED_SECRET: REMOVED_SECRETtensorflow_baseREMOVED_SECRET,
   REMOVED_SECRETlanguageREMOVED_SECRET: REMOVED_SECRETpythonREMOVED_SECRET,
   REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETpython3REMOVED_SECRET
  },
  REMOVED_SECRETlanguage_infoREMOVED_SECRET: {
   REMOVED_SECRETcodemirror_modeREMOVED_SECRET: {
    REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETipythonREMOVED_SECRET,
    REMOVED_SECRETversionREMOVED_SECRET: 3
   },
   REMOVED_SECRETfile_extensionREMOVED_SECRET: REMOVED_SECRET.pyREMOVED_SECRET,
   REMOVED_SECRETmimetypeREMOVED_SECRET: REMOVED_SECRETtext/x-pythonREMOVED_SECRET,
   REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETpythonREMOVED_SECRET,
   REMOVED_SECRETnbconvert_exporterREMOVED_SECRET: REMOVED_SECRETpythonREMOVED_SECRET,
   REMOVED_SECRETpygments_lexerREMOVED_SECRET: REMOVED_SECRETipython3REMOVED_SECRET,
   REMOVED_SECRETversionREMOVED_SECRET: REMOVED_SECRET3.10.11REMOVED_SECRET
  }
 },
 REMOVED_SECRETnbformatREMOVED_SECRET: 4,
 REMOVED_SECRETnbformat_minorREMOVED_SECRET: 5
}
