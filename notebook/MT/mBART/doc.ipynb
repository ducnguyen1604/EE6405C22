{
 REMOVED_SECRETcellsREMOVED_SECRET: [
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET6d9ae35dREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET# Overview of MT PipelineREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETac4ff736REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### Step 1: Query Expansion CODE LOCATED IN queryexpansion.py\nREMOVED_SECRET,
    REMOVED_SECRETWe first use DeepSeek v3 to carry out query expansion on our queries. This is implemented as a function in queryexpansion.py, but will be demonstrated here:REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 1,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETab33f134REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom openai import OpenAI\nREMOVED_SECRET,
    REMOVED_SECRETfrom dotenv import load_dotenv\nREMOVED_SECRET,
    REMOVED_SECRETimport os\nREMOVED_SECRET,
    REMOVED_SECRETimport json\nREMOVED_SECRET,
    REMOVED_SECRETimport re\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#load API key\nREMOVED_SECRET,
    REMOVED_SECRETload_dotenv(dotenv_path='../.env')\nREMOVED_SECRET,
    REMOVED_SECRETapi_key = os.getenv('deepseek_API_KEY')\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#set up connection\nREMOVED_SECRET,
    REMOVED_SECRETclient = OpenAI(api_key=api_key, base_url=\REMOVED_SECREThttps://openrouter.ai/api/v1\REMOVED_SECRET)\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET235c12d4REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETWe define a function to expand our query:REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 2,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET1fe9f19eREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETdef get_expanded_queries(user_query):\nREMOVED_SECRET,
    REMOVED_SECRET    prompt=f'''You are an expert search query optimizer. Your task is to expand the following e-commerce search query to improve retrieval of relevant products. Generate a list of semantically related terms, synonyms, and common user variations while preserving the original intent.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Rules:**\nREMOVED_SECRET,
    REMOVED_SECRET1. Prioritize **contextual relevance** (e.g., \REMOVED_SECRETrunning shoes\REMOVED_SECRET → \REMOVED_SECRETjogging sneakers\REMOVED_SECRET).\nREMOVED_SECRET,
    REMOVED_SECRET2. Include **common misspellings** (e.g., \REMOVED_SECRETearbuds\REMOVED_SECRET → \REMOVED_SECRETairbuds\REMOVED_SECRET).\nREMOVED_SECRET,
    REMOVED_SECRET3. Add **technical/layman variants** (e.g., \REMOVED_SECRET4K TV\REMOVED_SECRET → \REMOVED_SECRETultra HD television\REMOVED_SECRET).\nREMOVED_SECRET,
    REMOVED_SECRET4. For non-English queries, provide **translations/transliterations** if applicable (e.g., \REMOVED_SECRETスマホ\REMOVED_SECRET → \REMOVED_SECRETsmartphone\REMOVED_SECRET).\nREMOVED_SECRET,
    REMOVED_SECRET5. Output in JSON format for easy parsing.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Input Query:** \REMOVED_SECRET{user_query}\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Output Format:**  \nREMOVED_SECRET,
    REMOVED_SECRET{{\nREMOVED_SECRET,
    REMOVED_SECRET  \REMOVED_SECREToriginal_query\REMOVED_SECRET: \REMOVED_SECRET...\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET  \REMOVED_SECRETexpanded_terms\REMOVED_SECRET: [\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRET...\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRET...\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETmisspelling\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRET...\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETtechnical\REMOVED_SECRET}}\nREMOVED_SECRET,
    REMOVED_SECRET  ]\nREMOVED_SECRET,
    REMOVED_SECRET}}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Example Output for \REMOVED_SECRETwireless headphones\REMOVED_SECRET:**\nREMOVED_SECRET,
    REMOVED_SECRET{{\nREMOVED_SECRET,
    REMOVED_SECRET  \REMOVED_SECREToriginal_query\REMOVED_SECRET: \REMOVED_SECRETwireless headphones\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET  \REMOVED_SECRETexpanded_terms\REMOVED_SECRET: [\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETBluetooth headphones\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETcordless earphones\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETwireless headsets\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETsynonym\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETairbuds\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETmisspelling\REMOVED_SECRET}},\nREMOVED_SECRET,
    REMOVED_SECRET    {{\REMOVED_SECRETterm\REMOVED_SECRET: \REMOVED_SECRETnoise-cancelling headphones\REMOVED_SECRET, \REMOVED_SECRETtype\REMOVED_SECRET: \REMOVED_SECRETtechnical\REMOVED_SECRET}}\nREMOVED_SECRET,
    REMOVED_SECRET  ]\nREMOVED_SECRET,
    REMOVED_SECRET}}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET**Now process this query:** \REMOVED_SECRET{user_query}\REMOVED_SECRET'''\nREMOVED_SECRET,
    REMOVED_SECRET    response = client.chat.completions.create(\nREMOVED_SECRET,
    REMOVED_SECRET        model=\REMOVED_SECRETdeepseek/deepseek-chat-v3-0324:free\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET        messages=[\nREMOVED_SECRET,
    REMOVED_SECRET            {\REMOVED_SECRETrole\REMOVED_SECRET: \REMOVED_SECRETuser\REMOVED_SECRET, \REMOVED_SECRETcontent\REMOVED_SECRET: prompt},\nREMOVED_SECRET,
    REMOVED_SECRET        ],\nREMOVED_SECRET,
    REMOVED_SECRET        temperature=0.3,\nREMOVED_SECRET,
    REMOVED_SECRET    )\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    expanded_queries_raw=response.choices[0].message.content\nREMOVED_SECRET,
    REMOVED_SECRET    if not expanded_queries_raw or expanded_queries_raw.strip() == \REMOVED_SECRET\REMOVED_SECRET:\nREMOVED_SECRET,
    REMOVED_SECRET      raise ValueError(\REMOVED_SECRETAPI returned an empty response\REMOVED_SECRET)\nREMOVED_SECRET,
    REMOVED_SECRET    expanded_queries_raw = re.search(r'```json\\n({.*?})\\n```', expanded_queries_raw, re.DOTALL)\nREMOVED_SECRET,
    REMOVED_SECRET    if expanded_queries_raw:\nREMOVED_SECRET,
    REMOVED_SECRET      expanded_queries_raw = expanded_queries_raw.group(1)\nREMOVED_SECRET,
    REMOVED_SECRET    else:\nREMOVED_SECRET,
    REMOVED_SECRET      expanded_queries_raw = expanded_queries_raw.strip()  # fallback to raw response\nREMOVED_SECRET,
    REMOVED_SECRET      \nREMOVED_SECRET,
    REMOVED_SECRET    #print(expanded_queries_raw)\nREMOVED_SECRET,
    REMOVED_SECRET    expanded_queries=json.loads(expanded_queries_raw)\nREMOVED_SECRET,
    REMOVED_SECRET    return expanded_queriesREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET2840849eREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETThis query should return us an expanded version of the user's original query, accounting for misspellings, vague queries, etcREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 4,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETeafbc2baREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET{'original_query': 'shir long sleeve',\nREMOVED_SECRET,
       REMOVED_SECRET 'expanded_terms': [{'term': 'shirt long sleeve', 'type': 'misspelling'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve shirt', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve t-shirt', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve blouse', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve top', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve tee', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve polo', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve button-up', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve dress shirt', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve casual shirt', 'type': 'synonym'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve henley', 'type': 'technical'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve oxford shirt', 'type': 'technical'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve flannel shirt', 'type': 'technical'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve thermal shirt', 'type': 'technical'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeve knit shirt', 'type': 'technical'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'shirt long sleeved', 'type': 'misspelling'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeved shir', 'type': 'misspelling'},\nREMOVED_SECRET,
       REMOVED_SECRET  {'term': 'long sleeved tshirt', 'type': 'misspelling'}]}REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 4,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETquery=\REMOVED_SECRETshir long sleeve\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#demo with misspelling\nREMOVED_SECRET,
    REMOVED_SECRETexpanded_queries=get_expanded_queries(query)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETexpanded_queriesREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET534d7700REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETWe then rank these expanded queries based on their types, giving the most importance to the original queryREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 5,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET64dd2c27REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#weight the different output types\nREMOVED_SECRET,
    REMOVED_SECRETdef assign_weights(term_type):\nREMOVED_SECRET,
    REMOVED_SECRET    weights = {\nREMOVED_SECRET,
    REMOVED_SECRET        \REMOVED_SECRETsynonym\REMOVED_SECRET: 0.8,\nREMOVED_SECRET,
    REMOVED_SECRET        \REMOVED_SECRETmisspelling\REMOVED_SECRET: 0.3,\nREMOVED_SECRET,
    REMOVED_SECRET        \REMOVED_SECRETtechnical\REMOVED_SECRET: 0.7,\nREMOVED_SECRET,
    REMOVED_SECRET        \REMOVED_SECRETtranslation\REMOVED_SECRET: 0.6\nREMOVED_SECRET,
    REMOVED_SECRET    }\nREMOVED_SECRET,
    REMOVED_SECRET    return weights.get(term_type, 0.5)  #default weight\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef return_weighted_dict(expanded_queries, include_translations): #option to remove translations for certain pipelines\nREMOVED_SECRET,
    REMOVED_SECRET    weighted_terms = [\nREMOVED_SECRET,
    REMOVED_SECRET    {\REMOVED_SECRETterm\REMOVED_SECRET: expanded_queries[\REMOVED_SECREToriginal_query\REMOVED_SECRET], \REMOVED_SECRETweight\REMOVED_SECRET: 1.0}  # Original query (highest priority)\nREMOVED_SECRET,
    REMOVED_SECRET    ]\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    if include_translations:\nREMOVED_SECRET,
    REMOVED_SECRET      for item in expanded_queries[\REMOVED_SECRETexpanded_terms\REMOVED_SECRET]:\nREMOVED_SECRET,
    REMOVED_SECRET          weighted_terms.append({\nREMOVED_SECRET,
    REMOVED_SECRET              \REMOVED_SECRETterm\REMOVED_SECRET: item[\REMOVED_SECRETterm\REMOVED_SECRET],\nREMOVED_SECRET,
    REMOVED_SECRET              \REMOVED_SECRETweight\REMOVED_SECRET: assign_weights(item[\REMOVED_SECRETtype\REMOVED_SECRET])\nREMOVED_SECRET,
    REMOVED_SECRET          })\nREMOVED_SECRET,
    REMOVED_SECRET    else:\nREMOVED_SECRET,
    REMOVED_SECRET       for item in expanded_queries[\REMOVED_SECRETexpanded_terms\REMOVED_SECRET]:\nREMOVED_SECRET,
    REMOVED_SECRET          if item[\REMOVED_SECRETtype\REMOVED_SECRET]!=\REMOVED_SECRETtranslation\REMOVED_SECRET:\nREMOVED_SECRET,
    REMOVED_SECRET            weighted_terms.append({\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETterm\REMOVED_SECRET: item[\REMOVED_SECRETterm\REMOVED_SECRET],\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETweight\REMOVED_SECRET: assign_weights(item[\REMOVED_SECRETtype\REMOVED_SECRET])\nREMOVED_SECRET,
    REMOVED_SECRET            })\nREMOVED_SECRET,
    REMOVED_SECRET    return weighted_termsREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 17,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETeae29f1bREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET[{'term': 'shir long sleeve', 'weight': 1.0},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'shirt long sleeve', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve shirt', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve t-shirt', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve blouse', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve top', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve tee', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve polo', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve button-up', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve dress shirt', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve casual shirt', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve henley', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve oxford shirt', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve flannel shirt', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve thermal shirt', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeve knit shirt', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'shirt long sleeved', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeved shir', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': 'long sleeved tshirt', 'weight': 0.3}]REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 17,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#demo with the above expansions\nREMOVED_SECRET,
    REMOVED_SECRETweighted_queries=return_weighted_dict(expanded_queries, include_translations=False)\nREMOVED_SECRET,
    REMOVED_SECRETweighted_queriesREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETff99aecaREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### Step 2: Fine-tuning of mBART model\nREMOVED_SECRET,
    REMOVED_SECRETWe first fine-tune an mBART model on our spanish, italian and chinese dataset to carry out our machine translation task. The code for fine-tuning can be found at finetune.py, while the model is saved in ./finalREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0e4d7643REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### Step 3: Machine Translation of expanded queries\nREMOVED_SECRET,
    REMOVED_SECRETWe then translate these queries using our finetuned mBART model. Similarly, this is implemented in translate.py but showcased here. REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 15,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET97a7137aREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETimport torch\nREMOVED_SECRET,
    REMOVED_SECRETfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETlang_code_map = {\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRETen\REMOVED_SECRET: \REMOVED_SECRETen_XX\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRETes\REMOVED_SECRET: \REMOVED_SECRETes_XX\REMOVED_SECRET,\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRETit\REMOVED_SECRET: \REMOVED_SECRETit_IT\REMOVED_SECRET, \nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRETcn\REMOVED_SECRET: \REMOVED_SECRETzh_CN\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#function to load model and tokenizer\nREMOVED_SECRET,
    REMOVED_SECRETdef load_model_and_tokenizer(model_path):\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRETLoad the model and tokenizer from the saved checkpoint\REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    model = MBartForConditionalGeneration.from_pretrained(model_path)\nREMOVED_SECRET,
    REMOVED_SECRET    tokenizer = MBart50TokenizerFast.from_pretrained(model_path)\nREMOVED_SECRET,
    REMOVED_SECRET    return model, tokenizer\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#translation function.\nREMOVED_SECRET,
    REMOVED_SECRETdef translate_sentence(model, tokenizer, text, src_lang, tgt_lang):\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRETTranslate a single sentence\REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    # Set source and target languages\nREMOVED_SECRET,
    REMOVED_SECRET    tokenizer.src_lang = lang_code_map[src_lang]\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Tokenize input\nREMOVED_SECRET,
    REMOVED_SECRET    inputs = tokenizer(text, return_tensors=\REMOVED_SECRETpt\REMOVED_SECRET, padding=True, truncation=True, max_length=64)\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Generate translation\nREMOVED_SECRET,
    REMOVED_SECRET    with torch.no_grad():\nREMOVED_SECRET,
    REMOVED_SECRET        outputs = model.generate(\nREMOVED_SECRET,
    REMOVED_SECRET            **inputs,\nREMOVED_SECRET,
    REMOVED_SECRET            forced_bos_token_id=tokenizer.lang_code_to_id[lang_code_map[tgt_lang]],\nREMOVED_SECRET,
    REMOVED_SECRET            max_length=64,\nREMOVED_SECRET,
    REMOVED_SECRET            num_beams=4,\nREMOVED_SECRET,
    REMOVED_SECRET            early_stopping=True,\nREMOVED_SECRET,
    REMOVED_SECRET            no_repeat_ngram_size=3,  # Prevent repeating n-grams\nREMOVED_SECRET,
    REMOVED_SECRET            repetition_penalty=2.0,   # Penalize repetition\nREMOVED_SECRET,
    REMOVED_SECRET            length_penalty=1.0,       # Balance between length and score\nREMOVED_SECRET,
    REMOVED_SECRET            temperature=0.7,          # Control randomness\nREMOVED_SECRET,
    REMOVED_SECRET            do_sample=True           # Enable sampling\nREMOVED_SECRET,
    REMOVED_SECRET        )\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET     # Decode the output\nREMOVED_SECRET,
    REMOVED_SECRET    translation = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\nREMOVED_SECRET,
    REMOVED_SECRET    return translation\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef translate_expanded(model, tokenizer, query_list, src_lang, tgt_lang):\nREMOVED_SECRET,
    REMOVED_SECRET    for query in query_list:\nREMOVED_SECRET,
    REMOVED_SECRET        query['term']=translate_sentence(model, tokenizer, query['term'], src_lang, tgt_lang)\nREMOVED_SECRET,
    REMOVED_SECRET    return query_list\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 18,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET7ab51c82REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#demo using expanded queries\nREMOVED_SECRET,
    REMOVED_SECRETtgt_lang='cn'\nREMOVED_SECRET,
    REMOVED_SECRETmodel, tokenizer = load_model_and_tokenizer(\REMOVED_SECRET./final\REMOVED_SECRET)\nREMOVED_SECRET,
    REMOVED_SECRETweighted_queries = translate_expanded(model, tokenizer, weighted_queries, 'en', tgt_lang)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 20,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETd70da652REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET[{'term': '雪龍袖', 'weight': 1.0},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '衬衫長袖', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖衬衫', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖t恤衫', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖 blouse', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖上衣', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖 tee', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖保羅', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖上扣', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖裙衫', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖休闲衣', 'weight': 0.8},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖亨利', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖牛仔衫', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖flannel衬衫', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖熱帶衫', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖編織衬衫', 'weight': 0.7},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '衬衫長袖', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖雪子', 'weight': 0.3},\nREMOVED_SECRET,
       REMOVED_SECRET {'term': '長袖tshirt', 'weight': 0.3}]REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 20,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETweighted_queriesREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET08e461d7REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET### Step 4: Hybrid Search of expanded queries\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETc29f5054REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#### 4.1 Data LoadingREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 9,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET34946e9bREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#returns a dicitonary of dfs\nREMOVED_SECRET,
    REMOVED_SECRETimport pandas as pd\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef get_data(data_paths):\nREMOVED_SECRET,
    REMOVED_SECRET    data = {} \nREMOVED_SECRET,
    REMOVED_SECRET    for lang, path in data_paths.items():\nREMOVED_SECRET,
    REMOVED_SECRET        data[lang]=pd.read_pickle(path)\nREMOVED_SECRET,
    REMOVED_SECRET    return dataREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 10,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETcfe4b66fREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETdata_paths={'cn':'en_to_cn_embeddings.pkl', 'es':'en_to_sp_embeddings.pkl', 'it':'en_to_it_embeddings.pkl'}\nREMOVED_SECRET,
    REMOVED_SECRETdata = get_data(data_paths)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETba0ccbfaREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#### BM25 SearchREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 11,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET84d6a6d8REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom rank_bm25 import BM25Okapi\nREMOVED_SECRET,
    REMOVED_SECRETimport pandas as pd\nREMOVED_SECRET,
    REMOVED_SECRETimport jiebaREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 12,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETfebd1b38REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#Build BM_25 corpus\nREMOVED_SECRET,
    REMOVED_SECRETdef build_BM25(data):\nREMOVED_SECRET,
    REMOVED_SECRET    #cn\nREMOVED_SECRET,
    REMOVED_SECRET    entocn_chinese_titles = data['cn']['chinese translation']\nREMOVED_SECRET,
    REMOVED_SECRET    entocn_tokenized_cn = [list(jieba.cut_for_search(title.lower())) for title in entocn_chinese_titles]\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_cn = BM25Okapi(entocn_tokenized_cn)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #es\nREMOVED_SECRET,
    REMOVED_SECRET    entoes_spanish_titles = data['es']['title_spanish']\nREMOVED_SECRET,
    REMOVED_SECRET    entoes_tokenized_es = [title.split() for title in entoes_spanish_titles]\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_es = BM25Okapi(entoes_tokenized_es)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #it\nREMOVED_SECRET,
    REMOVED_SECRET    entoit_italian_titles = data['it']['title_italian']\nREMOVED_SECRET,
    REMOVED_SECRET    entoit_tokenized_it = [title.split() for title in entoit_italian_titles]\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_it = BM25Okapi(entoit_tokenized_it)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_corpus={'cn':bm25_cn, 'es':bm25_es, 'it':bm25_it}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return bm25_corpus\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#Search BM25\nREMOVED_SECRET,
    REMOVED_SECRETdef search_bm25_expanded(query_list, corpus, tgt_lang='cn', top_k=5):\nREMOVED_SECRET,
    REMOVED_SECRET    #init scores as zeros\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    scores = [0.0] * len(corpus[tgt_lang].doc_len)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    for query_dict in query_list:\nREMOVED_SECRET,
    REMOVED_SECRET        term=query_dict['term']\nREMOVED_SECRET,
    REMOVED_SECRET        weight=query_dict['weight']\nREMOVED_SECRET,
    REMOVED_SECRET        if tgt_lang=='cn':\nREMOVED_SECRET,
    REMOVED_SECRET            tokens=jieba.cut_for_search(term.lower())\nREMOVED_SECRET,
    REMOVED_SECRET            term_scores = corpus[tgt_lang].get_scores(tokens)        \nREMOVED_SECRET,
    REMOVED_SECRET        else:\nREMOVED_SECRET,
    REMOVED_SECRET            tokens = term.lower().split()\nREMOVED_SECRET,
    REMOVED_SECRET            term_scores = corpus[tgt_lang].get_scores(tokens)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET        scores = [s + weight * ts for s, ts in zip(scores, term_scores)]\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    # Get top-k ranked indices\nREMOVED_SECRET,
    REMOVED_SECRET    top_k_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\nREMOVED_SECRET,
    REMOVED_SECRET    return top_k_ids, [scores[i] for i in top_k_ids]REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 13,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETb556de8bREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstderrREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRETBuilding prefix dict from the default dictionary ...\nREMOVED_SECRET,
      REMOVED_SECRETLoading model from cache C:\\Users\\liuru\\AppData\\Local\\Temp\\jieba.cache\nREMOVED_SECRET,
      REMOVED_SECRETLoading model cost 0.491 seconds.\nREMOVED_SECRET,
      REMOVED_SECRETPrefix dict has been built successfully.\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETbm25_corpus = build_BM25(data)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 21,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET9c4f4687REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETtop_ids, top_scores = search_bm25_expanded(weighted_queries, bm25_corpus)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 22,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETdcceebfaREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET141.3012 | Polo Shirt Classic Denim Pocket Long Sleeve Shirt  | Polo衫 經典丹寧 口袋長袖襯衫\nREMOVED_SECRET,
      REMOVED_SECRET112.8441 | Kids Set Table Bay - Thin Long Sleeve Home Suit Magic Baby ~ K60092  | 兒童套裝 台灣製薄長袖居家套裝 魔法Baby~k60092\nREMOVED_SECRET,
      REMOVED_SECRET88.6328 | GAP Kids Long Sleeve Logo Patch Top  | GAP 童裝長袖Logo貼布上衣\nREMOVED_SECRET,
      REMOVED_SECRET71.6278 | Long version Pocket Cardigan Knit Coat  | 長版口袋開襟針織外套\nREMOVED_SECRET,
      REMOVED_SECRET65.9903 | IFairies large size long sleeve T shirt Tops ifairies [59000] 【 59000 】  | iFairies 中大尺碼長袖T恤上衣★ifairies【59000】【59000】\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#remember our original search was 'shir long sleeve', mispelled on purpose.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETfor i, score in zip(top_ids, top_scores):\nREMOVED_SECRET,
    REMOVED_SECRET    print(f\REMOVED_SECRET{score:.4f} | {data['cn']['title'][i]}  | {data['cn']['chinese translation'][i]}\REMOVED_SECRET)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET1f994cf4REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#### Dense SearchREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 23,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETdf47839dREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom sentence_transformers import SentenceTransformer\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETmodel = SentenceTransformer(\REMOVED_SECRETBAAI/bge-m3\REMOVED_SECRET)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 44,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET8e0843e0REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom pinecone import Pinecone\nREMOVED_SECRET,
    REMOVED_SECRETfrom pinecone import ServerlessSpec\nREMOVED_SECRET,
    REMOVED_SECRETfrom dotenv import load_dotenv\nREMOVED_SECRET,
    REMOVED_SECRETimport os\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET#Embeds a dense embedding representing the weighted mean of the expanded queries\nREMOVED_SECRET,
    REMOVED_SECRETdef embed_expanded(query_list, model):\nREMOVED_SECRET,
    REMOVED_SECRET    query_embeddings= []\nREMOVED_SECRET,
    REMOVED_SECRET    #embed expanded queries\nREMOVED_SECRET,
    REMOVED_SECRET    for query_dict in query_list:\nREMOVED_SECRET,
    REMOVED_SECRET        embedding=model.encode(query_dict['term'],  convert_to_tensor=True).cpu().numpy() #size1024\nREMOVED_SECRET,
    REMOVED_SECRET        query_embeddings.append(embedding * query_dict[\REMOVED_SECRETweight\REMOVED_SECRET])\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    query_embedding = sum(query_embeddings) / len(query_embeddings)  # Weighted mean\nREMOVED_SECRET,
    REMOVED_SECRET    return query_embedding\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef init_index(pc, index_name, data, embedding_col, eng_col, tgt_col, tgt_lang):\nREMOVED_SECRET,
    REMOVED_SECRET    index_name = index_name\nREMOVED_SECRET,
    REMOVED_SECRET    dimension = 1024\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    if index_name not in pc.list_indexes().names():\nREMOVED_SECRET,
    REMOVED_SECRET        pc.create_index(\nREMOVED_SECRET,
    REMOVED_SECRET            name=index_name,\nREMOVED_SECRET,
    REMOVED_SECRET            dimension=dimension,\nREMOVED_SECRET,
    REMOVED_SECRET            metric=\REMOVED_SECRETcosine\REMOVED_SECRET,  # by cosine similarity\nREMOVED_SECRET,
    REMOVED_SECRET            spec=ServerlessSpec(\nREMOVED_SECRET,
    REMOVED_SECRET                cloud=\REMOVED_SECRETaws\REMOVED_SECRET,  # or \REMOVED_SECRETgcp\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET                region=\REMOVED_SECRETus-east-1\REMOVED_SECRET \nREMOVED_SECRET,
    REMOVED_SECRET            )\nREMOVED_SECRET,
    REMOVED_SECRET        )\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    index = pc.Index(index_name)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    vectors_to_upsert = []\nREMOVED_SECRET,
    REMOVED_SECRET    for _, row in data.iterrows():\nREMOVED_SECRET,
    REMOVED_SECRET        vectors_to_upsert.append({\nREMOVED_SECRET,
    REMOVED_SECRET            \REMOVED_SECRETid\REMOVED_SECRET: str(_),  # Use index or generate unique IDs\nREMOVED_SECRET,
    REMOVED_SECRET            \REMOVED_SECRETvalues\REMOVED_SECRET: row[embedding_col],  # Using Chinese embeddings\nREMOVED_SECRET,
    REMOVED_SECRET            \REMOVED_SECRETmetadata\REMOVED_SECRET: {\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETtitle\REMOVED_SECRET: row[eng_col],\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETchinese_title\REMOVED_SECRET: row[tgt_col],\nREMOVED_SECRET,
    REMOVED_SECRET                \REMOVED_SECRETembedding_type\REMOVED_SECRET: tgt_lang  # Track which embedding was used\nREMOVED_SECRET,
    REMOVED_SECRET            }\nREMOVED_SECRET,
    REMOVED_SECRET        })\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    for i in range(0, len(vectors_to_upsert), 100):\nREMOVED_SECRET,
    REMOVED_SECRET        index.upsert(vectors=vectors_to_upsert[i:i+100])\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef setup_pinecone(data):\nREMOVED_SECRET,
    REMOVED_SECRET    load_dotenv(dotenv_path='../.env')\nREMOVED_SECRET,
    REMOVED_SECRET    pinecone_api_key = os.getenv('pinecone_API_KEY')\nREMOVED_SECRET,
    REMOVED_SECRET    pc = Pinecone(api_key=pinecone_api_key)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    data = data\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    indexes={'cn':'cn-search', 'it':'it-search', 'es':'es-search'}\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #setup cn\nREMOVED_SECRET,
    REMOVED_SECRET    init_index(pc, index_name=indexes['cn'], data=data['cn'],\nREMOVED_SECRET,
    REMOVED_SECRET     embedding_col='chinese_embedding',\nREMOVED_SECRET,
    REMOVED_SECRET     eng_col='title',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_col='chinese translation',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_lang='chinese')\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #setup it\nREMOVED_SECRET,
    REMOVED_SECRET    init_index(pc, index_name=indexes['it'], data=data['it'],\nREMOVED_SECRET,
    REMOVED_SECRET     embedding_col='italian_embedding',\nREMOVED_SECRET,
    REMOVED_SECRET     eng_col='title',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_col='title_italian',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_lang='italian')\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #setup es\nREMOVED_SECRET,
    REMOVED_SECRET    init_index(pc, index_name=indexes['es'], data=data['es'],\nREMOVED_SECRET,
    REMOVED_SECRET     embedding_col='spanish_embedding',\nREMOVED_SECRET,
    REMOVED_SECRET     eng_col='title',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_col='title_spanish',\nREMOVED_SECRET,
    REMOVED_SECRET     tgt_lang='spanish')\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return indexes\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef search_pinecone(query_list, embedding_model, index_name, top_k=5):\nREMOVED_SECRET,
    REMOVED_SECRET    load_dotenv(dotenv_path='../.env')\nREMOVED_SECRET,
    REMOVED_SECRET    pinecone_api_key = os.getenv('pinecone_API_KEY')\nREMOVED_SECRET,
    REMOVED_SECRET    pc = Pinecone(api_key=pinecone_api_key)\nREMOVED_SECRET,
    REMOVED_SECRET    index = pc.Index(index_name)\nREMOVED_SECRET,
    REMOVED_SECRET    query_embedding=embed_expanded(query_list, embedding_model)\nREMOVED_SECRET,
    REMOVED_SECRET    results = index.query(\nREMOVED_SECRET,
    REMOVED_SECRET            vector=query_embedding.tolist(),\nREMOVED_SECRET,
    REMOVED_SECRET            top_k=top_k,\nREMOVED_SECRET,
    REMOVED_SECRET            include_metadata=False\nREMOVED_SECRET,
    REMOVED_SECRET        )\nREMOVED_SECRET,
    REMOVED_SECRET    id_list = []\nREMOVED_SECRET,
    REMOVED_SECRET    score_list = []\nREMOVED_SECRET,
    REMOVED_SECRET    for dict in results.matches:\nREMOVED_SECRET,
    REMOVED_SECRET        id_list.append(int(dict['id']))\nREMOVED_SECRET,
    REMOVED_SECRET        score_list.append(float(dict['score']))\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return id_list, score_list\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 25,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0f7a2022REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETpinecone_indices=setup_pinecone(data)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 45,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0efad315REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETtop_ids_pc, top_scores_pc =search_pinecone(weighted_queries, model, pinecone_indices['cn'])REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 47,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET0cf11e39REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET0.7519 | Long version Pocket Cardigan Knit Coat  | 長版口袋開襟針織外套\nREMOVED_SECRET,
      REMOVED_SECRET0.7019 | Polo Shirt Classic Denim Pocket Long Sleeve Shirt  | Polo衫 經典丹寧 口袋長袖襯衫\nREMOVED_SECRET,
      REMOVED_SECRET0.6916 | Shiny Glossy Long Edition Perspective Shirt  | 閃亮光澤長版透視襯衫\nREMOVED_SECRET,
      REMOVED_SECRET0.6759 | Korean Made. Thick Straps Cross Vest  | 韩制。粗肩带交叉背心\nREMOVED_SECRET,
      REMOVED_SECRET0.6581 | IFairies large size long sleeve T shirt Tops ifairies [59000] 【 59000 】  | iFairies 中大尺碼長袖T恤上衣★ifairies【59000】【59000】\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#remember our original search was 'shir long sleeve', mispelled on purpose.\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETfor i, score in zip(top_ids_pc, top_scores_pc):\nREMOVED_SECRET,
    REMOVED_SECRET    print(f\REMOVED_SECRET{score:.4f} | {data['cn']['title'][i]}  | {data['cn']['chinese translation'][i]}\REMOVED_SECRET)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETmarkdownREMOVED_SECRET,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET7690b596REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#### RRFREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 31,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETa085a8b8REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET[656, 996, 701, 276, 418] [141.30117982812962, 112.84411227054272, 88.63276428673784, 71.6278067714302, 65.99026659028007]\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#recap: Right now, we have BM25 results, returned as\nREMOVED_SECRET,
    REMOVED_SECRETprint(top_ids, top_scores)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 48,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETb655385fREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET[276, 656, 134, 76, 418] [0.7518996, 0.701878309, 0.691553712, 0.675868392, 0.658072412]\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRET#recap: We also have semantic results, returned as\nREMOVED_SECRET,
    REMOVED_SECRETprint(top_ids_pc, top_scores_pc)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: null,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET64a460d6REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETimport numpy as np\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef scores_to_ranking(scores: list[float]) -> list[int]:\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRETConvert float scores into int rankings (1 = best).\REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return np.argsort(scores)[::-1] + 1  # ranks start at 1\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef rrf(keyword_rank: int, semantic_rank: int, k: int = 60) -> float:\nREMOVED_SECRET,
    REMOVED_SECRET    \REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRETCombine keyword rank and semantic rank into a hybrid score using RRF.\REMOVED_SECRET\REMOVED_SECRET\REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    return 1 / (k + keyword_rank) + 1 / (k + semantic_rank)\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 58,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETf4b0b516REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETdef hybrid_expanded_search(query_list, bm25_corpus, pinecone_indices, embedding_model, tgt_lang='cn', top_k=5 ):\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_top_ids, bm25_top_scores = search_bm25_expanded(query_list, bm25_corpus, top_k=top_k)\nREMOVED_SECRET,
    REMOVED_SECRET    pc_top_ids, pc_top_scores =search_pinecone(query_list, embedding_model, pinecone_indices[tgt_lang], top_k=top_k)\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_ranks = scores_to_ranking(bm25_top_scores)\nREMOVED_SECRET,
    REMOVED_SECRET    pc_ranks = scores_to_ranking(pc_top_scores)\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    # Create dictionaries for quick rank lookup\nREMOVED_SECRET,
    REMOVED_SECRET    bm25_rank_dict = {doc_id: rank for doc_id, rank in zip(bm25_top_ids, bm25_ranks)}\nREMOVED_SECRET,
    REMOVED_SECRET    pc_rank_dict = {doc_id: rank for doc_id, rank in zip(pc_top_ids, pc_ranks)}\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Combine all unique document IDs from both methods\nREMOVED_SECRET,
    REMOVED_SECRET    all_doc_ids = list(set(bm25_top_ids) | set(pc_top_ids))\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Calculate RRF scores for each document\nREMOVED_SECRET,
    REMOVED_SECRET    rrf_scores = []\nREMOVED_SECRET,
    REMOVED_SECRET    for doc_id in all_doc_ids:\nREMOVED_SECRET,
    REMOVED_SECRET        # Get ranks from each method (use a high rank if document not found)\nREMOVED_SECRET,
    REMOVED_SECRET        bm25_rank = bm25_rank_dict.get(doc_id, top_k * 2)  # Penalize missing documents\nREMOVED_SECRET,
    REMOVED_SECRET        pc_rank = pc_rank_dict.get(doc_id, top_k * 2)\nREMOVED_SECRET,
    REMOVED_SECRET        \nREMOVED_SECRET,
    REMOVED_SECRET        # Calculate combined RRF score\nREMOVED_SECRET,
    REMOVED_SECRET        score = rrf(bm25_rank, pc_rank)\nREMOVED_SECRET,
    REMOVED_SECRET        rrf_scores.append((doc_id, score))\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Sort documents by RRF score (descending)\nREMOVED_SECRET,
    REMOVED_SECRET    rrf_scores.sort(key=lambda x: -x[1])\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    # Extract the top_k document IDs\nREMOVED_SECRET,
    REMOVED_SECRET    #hybrid_top_ids = [doc_id for doc_id, score in rrf_scores[:top_k]]\nREMOVED_SECRET,
    REMOVED_SECRET    hybrid_top_ids = [doc_id for doc_id, score in rrf_scores]\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET    #hybrid_top_scores = [score for doc_id, score in rrf_scores[:top_k]]\nREMOVED_SECRET,
    REMOVED_SECRET    hybrid_top_scores = [score for doc_id, score in rrf_scores]\nREMOVED_SECRET,
    REMOVED_SECRET    \nREMOVED_SECRET,
    REMOVED_SECRET    return hybrid_top_ids, hybrid_top_scores\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 59,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET43bd0e40REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECREThybrid_top_id, hybrid_top_scores=hybrid_expanded_search(weighted_queries, bm25_corpus, pinecone_indices, model)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 60,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET3cf19797REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstdoutREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRET0.0325 | Polo Shirt Classic Denim Pocket Long Sleeve Shirt  | Polo衫 經典丹寧 口袋長袖襯衫\nREMOVED_SECRET,
      REMOVED_SECRET0.0320 | Long version Pocket Cardigan Knit Coat  | 長版口袋開襟針織外套\nREMOVED_SECRET,
      REMOVED_SECRET0.0308 | IFairies large size long sleeve T shirt Tops ifairies [59000] 【 59000 】  | iFairies 中大尺碼長袖T恤上衣★ifairies【59000】【59000】\nREMOVED_SECRET,
      REMOVED_SECRET0.0304 | Kids Set Table Bay - Thin Long Sleeve Home Suit Magic Baby ~ K60092  | 兒童套裝 台灣製薄長袖居家套裝 魔法Baby~k60092\nREMOVED_SECRET,
      REMOVED_SECRET0.0302 | Shiny Glossy Long Edition Perspective Shirt  | 閃亮光澤長版透視襯衫\nREMOVED_SECRET,
      REMOVED_SECRET0.0302 | GAP Kids Long Sleeve Logo Patch Top  | GAP 童裝長袖Logo貼布上衣\nREMOVED_SECRET,
      REMOVED_SECRET0.0299 | Korean Made. Thick Straps Cross Vest  | 韩制。粗肩带交叉背心\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfor i, score in zip(hybrid_top_id, hybrid_top_scores):\nREMOVED_SECRET,
    REMOVED_SECRET    print(f\REMOVED_SECRET{score:.4f} | {data['cn']['title'][i]}  | {data['cn']['chinese translation'][i]}\REMOVED_SECRET)REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 75,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET48db3d24REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfrom bert_score import score\nREMOVED_SECRET,
    REMOVED_SECRETimport warnings\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef calculate_bertscore(candidate, reference, lang = \REMOVED_SECRETen\REMOVED_SECRET):\nREMOVED_SECRET,
    REMOVED_SECRET    with warnings.catch_warnings():\nREMOVED_SECRET,
    REMOVED_SECRET        warnings.simplefilter(\REMOVED_SECRETignore\REMOVED_SECRET)\nREMOVED_SECRET,
    REMOVED_SECRET        # Compute scores\nREMOVED_SECRET,
    REMOVED_SECRET        P, R, F1 = score(\nREMOVED_SECRET,
    REMOVED_SECRET            [candidate], \nREMOVED_SECRET,
    REMOVED_SECRET            [reference], \nREMOVED_SECRET,
    REMOVED_SECRET            lang=lang,\nREMOVED_SECRET,
    REMOVED_SECRET            model_type=\REMOVED_SECRETbert-base-multilingual-cased\REMOVED_SECRET,  # Multilingual BERT\nREMOVED_SECRET,
    REMOVED_SECRET            verbose=False  # Disable progress messages\nREMOVED_SECRET,
    REMOVED_SECRET        )\nREMOVED_SECRET,
    REMOVED_SECRET    return P.item(), R.item(), F1.item()\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRETdef get_final_output(query, hybrid_top_id, data, tgt_lang='cn'):\nREMOVED_SECRET,
    REMOVED_SECRET    final_output={}\nREMOVED_SECRET,
    REMOVED_SECRET    for ids in hybrid_top_id:\nREMOVED_SECRET,
    REMOVED_SECRET        if tgt_lang=='cn':\nREMOVED_SECRET,
    REMOVED_SECRET            txt=data[tgt_lang]['chinese translation'][ids]\nREMOVED_SECRET,
    REMOVED_SECRET        elif tgt_lang=='es':\nREMOVED_SECRET,
    REMOVED_SECRET            txt=data[tgt_lang]['title_spanish'][ids]\nREMOVED_SECRET,
    REMOVED_SECRET        elif tgt_lang=='it':\nREMOVED_SECRET,
    REMOVED_SECRET            txt=data[tgt_lang]['title_italian'][ids]\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET,
    REMOVED_SECRET        acc, precision, f1 = calculate_bertscore(txt, query)\nREMOVED_SECRET,
    REMOVED_SECRET        final_output[txt]=f1\nREMOVED_SECRET,
    REMOVED_SECRET    return final_output\nREMOVED_SECRET,
    REMOVED_SECRET\nREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 76,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETa8a504f8REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETquery=\REMOVED_SECRETshir long sleeve\REMOVED_SECRETREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 77,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETb9f01fb5REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETstderrREMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETstreamREMOVED_SECRET,
     REMOVED_SECRETtextREMOVED_SECRET: [
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET,
      REMOVED_SECRETSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\nREMOVED_SECRET,
      REMOVED_SECRET- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\nREMOVED_SECRET,
      REMOVED_SECRET- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfinal_output = get_final_output(query, hybrid_top_id, data, tgt_lang='cn')REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: 74,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET5c580dc6REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETdataREMOVED_SECRET: {
      REMOVED_SECRETtext/plainREMOVED_SECRET: [
       REMOVED_SECRET{'Polo衫 經典丹寧 口袋長袖襯衫': 0.6623846292495728,\nREMOVED_SECRET,
       REMOVED_SECRET '長版口袋開襟針織外套': 0.6716357469558716,\nREMOVED_SECRET,
       REMOVED_SECRET 'iFairies 中大尺碼長袖T恤上衣★ifairies【59000】【59000】': 0.6212053894996643,\nREMOVED_SECRET,
       REMOVED_SECRET '兒童套裝 台灣製薄長袖居家套裝 魔法Baby~k60092': 0.6144145727157593,\nREMOVED_SECRET,
       REMOVED_SECRET '閃亮光澤長版透視襯衫': 0.6694958806037903,\nREMOVED_SECRET,
       REMOVED_SECRET 'GAP 童裝長袖Logo貼布上衣': 0.659843921661377,\nREMOVED_SECRET,
       REMOVED_SECRET '韩制。粗肩带交叉背心': 0.655915379524231}REMOVED_SECRET
      ]
     },
     REMOVED_SECRETexecution_countREMOVED_SECRET: 74,
     REMOVED_SECRETmetadataREMOVED_SECRET: {},
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETexecute_resultREMOVED_SECRET
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETfinal_outputREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: null,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETa0872cfdREMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETimport torch\nREMOVED_SECRET,
    REMOVED_SECRETfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\nREMOVED_SECRET,
    REMOVED_SECRETimport argparse\nREMOVED_SECRET,
    REMOVED_SECRETfrom dotenv import load_dotenv\nREMOVED_SECRET,
    REMOVED_SECRETimport os\nREMOVED_SECRET,
    REMOVED_SECRETfrom translate import load_model_and_tokenizer, translate_sentence\nREMOVED_SECRET,
    REMOVED_SECRETfrom queryexpansion import expand\nREMOVED_SECRET,
    REMOVED_SECRETfrom langdetect import detect\nREMOVED_SECRET,
    REMOVED_SECRETimport jiebaREMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: null,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRETda627ba2REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [
    {
     REMOVED_SECRETenameREMOVED_SECRET: REMOVED_SECRETSyntaxErrorREMOVED_SECRET,
     REMOVED_SECRETevalueREMOVED_SECRET: REMOVED_SECRETinvalid syntax (2893126158.py, line 6)REMOVED_SECRET,
     REMOVED_SECREToutput_typeREMOVED_SECRET: REMOVED_SECRETerrorREMOVED_SECRET,
     REMOVED_SECRETtracebackREMOVED_SECRET: [
      REMOVED_SECRET\u001b[1;36m  Cell \u001b[1;32mIn[5], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    for query in\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\nREMOVED_SECRET
     ]
    }
   ],
   REMOVED_SECRETsourceREMOVED_SECRET: [
    REMOVED_SECRETdef mtpipeline(input_query, tgt_lang=\REMOVED_SECRETcn\REMOVED_SECRET):\nREMOVED_SECRET,
    REMOVED_SECRET    load_dotenv(dotenv_path='..../.env')\nREMOVED_SECRET,
    REMOVED_SECRET    model_path = os.getenv('mBART_path')\nREMOVED_SECRET,
    REMOVED_SECRET    model, tokenizer = load_model_and_tokenizer(model_path)\nREMOVED_SECRET,
    REMOVED_SECRET    input_query_expanded=expand(input_query, include_translations=False)\nREMOVED_SECRET,
    REMOVED_SECRET    for query in input_query_expanded:\nREMOVED_SECRET,
    REMOVED_SECRET        query['term']=translate_sentence(model, tokenizer, query['term'], 'en', tgt_lang)\nREMOVED_SECRET,
    REMOVED_SECRET    REMOVED_SECRET
   ]
  },
  {
   REMOVED_SECRETcell_typeREMOVED_SECRET: REMOVED_SECRETcodeREMOVED_SECRET,
   REMOVED_SECRETexecution_countREMOVED_SECRET: null,
   REMOVED_SECRETidREMOVED_SECRET: REMOVED_SECRET2546c887REMOVED_SECRET,
   REMOVED_SECRETmetadataREMOVED_SECRET: {},
   REMOVED_SECREToutputsREMOVED_SECRET: [],
   REMOVED_SECRETsourceREMOVED_SECRET: []
  }
 ],
 REMOVED_SECRETmetadataREMOVED_SECRET: {
  REMOVED_SECRETkernelspecREMOVED_SECRET: {
   REMOVED_SECRETdisplay_nameREMOVED_SECRET: REMOVED_SECRETtensorflow_baseREMOVED_SECRET,
   REMOVED_SECRETlanguageREMOVED_SECRET: REMOVED_SECRETpythonREMOVED_SECRET,
   REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETpython3REMOVED_SECRET
  },
  REMOVED_SECRETlanguage_infoREMOVED_SECRET: {
   REMOVED_SECRETcodemirror_modeREMOVED_SECRET: {
    REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETipythonREMOVED_SECRET,
    REMOVED_SECRETversionREMOVED_SECRET: 3
   },
   REMOVED_SECRETfile_extensionREMOVED_SECRET: REMOVED_SECRET.pyREMOVED_SECRET,
   REMOVED_SECRETmimetypeREMOVED_SECRET: REMOVED_SECRETtext/x-pythonREMOVED_SECRET,
   REMOVED_SECRETnameREMOVED_SECRET: REMOVED_SECRETpythonREMOVED_SECRET,
   REMOVED_SECRETnbconvert_exporterREMOVED_SECRET: REMOVED_SECRETpythonREMOVED_SECRET,
   REMOVED_SECRETpygments_lexerREMOVED_SECRET: REMOVED_SECRETipython3REMOVED_SECRET,
   REMOVED_SECRETversionREMOVED_SECRET: REMOVED_SECRET3.10.11REMOVED_SECRET
  }
 },
 REMOVED_SECRETnbformatREMOVED_SECRET: 4,
 REMOVED_SECRETnbformat_minorREMOVED_SECRET: 5
}
