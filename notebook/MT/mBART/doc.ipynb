{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9ae35d",
   "metadata": {},
   "source": [
    "# Overview of MT Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ff736",
   "metadata": {},
   "source": [
    "### Step 1: Query Expansion CODE LOCATED IN queryexpansion.py\n",
    "We first use DeepSeek v3 to carry out query expansion on our queries. This is implemented as a function in queryexpansion.py, but will be demonstrated here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab33f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "#load API key\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "api_key = os.getenv('deepseek_API_KEY')\n",
    "\n",
    "#set up connection\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c12d4",
   "metadata": {},
   "source": [
    "We define a function to expand our query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fe9f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expanded_queries(user_query):\n",
    "    prompt=f'''You are an expert search query optimizer. Your task is to expand the following e-commerce search query to improve retrieval of relevant products. Generate a list of semantically related terms, synonyms, and common user variations while preserving the original intent.\n",
    "\n",
    "**Rules:**\n",
    "1. Prioritize **contextual relevance** (e.g., \"running shoes\" → \"jogging sneakers\").\n",
    "2. Include **common misspellings** (e.g., \"earbuds\" → \"airbuds\").\n",
    "3. Add **technical/layman variants** (e.g., \"4K TV\" → \"ultra HD television\").\n",
    "4. For non-English queries, provide **translations/transliterations** if applicable (e.g., \"スマホ\" → \"smartphone\").\n",
    "5. Output in JSON format for easy parsing.\n",
    "\n",
    "**Input Query:** \"{user_query}\"\n",
    "\n",
    "**Output Format:**  \n",
    "{{\n",
    "  \"original_query\": \"...\",\n",
    "  \"expanded_terms\": [\n",
    "    {{\"term\": \"...\", \"type\": \"synonym\"}},\n",
    "    {{\"term\": \"...\", \"type\": \"misspelling\"}},\n",
    "    {{\"term\": \"...\", \"type\": \"technical\"}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "**Example Output for \"wireless headphones\":**\n",
    "{{\n",
    "  \"original_query\": \"wireless headphones\",\n",
    "  \"expanded_terms\": [\n",
    "    {{\"term\": \"Bluetooth headphones\", \"type\": \"synonym\"}},\n",
    "    {{\"term\": \"cordless earphones\", \"type\": \"synonym\"}},\n",
    "    {{\"term\": \"wireless headsets\", \"type\": \"synonym\"}},\n",
    "    {{\"term\": \"airbuds\", \"type\": \"misspelling\"}},\n",
    "    {{\"term\": \"noise-cancelling headphones\", \"type\": \"technical\"}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "**Now process this query:** \"{user_query}\"'''\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    print(response) #debug\n",
    "    expanded_queries_raw=response.choices[0].message.content\n",
    "    if not expanded_queries_raw or expanded_queries_raw.strip() == \"\":\n",
    "      raise ValueError(\"API returned an empty response\")\n",
    "    expanded_queries_raw = re.search(r'```json\\n({.*?})\\n```', expanded_queries_raw, re.DOTALL)\n",
    "    if expanded_queries_raw:\n",
    "      expanded_queries_raw = expanded_queries_raw.group(1)\n",
    "    else:\n",
    "      expanded_queries_raw = expanded_queries_raw.strip()  # fallback to raw response\n",
    "      \n",
    "    #print(expanded_queries_raw)\n",
    "    expanded_queries=json.loads(expanded_queries_raw)\n",
    "    return expanded_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2840849e",
   "metadata": {},
   "source": [
    "This query should return us an expanded version of the user's original query, accounting for misspellings, vague queries, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eafbc2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='gen-1745148844-DAke1KpC3PwiP7GkudfC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \"original_query\": \"running shoos\",\\n  \"expanded_terms\": [\\n    {\"term\": \"running shoes\", \"type\": \"misspelling\"},\\n    {\"term\": \"jogging shoes\", \"type\": \"synonym\"},\\n    {\"term\": \"sneakers\", \"type\": \"synonym\"},\\n    {\"term\": \"athletic shoes\", \"type\": \"synonym\"},\\n    {\"term\": \"trainers\", \"type\": \"synonym\"},\\n    {\"term\": \"running sneakers\", \"type\": \"synonym\"},\\n    {\"term\": \"running footwear\", \"type\": \"synonym\"},\\n    {\"term\": \"trail running shoes\", \"type\": \"technical\"},\\n    {\"term\": \"road running shoes\", \"type\": \"technical\"},\\n    {\"term\": \"performance running shoes\", \"type\": \"technical\"},\\n    {\"term\": \"running shooes\", \"type\": \"misspelling\"},\\n    {\"term\": \"runing shoes\", \"type\": \"misspelling\"},\\n    {\"term\": \"runnin shoes\", \"type\": \"misspelling\"},\\n    {\"term\": \"スポーツシューズ\", \"type\": \"translation\"},\\n    {\"term\": \"correr zapatos\", \"type\": \"translation\"}\\n  ]\\n}\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='stop')], created=1745148844, model='deepseek/deepseek-chat-v3-0324', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=273, prompt_tokens=373, total_tokens=646, completion_tokens_details=None, prompt_tokens_details=None), provider='Targon')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'original_query': 'running shoos',\n",
       " 'expanded_terms': [{'term': 'running shoes', 'type': 'misspelling'},\n",
       "  {'term': 'jogging shoes', 'type': 'synonym'},\n",
       "  {'term': 'sneakers', 'type': 'synonym'},\n",
       "  {'term': 'athletic shoes', 'type': 'synonym'},\n",
       "  {'term': 'trainers', 'type': 'synonym'},\n",
       "  {'term': 'running sneakers', 'type': 'synonym'},\n",
       "  {'term': 'running footwear', 'type': 'synonym'},\n",
       "  {'term': 'trail running shoes', 'type': 'technical'},\n",
       "  {'term': 'road running shoes', 'type': 'technical'},\n",
       "  {'term': 'performance running shoes', 'type': 'technical'},\n",
       "  {'term': 'running shooes', 'type': 'misspelling'},\n",
       "  {'term': 'runing shoes', 'type': 'misspelling'},\n",
       "  {'term': 'runnin shoes', 'type': 'misspelling'},\n",
       "  {'term': 'スポーツシューズ', 'type': 'translation'},\n",
       "  {'term': 'correr zapatos', 'type': 'translation'}]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"running shoos\"\n",
    "#demo with misspelling\n",
    "expanded_queries=get_expanded_queries(query)\n",
    "\n",
    "expanded_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d7700",
   "metadata": {},
   "source": [
    "We then rank these expanded queries based on their types, giving the most importance to the original query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64dd2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight the different output types\n",
    "def assign_weights(term_type):\n",
    "    weights = {\n",
    "        \"synonym\": 0.8,\n",
    "        \"misspelling\": 0.3,\n",
    "        \"technical\": 0.7,\n",
    "        \"translation\": 0.6\n",
    "    }\n",
    "    return weights.get(term_type, 0.5)  #default weight\n",
    "\n",
    "def return_weighted_dict(expanded_queries, include_translations): #option to remove translations for certain pipelines\n",
    "    weighted_terms = [\n",
    "    {\"term\": expanded_queries[\"original_query\"], \"weight\": 1.0}  # Original query (highest priority)\n",
    "    ]\n",
    "\n",
    "    if include_translations:\n",
    "      for item in expanded_queries[\"expanded_terms\"]:\n",
    "          weighted_terms.append({\n",
    "              \"term\": item[\"term\"],\n",
    "              \"weight\": assign_weights(item[\"type\"])\n",
    "          })\n",
    "    else:\n",
    "       for item in expanded_queries[\"expanded_terms\"]:\n",
    "          if item[\"type\"]!=\"translation\":\n",
    "            weighted_terms.append({\n",
    "                \"term\": item[\"term\"],\n",
    "                \"weight\": assign_weights(item[\"type\"])\n",
    "            })\n",
    "    return weighted_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eae29f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'term': 'running shoos', 'weight': 1.0},\n",
       " {'term': 'running shoes', 'weight': 0.3},\n",
       " {'term': 'jogging shoes', 'weight': 0.8},\n",
       " {'term': 'sneakers', 'weight': 0.8},\n",
       " {'term': 'athletic shoes', 'weight': 0.8},\n",
       " {'term': 'trainers', 'weight': 0.8},\n",
       " {'term': 'running sneakers', 'weight': 0.8},\n",
       " {'term': 'running footwear', 'weight': 0.8},\n",
       " {'term': 'trail running shoes', 'weight': 0.7},\n",
       " {'term': 'road running shoes', 'weight': 0.7},\n",
       " {'term': 'performance running shoes', 'weight': 0.7},\n",
       " {'term': 'running shooes', 'weight': 0.3},\n",
       " {'term': 'runing shoes', 'weight': 0.3},\n",
       " {'term': 'runnin shoes', 'weight': 0.3}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#demo with the above expansions\n",
    "weighted_queries=return_weighted_dict(expanded_queries, include_translations=False)\n",
    "weighted_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99aeca",
   "metadata": {},
   "source": [
    "### Step 2: Fine-tuning of mBART model\n",
    "We first fine-tune an mBART model on our spanish, italian and chinese dataset to carry out our machine translation task. The code for fine-tuning can be found at finetune.py, while the model is saved in ./final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d7643",
   "metadata": {},
   "source": [
    "### Step 3: Machine Translation of expanded queries\n",
    "We then translate these queries using our finetuned mBART model. Similarly, this is implemented in translate.py but showcased here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97a7137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "lang_code_map = {\n",
    "    \"en\": \"en_XX\",\n",
    "    \"es\": \"es_XX\",\n",
    "    \"it\": \"it_IT\", \n",
    "    \"cn\": \"zh_CN\"\n",
    "}\n",
    "\n",
    "#function to load model and tokenizer\n",
    "def load_model_and_tokenizer(model_path):\n",
    "    \"\"\"Load the model and tokenizer from the saved checkpoint\"\"\"\n",
    "    model = MBartForConditionalGeneration.from_pretrained(model_path)\n",
    "    tokenizer = MBart50TokenizerFast.from_pretrained(model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "#translation function.\n",
    "def translate_sentence(model, tokenizer, text, src_lang, tgt_lang):\n",
    "    \"\"\"Translate a single sentence\"\"\"\n",
    "    # Set source and target languages\n",
    "    tokenizer.src_lang = lang_code_map[src_lang]\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
    "    \n",
    "    # Generate translation\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[lang_code_map[tgt_lang]],\n",
    "            max_length=64,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3,  # Prevent repeating n-grams\n",
    "            repetition_penalty=2.0,   # Penalize repetition\n",
    "            length_penalty=1.0,       # Balance between length and score\n",
    "            temperature=0.7,          # Control randomness\n",
    "            do_sample=True           # Enable sampling\n",
    "        )\n",
    "\n",
    "     # Decode the output\n",
    "    translation = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    return translation\n",
    "\n",
    "def translate_expanded(model, tokenizer, query_list, src_lang, tgt_lang):\n",
    "    for query in query_list:\n",
    "        query['term']=translate_sentence(model, tokenizer, query['term'], src_lang, tgt_lang)\n",
    "    return query_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ab51c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo using expanded queries\n",
    "tgt_lang='cn'\n",
    "model, tokenizer = load_model_and_tokenizer(\"./final\")\n",
    "weighted_queries = translate_expanded(model, tokenizer, weighted_queries, 'en', tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d70da652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'term': '跑鞋', 'weight': 1.0},\n",
       " {'term': '跑鞋', 'weight': 0.3},\n",
       " {'term': '慢跑鞋', 'weight': 0.8},\n",
       " {'term': '耐鞋', 'weight': 0.8},\n",
       " {'term': '運動鞋', 'weight': 0.8},\n",
       " {'term': '教练员', 'weight': 0.8},\n",
       " {'term': '跑鞋', 'weight': 0.8},\n",
       " {'term': '跑鞋', 'weight': 0.8},\n",
       " {'term': '路跑鞋', 'weight': 0.7},\n",
       " {'term': '路跑鞋', 'weight': 0.7},\n",
       " {'term': '性能跑鞋', 'weight': 0.7},\n",
       " {'term': '跑鞋', 'weight': 0.3},\n",
       " {'term': '耐力鞋', 'weight': 0.3},\n",
       " {'term': '蘭寧鞋', 'weight': 0.3}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e461d7",
   "metadata": {},
   "source": [
    "### Step 4: Hybrid Search of expanded queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29f5054",
   "metadata": {},
   "source": [
    "#### 4.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34946e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a dicitonary of dfs\n",
    "import pandas as pd\n",
    "\n",
    "def get_data(data_paths):\n",
    "    data = {} \n",
    "    for lang, path in data_paths.items():\n",
    "        data[lang]=pd.read_pickle(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cfe4b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths={'cn':'en_to_cn_embeddings.pkl', 'es':'en_to_sp_embeddings.pkl', 'it':'en_to_it_embeddings.pkl'}\n",
    "data = get_data(data_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0ccbfa",
   "metadata": {},
   "source": [
    "#### BM25 Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84d6a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "febd1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build BM_25 corpus\n",
    "def build_BM25(data):\n",
    "    #cn\n",
    "    entocn_chinese_titles = data['cn']['chinese translation']\n",
    "    entocn_tokenized_cn = [list(jieba.cut_for_search(title.lower())) for title in entocn_chinese_titles]\n",
    "    bm25_cn = BM25Okapi(entocn_tokenized_cn)\n",
    "\n",
    "    #es\n",
    "    entoes_spanish_titles = data['es']['title_spanish']\n",
    "    entoes_tokenized_es = [title.split() for title in entoes_spanish_titles]\n",
    "    bm25_es = BM25Okapi(entoes_tokenized_es)\n",
    "\n",
    "    #it\n",
    "    entoit_italian_titles = data['it']['title_italian']\n",
    "    entoit_tokenized_it = [title.split() for title in entoit_italian_titles]\n",
    "    bm25_it = BM25Okapi(entoit_tokenized_it)\n",
    "\n",
    "    bm25_corpus={'cn':bm25_cn, 'es':bm25_es, 'it':bm25_it}\n",
    "\n",
    "\n",
    "    return bm25_corpus\n",
    "\n",
    "\n",
    "#Search BM25\n",
    "def search_bm25_expanded(query_list, corpus, tgt_lang='cn', top_k=5):\n",
    "    #init scores as zeros\n",
    "\n",
    "    scores = [0.0] * len(corpus[tgt_lang].doc_len)\n",
    "\n",
    "    for query_dict in query_list:\n",
    "        term=query_dict['term']\n",
    "        weight=query_dict['weight']\n",
    "        if tgt_lang=='cn':\n",
    "            tokens=jieba.cut_for_search(term.lower())\n",
    "            term_scores = corpus[tgt_lang].get_scores(tokens)        \n",
    "        else:\n",
    "            tokens = term.lower().split()\n",
    "            term_scores = corpus[tgt_lang].get_scores(tokens)\n",
    "\n",
    "        scores = [s + weight * ts for s, ts in zip(scores, term_scores)]\n",
    "\n",
    "    # Get top-k ranked indices\n",
    "    top_k_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "    return top_k_ids, [scores[i] for i in top_k_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b556de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_corpus = build_BM25(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c4f4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ids, top_scores = search_bm25_expanded(weighted_queries, bm25_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcceebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.3637 | New Balance Female 90 Lightweight Running Shoes  | New Balance 女 90轻量跑鞋 慢跑鞋- WSONIBS\n",
      "37.0750 | Men Running Shoes Lightweight Sneakers Magic Baby ~ Sd8035  | 慢跑鞋 男款輕量運動鞋 魔法Baby~sd8035\n",
      "36.7351 | Hole Bow Lazy Running Shoes Peach 1Ce28  | 洞洞蝴蝶結懶人慢跑鞋桃色1CE28\n",
      "34.7104 | Magic Baby Children Girls Running Shoes Light Sneakers ~ Sa68305  | 魔法Baby 兒童慢跑鞋 中大童輕量運動鞋~sa68305\n",
      "32.9813 | Mizuno Mizuno Running Shoes Female  | MIZUNO 女 美津浓 慢跑鞋- J1GD183001\n"
     ]
    }
   ],
   "source": [
    "#remember our original search was 'shir long sleeve', mispelled on purpose.\n",
    "\n",
    "for i, score in zip(top_ids, top_scores):\n",
    "    print(f\"{score:.4f} | {data['cn']['title'][i]}  | {data['cn']['chinese translation'][i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f994cf4",
   "metadata": {},
   "source": [
    "#### Dense Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df47839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e0843e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#Embeds a dense embedding representing the weighted mean of the expanded queries\n",
    "def embed_expanded(query_list, model):\n",
    "    query_embeddings= []\n",
    "    #embed expanded queries\n",
    "    for query_dict in query_list:\n",
    "        embedding=model.encode(query_dict['term'],  convert_to_tensor=True).cpu().numpy() #size1024\n",
    "        query_embeddings.append(embedding * query_dict[\"weight\"])\n",
    "\n",
    "    query_embedding = sum(query_embeddings) / len(query_embeddings)  # Weighted mean\n",
    "    return query_embedding\n",
    "\n",
    "\n",
    "def init_index(pc, index_name, data, embedding_col, eng_col, tgt_col, tgt_lang):\n",
    "    index_name = index_name\n",
    "    dimension = 1024\n",
    "\n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=dimension,\n",
    "            metric=\"cosine\",  # by cosine similarity\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",  # or \"gcp\"\n",
    "                region=\"us-east-1\" \n",
    "            )\n",
    "        )\n",
    "\n",
    "    index = pc.Index(index_name)\n",
    "\n",
    "    vectors_to_upsert = []\n",
    "    for _, row in data.iterrows():\n",
    "        vectors_to_upsert.append({\n",
    "            \"id\": str(_),  # Use index or generate unique IDs\n",
    "            \"values\": row[embedding_col],  # Using Chinese embeddings\n",
    "            \"metadata\": {\n",
    "                \"title\": row[eng_col],\n",
    "                \"chinese_title\": row[tgt_col],\n",
    "                \"embedding_type\": tgt_lang  # Track which embedding was used\n",
    "            }\n",
    "        })\n",
    "\n",
    "    for i in range(0, len(vectors_to_upsert), 100):\n",
    "        index.upsert(vectors=vectors_to_upsert[i:i+100])\n",
    "\n",
    "def setup_pinecone(data):\n",
    "    load_dotenv(dotenv_path='../.env')\n",
    "    pinecone_api_key = os.getenv('pinecone_API_KEY')\n",
    "    pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "    data = data\n",
    "    \n",
    "    indexes={'cn':'cn-search', 'it':'it-search', 'es':'es-search'}\n",
    "\n",
    "    #setup cn\n",
    "    init_index(pc, index_name=indexes['cn'], data=data['cn'],\n",
    "     embedding_col='chinese_embedding',\n",
    "     eng_col='title',\n",
    "     tgt_col='chinese translation',\n",
    "     tgt_lang='chinese')\n",
    "\n",
    "    #setup it\n",
    "    init_index(pc, index_name=indexes['it'], data=data['it'],\n",
    "     embedding_col='italian_embedding',\n",
    "     eng_col='title',\n",
    "     tgt_col='title_italian',\n",
    "     tgt_lang='italian')\n",
    "\n",
    "    #setup es\n",
    "    init_index(pc, index_name=indexes['es'], data=data['es'],\n",
    "     embedding_col='spanish_embedding',\n",
    "     eng_col='title',\n",
    "     tgt_col='title_spanish',\n",
    "     tgt_lang='spanish')\n",
    "\n",
    "    return indexes\n",
    "\n",
    "def search_pinecone(query_list, embedding_model, index_name, top_k=5):\n",
    "    load_dotenv(dotenv_path='../.env')\n",
    "    pinecone_api_key = os.getenv('pinecone_API_KEY')\n",
    "    pc = Pinecone(api_key=pinecone_api_key)\n",
    "    index = pc.Index(index_name)\n",
    "    query_embedding=embed_expanded(query_list, embedding_model)\n",
    "    results = index.query(\n",
    "            vector=query_embedding.tolist(),\n",
    "            top_k=top_k,\n",
    "            include_metadata=False\n",
    "        )\n",
    "    id_list = []\n",
    "    score_list = []\n",
    "    for dict in results.matches:\n",
    "        id_list.append(int(dict['id']))\n",
    "        score_list.append(float(dict['score']))\n",
    "\n",
    "    return id_list, score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f7a2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_indices=setup_pinecone(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0efad315",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ids_pc, top_scores_pc =search_pinecone(weighted_queries, model, pinecone_indices['cn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0cf11e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7090 | Men'S Shoes Sports Shoes Shoes Running Shoes Air Cushion Shoes  | 男鞋運動鞋男休閒鞋跑步鞋氣墊鞋子\n",
      "0.6922 | Running Sports Shoes Shoes Shoes Shoes  | 韓版跑步運動鞋女鞋學生單鞋女球鞋百搭休閒鞋子\n",
      "0.6707 | New BALANCE 247 sports shoes running shoes black shoes Child ka247t2p no338  | New Balance 247 運動鞋 跑鞋 黑色 中童 童鞋 KA247T2P no338\n",
      "0.6674 | New Balance Female 90 Lightweight Running Shoes  | New Balance 女 90轻量跑鞋 慢跑鞋- WSONIBS\n",
      "0.6673 | Skechers Women When - High Running Shoes  | SKECHERS 女 Liv-High 慢跑鞋 - 99830WSL\n"
     ]
    }
   ],
   "source": [
    "#remember our original search was 'shir long sleeve', mispelled on purpose.\n",
    "\n",
    "for i, score in zip(top_ids_pc, top_scores_pc):\n",
    "    print(f\"{score:.4f} | {data['cn']['title'][i]}  | {data['cn']['chinese translation'][i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690b596",
   "metadata": {},
   "source": [
    "#### RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a085a8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[902, 349, 630, 356, 156] [39.36373785264429, 37.07501466149296, 36.735098995178525, 34.71038588022547, 32.981256874273285]\n"
     ]
    }
   ],
   "source": [
    "#recap: Right now, we have BM25 results, returned as\n",
    "print(top_ids, top_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b655385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[951, 654, 782, 902, 783] [0.708953798, 0.692248642, 0.670711398, 0.66745, 0.667325675]\n"
     ]
    }
   ],
   "source": [
    "#recap: We also have semantic results, returned as\n",
    "print(top_ids_pc, top_scores_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64a460d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def scores_to_ranking(scores: list[float]) -> list[int]:\n",
    "    \"\"\"Convert float scores into int rankings (1 = best).\"\"\"\n",
    "    return np.argsort(scores)[::-1] + 1  # ranks start at 1\n",
    "\n",
    "def rrf(keyword_rank: int, semantic_rank: int, k: int = 60) -> float:\n",
    "    \"\"\"Combine keyword rank and semantic rank into a hybrid score using RRF.\"\"\"\n",
    "    return 1 / (k + keyword_rank) + 1 / (k + semantic_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4b0b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_expanded_search(query_list, bm25_corpus, pinecone_indices, embedding_model, tgt_lang='cn', top_k=5 ):\n",
    "    bm25_top_ids, bm25_top_scores = search_bm25_expanded(query_list, bm25_corpus, top_k=top_k)\n",
    "    pc_top_ids, pc_top_scores =search_pinecone(query_list, embedding_model, pinecone_indices[tgt_lang], top_k=top_k)\n",
    "    bm25_ranks = scores_to_ranking(bm25_top_scores)\n",
    "    pc_ranks = scores_to_ranking(pc_top_scores)\n",
    "\n",
    "    # Create dictionaries for quick rank lookup\n",
    "    bm25_rank_dict = {doc_id: rank for doc_id, rank in zip(bm25_top_ids, bm25_ranks)}\n",
    "    pc_rank_dict = {doc_id: rank for doc_id, rank in zip(pc_top_ids, pc_ranks)}\n",
    "    \n",
    "    # Combine all unique document IDs from both methods\n",
    "    all_doc_ids = list(set(bm25_top_ids) | set(pc_top_ids))\n",
    "    \n",
    "    # Calculate RRF scores for each document\n",
    "    rrf_scores = []\n",
    "    for doc_id in all_doc_ids:\n",
    "        # Get ranks from each method (use a high rank if document not found)\n",
    "        bm25_rank = bm25_rank_dict.get(doc_id, top_k * 2)  # Penalize missing documents\n",
    "        pc_rank = pc_rank_dict.get(doc_id, top_k * 2)\n",
    "        \n",
    "        # Calculate combined RRF score\n",
    "        score = rrf(bm25_rank, pc_rank)\n",
    "        rrf_scores.append((doc_id, score))\n",
    "    \n",
    "    # Sort documents by RRF score (descending)\n",
    "    rrf_scores.sort(key=lambda x: -x[1])\n",
    "    \n",
    "    # Extract the top_k document IDs\n",
    "    #hybrid_top_ids = [doc_id for doc_id, score in rrf_scores[:top_k]]\n",
    "    hybrid_top_ids = [doc_id for doc_id, score in rrf_scores]\n",
    "\n",
    "    #hybrid_top_scores = [score for doc_id, score in rrf_scores[:top_k]]\n",
    "    hybrid_top_scores = [score for doc_id, score in rrf_scores]\n",
    "    \n",
    "    return hybrid_top_ids, hybrid_top_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43bd0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_top_id, hybrid_top_scores=hybrid_expanded_search(weighted_queries, bm25_corpus, pinecone_indices, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3cf19797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0320 | New Balance Female 90 Lightweight Running Shoes  | New Balance 女 90轻量跑鞋 慢跑鞋- WSONIBS\n",
      "0.0307 | Men'S Shoes Sports Shoes Shoes Running Shoes Air Cushion Shoes  | 男鞋運動鞋男休閒鞋跑步鞋氣墊鞋子\n",
      "0.0304 | Running Sports Shoes Shoes Shoes Shoes  | 韓版跑步運動鞋女鞋學生單鞋女球鞋百搭休閒鞋子\n",
      "0.0304 | Men Running Shoes Lightweight Sneakers Magic Baby ~ Sd8035  | 慢跑鞋 男款輕量運動鞋 魔法Baby~sd8035\n",
      "0.0302 | New BALANCE 247 sports shoes running shoes black shoes Child ka247t2p no338  | New Balance 247 運動鞋 跑鞋 黑色 中童 童鞋 KA247T2P no338\n",
      "0.0302 | Hole Bow Lazy Running Shoes Peach 1Ce28  | 洞洞蝴蝶結懶人慢跑鞋桃色1CE28\n",
      "0.0299 | Magic Baby Children Girls Running Shoes Light Sneakers ~ Sa68305  | 魔法Baby 兒童慢跑鞋 中大童輕量運動鞋~sa68305\n",
      "0.0297 | Skechers Women When - High Running Shoes  | SKECHERS 女 Liv-High 慢跑鞋 - 99830WSL\n",
      "0.0297 | Mizuno Mizuno Running Shoes Female  | MIZUNO 女 美津浓 慢跑鞋- J1GD183001\n"
     ]
    }
   ],
   "source": [
    "for i, score in zip(hybrid_top_id, hybrid_top_scores):\n",
    "    print(f\"{score:.4f} | {data['cn']['title'][i]}  | {data['cn']['chinese translation'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "48db3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "import warnings\n",
    "\n",
    "def calculate_bertscore(candidate, reference, lang = \"en\"):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Compute scores\n",
    "        P, R, F1 = score(\n",
    "            [candidate], \n",
    "            [reference], \n",
    "            lang=lang,\n",
    "            model_type=\"bert-base-multilingual-cased\",  # Multilingual BERT\n",
    "            verbose=False  # Disable progress messages\n",
    "        )\n",
    "    return P.item(), R.item(), F1.item()\n",
    "\n",
    "\n",
    "def get_final_output(query, hybrid_top_id, data, tgt_lang='cn'):\n",
    "    final_output={}\n",
    "    for ids in hybrid_top_id:\n",
    "        if tgt_lang=='cn':\n",
    "            txt=data[tgt_lang]['chinese translation'][ids]\n",
    "        elif tgt_lang=='es':\n",
    "            txt=data[tgt_lang]['title_spanish'][ids]\n",
    "        elif tgt_lang=='it':\n",
    "            txt=data[tgt_lang]['title_italian'][ids]\n",
    "\n",
    "        acc, precision, f1 = calculate_bertscore(txt, query)\n",
    "        final_output[txt]=f1\n",
    "    return final_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a8a504f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"shir long sleeve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b9f01fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "final_output = get_final_output(query, hybrid_top_id, data, tgt_lang='cn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5c580dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'New Balance 女 90轻量跑鞋 慢跑鞋- WSONIBS': 0.6317388415336609,\n",
       " '男鞋運動鞋男休閒鞋跑步鞋氣墊鞋子': 0.6080911755561829,\n",
       " '韓版跑步運動鞋女鞋學生單鞋女球鞋百搭休閒鞋子': 0.6144701242446899,\n",
       " '慢跑鞋 男款輕量運動鞋 魔法Baby~sd8035': 0.6211652159690857,\n",
       " 'New Balance 247 運動鞋 跑鞋 黑色 中童 童鞋 KA247T2P no338': 0.6184868812561035,\n",
       " '洞洞蝴蝶結懶人慢跑鞋桃色1CE28': 0.6251214742660522,\n",
       " '魔法Baby 兒童慢跑鞋 中大童輕量運動鞋~sa68305': 0.630289614200592,\n",
       " 'SKECHERS 女 Liv-High 慢跑鞋 - 99830WSL': 0.6048922538757324,\n",
       " 'MIZUNO 女 美津浓 慢跑鞋- J1GD183001': 0.6235170960426331}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2546c887",
   "metadata": {},
   "source": [
    "### Step 5: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e25715",
   "metadata": {},
   "source": [
    "Here, we use the debug mode for the implemented search function to generate some evaluation metrics for our searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a93fe",
   "metadata": {},
   "source": [
    "#### Testing the final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0c37a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtpipeline import init_mt_environment, mt_pipeline_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "23505f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mBART_model_path=\"./final\"\n",
    "data_paths={'cn':'en_to_cn_embeddings.pkl', 'es':'en_to_sp_embeddings.pkl', 'it':'en_to_it_embeddings.pkl'}\n",
    "embed_model = \"BAAI/bge-m3\"\n",
    "env_path = \"../.env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f184311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run once at start of front end\n",
    "mBART_model, mBART_tokenizer, data, bm25_corpus, dense_embed_model, pinecone_indices = init_mt_environment(mBART_model_path, data_paths, embed_model, env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc4f5f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OPPO A75 A75s A73 手机壳 软壳 挂绳壳 大眼兔硅胶壳'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cn']['chinese translation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "803fe495",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"short sleeved t-shirt\"\n",
    "tgt_lang = \"cn\" #should be 'es' for spanish, 'cn' for chinese and 'it' italy\n",
    "top_k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a00ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding queries...\n",
      "Queries Expanded\n",
      "Translating Queries...\n",
      "Searching...\n",
      "Processing Output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "final_output = mt_pipeline_search(query, \n",
    "                                    env_path,\n",
    "                                    mBART_model,\n",
    "                                    mBART_tokenizer,\n",
    "                                    data,\n",
    "                                    bm25_corpus,\n",
    "                                    pinecone_indices,\n",
    "                                    dense_embed_model,\n",
    "                                    tgt_lang, #optional\n",
    "                                    top_k,) #optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ecfe260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'點點荷葉一字領短上衣': 0.674094021320343,\n",
       " '情侶短袖t 夏季水洗33數字短袖t': 0.6550724506378174,\n",
       " 'Augelute 兒童 套裝 居家森林護肚短袖套裝 31152': 0.6553329825401306,\n",
       " '牛仔捲邊破褲 短褲': 0.6830734014511108,\n",
       " '韩制。针织洞洞感网状透气短袜': 0.6939300894737244,\n",
       " '0~2歲寶寶短袖居家套裝 魔法baby~k50475': 0.6293430328369141,\n",
       " '多彩舒適棉素面百搭大尺碼POLO短衫_薰衣紫': 0.6625270247459412,\n",
       " 'LIYO理優英文字母休閒棉T恤E712003': 0.6467800736427307,\n",
       " 'iFairies 中大尺碼長袖T恤上衣★ifairies【59000】【59000】': 0.6530770659446716,\n",
       " '長版口袋開襟針織外套': 0.6996235847473145}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bdb48",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b4b43",
   "metadata": {},
   "source": [
    "To evaluate the semantic relevance of search results we used **BERTScore (F1)**, **Sentence-BERT cosine similarity**, and **METEOR**. We selected these metrics to cover more than just simple lexical overlap, aiming to capture the deeper semantic meaning and contextual alignment between the query and the retrieved results.\n",
    "\n",
    "**BERTScore (F1)** uses contextual embeddings from a pre-trained BERT model to evaluate the similarity between a candidate sentence and query. Unlike traditional token-based metrics, BERTScore considers word usage in context, making it particularly effective at identifying semantic similarity even when different words or phrasing are used.\n",
    "\n",
    "**Sentence-BERT cosine similarity** compares sentence-level embeddings in a shared vector space. It measures the overall semantic closeness of the query and result pairs, making it a strong indicator of whether two sentences convey similar meanings holistically.\n",
    "\n",
    "**METEOR** offers a balance between precision and recall at the word level, incorporating stemming, synonym matching through WordNet, and alignment-based evaluation. It helps account for linguistic variation while still rewarding accurate matches, and has shown strong correlation with human judgments in evaluation studies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80c3e1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding queries...\n",
      "Queries Expanded\n",
      "Translating Queries...\n",
      "Searching...\n",
      "Processing Output...\n"
     ]
    }
   ],
   "source": [
    "final_output_debug = mt_pipeline_search(query, \n",
    "                                    env_path,\n",
    "                                    mBART_model,\n",
    "                                    mBART_tokenizer,\n",
    "                                    data,\n",
    "                                    bm25_corpus,\n",
    "                                    pinecone_indices,\n",
    "                                    dense_embed_model,\n",
    "                                    tgt_lang, #optional\n",
    "                                    top_k,\n",
    "                                    debug=True) #optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9547ec0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Couple Short-Sleeved T Summer Washed 33 Digita...</td>\n",
       "      <td>情侶短袖t 夏季水洗33數字短袖t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polka Dots Lotus Leaf word Short Tops</td>\n",
       "      <td>點點荷葉一字領短上衣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Augelute Kids Set Home Forest Belly Short Slee...</td>\n",
       "      <td>Augelute 兒童 套裝 居家森林護肚短袖套裝 31152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cowboy Curling Jeans Shorts</td>\n",
       "      <td>牛仔捲邊破褲 短褲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Korean Made. Knitted Hole Sexy Mesh Breathable...</td>\n",
       "      <td>韩制。针织洞洞感网状透气短袜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0 ~ 2 Girls Short Sleeve Home Suit Magic Baby ...</td>\n",
       "      <td>0~2歲寶寶短袖居家套裝 魔法baby~k50475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PolarStar Women Sweat Quick Dry T-shirt Black ...</td>\n",
       "      <td>PolarStar 女 排汗快干T恤『黑』P18102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LIYO-English letter casual cotton T-shirt</td>\n",
       "      <td>LIYO理優英文字母休閒棉T恤E712003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bamboo Cotton Spaghetti Strap Vest</td>\n",
       "      <td>竹節棉細肩帶背心</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Couple Short-Sleeved T Summer Washed 33 Digita...   \n",
       "1              Polka Dots Lotus Leaf word Short Tops   \n",
       "2  Augelute Kids Set Home Forest Belly Short Slee...   \n",
       "3                        Cowboy Curling Jeans Shorts   \n",
       "4  Korean Made. Knitted Hole Sexy Mesh Breathable...   \n",
       "5  0 ~ 2 Girls Short Sleeve Home Suit Magic Baby ...   \n",
       "6  PolarStar Women Sweat Quick Dry T-shirt Black ...   \n",
       "7          LIYO-English letter casual cotton T-shirt   \n",
       "8                 Bamboo Cotton Spaghetti Strap Vest   \n",
       "\n",
       "                               tgt  \n",
       "0                情侶短袖t 夏季水洗33數字短袖t  \n",
       "1                       點點荷葉一字領短上衣  \n",
       "2  Augelute 兒童 套裝 居家森林護肚短袖套裝 31152  \n",
       "3                        牛仔捲邊破褲 短褲  \n",
       "4                   韩制。针织洞洞感网状透气短袜  \n",
       "5       0~2歲寶寶短袖居家套裝 魔法baby~k50475  \n",
       "6      PolarStar 女 排汗快干T恤『黑』P18102  \n",
       "7           LIYO理優英文字母休閒棉T恤E712003  \n",
       "8                         竹節棉細肩帶背心  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "883b302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.meteor_score import meteor_score\n",
    "#calculate METEOR\n",
    "final_output_debug['meteor'] = final_output_debug['en'].apply(lambda x: meteor_score([query.split()], x.split()))\n",
    "\n",
    "#Compute sentenceBERT cosine sim\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "en_embeddings = model.encode(final_output_debug['en'].tolist(), convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(query_embedding, en_embeddings)[0]\n",
    "final_output_debug['sbert_cosine'] = cosine_scores.tolist()\n",
    "\n",
    "#calculate bertscore\n",
    "P, R, F1 = score([query] * len(final_output_debug), final_output_debug['en'].tolist(), lang=\"en\", verbose=False)\n",
    "final_output_debug['bertscore_f1'] = F1.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7e449c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>tgt</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sbert_cosine</th>\n",
       "      <th>bertscore_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Couple Short-Sleeved T Summer Washed 33 Digita...</td>\n",
       "      <td>情侶短袖t 夏季水洗33數字短袖t</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.703328</td>\n",
       "      <td>0.860155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polka Dots Lotus Leaf word Short Tops</td>\n",
       "      <td>點點荷葉一字領短上衣</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.327517</td>\n",
       "      <td>0.810884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Augelute Kids Set Home Forest Belly Short Slee...</td>\n",
       "      <td>Augelute 兒童 套裝 居家森林護肚短袖套裝 31152</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.504298</td>\n",
       "      <td>0.818984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cowboy Curling Jeans Shorts</td>\n",
       "      <td>牛仔捲邊破褲 短褲</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.365026</td>\n",
       "      <td>0.837606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Korean Made. Knitted Hole Sexy Mesh Breathable...</td>\n",
       "      <td>韩制。针织洞洞感网状透气短袜</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276768</td>\n",
       "      <td>0.822082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0 ~ 2 Girls Short Sleeve Home Suit Magic Baby ...</td>\n",
       "      <td>0~2歲寶寶短袖居家套裝 魔法baby~k50475</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.304197</td>\n",
       "      <td>0.847186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PolarStar Women Sweat Quick Dry T-shirt Black ...</td>\n",
       "      <td>PolarStar 女 排汗快干T恤『黑』P18102</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.404821</td>\n",
       "      <td>0.830408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LIYO-English letter casual cotton T-shirt</td>\n",
       "      <td>LIYO理優英文字母休閒棉T恤E712003</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.550334</td>\n",
       "      <td>0.856207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bamboo Cotton Spaghetti Strap Vest</td>\n",
       "      <td>竹節棉細肩帶背心</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366832</td>\n",
       "      <td>0.833241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Couple Short-Sleeved T Summer Washed 33 Digita...   \n",
       "1              Polka Dots Lotus Leaf word Short Tops   \n",
       "2  Augelute Kids Set Home Forest Belly Short Slee...   \n",
       "3                        Cowboy Curling Jeans Shorts   \n",
       "4  Korean Made. Knitted Hole Sexy Mesh Breathable...   \n",
       "5  0 ~ 2 Girls Short Sleeve Home Suit Magic Baby ...   \n",
       "6  PolarStar Women Sweat Quick Dry T-shirt Black ...   \n",
       "7          LIYO-English letter casual cotton T-shirt   \n",
       "8                 Bamboo Cotton Spaghetti Strap Vest   \n",
       "\n",
       "                               tgt    meteor  sbert_cosine  bertscore_f1  \n",
       "0                情侶短袖t 夏季水洗33數字短袖t  0.506757      0.703328      0.860155  \n",
       "1                       點點荷葉一字領短上衣  0.147059      0.327517      0.810884  \n",
       "2  Augelute 兒童 套裝 居家森林護肚短袖套裝 31152  0.520833      0.504298      0.818984  \n",
       "3                        牛仔捲邊破褲 短褲  0.161290      0.365026      0.837606  \n",
       "4                   韩制。针织洞洞感网状透气短袜  0.000000      0.276768      0.822082  \n",
       "5       0~2歲寶寶短袖居家套裝 魔法baby~k50475  0.480769      0.304197      0.847186  \n",
       "6      PolarStar 女 排汗快干T恤『黑』P18102  0.138889      0.404821      0.830408  \n",
       "7           LIYO理優英文字母休閒棉T恤E712003  0.156250      0.550334      0.856207  \n",
       "8                         竹節棉細肩帶背心  0.000000      0.366832      0.833241  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88aca6",
   "metadata": {},
   "source": [
    "A high BERTscore suggests strong semantic similarity between the query and target translations, whereas a greater variability in sentence-BERT suggests a potential sensitivity to global smenatic shifts. As METEOR is more reliant on token-level overlap, it scores much lower. However, as the results are still semantically similar, this is alright."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1f12a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
