import pandas as pd
from transformers import MarianMTModel, MarianTokenizer
from langdetect import detect

# Load datasets
amazon_df = pd.read_csv("C:\\Users\\65988\\Documents\\GitHub\\EE6405C22\\NLP\\dataset\\Amazon_en_to_es.csv")
shopee_df = pd.read_csv("C:\\Users\\65988\\Documents\\GitHub\\EE6405C22\\NLP\\dataset\\Shopee_CN_to_EN.csv")
italian_df = pd.read_csv("C:\\Users\\65988\\Documents\\GitHub\\EE6405C22\\NLP\\dataset\\target_en_to_it.csv")

# Define translation models
models = {
    "enâ†’zh": "Helsinki-NLP/opus-mt-en-zh",
    "zhâ†’en": "Helsinki-NLP/opus-mt-zh-en",
    "enâ†’it": "Helsinki-NLP/opus-mt-en-it",
    "itâ†’en": "Helsinki-NLP/opus-mt-mul-en",
    "enâ†’fr": "Helsinki-NLP/opus-mt-en-fr",
    "esâ†’en": "Helsinki-NLP/opus-mt-es-en",
    "enâ†’es": "Helsinki-NLP/opus-mt-en-es"
}

# Load translation pipelines
translation_pipelines = {}
for key, model_name in models.items():
    print(f"ğŸ”„ Loading model: {key}")
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    model = MarianMTModel.from_pretrained(model_name)
    translation_pipelines[key] = (tokenizer, model)

# Translation function
def translate(text, direction):
    tokenizer, model = translation_pipelines[direction]
    inputs = tokenizer(text, return_tensors="pt", padding=True)
    outputs = model.generate(**inputs)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# Search all datasets
def search_dataset(df, column, query):
    return df[df[column].str.contains(query, case=False, na=False)]

# Main search loop
while True:
    user_input = input("\nEnter your product search query (or type 'exit' to quit): ")
    if user_input.lower() in ["exit", "quit"]:
        print("ğŸ‘‹ Exiting search. Goodbye!")
        break

    detected_lang = detect(user_input)
    print(f"ğŸ” Detected language: {detected_lang}")

    supported_langs = ["zh", "it", "es", "fr"]
    if detected_lang not in supported_langs:
        print(f"âš ï¸ Detected unsupported language '{detected_lang}', defaulting to English.")
        detected_lang = "en"

    if detected_lang == "zh":
        search_query_en = translate(user_input, "zhâ†’en")
    elif detected_lang == "it":
        search_query_en = translate(user_input, "itâ†’en")
    elif detected_lang == "es":
        search_query_en = translate(user_input, "esâ†’en")
    else:
        search_query_en = user_input

    print(f"ğŸ” Searching for: {search_query_en}")

    results = []
    results.append(search_dataset(amazon_df, "title", search_query_en))
    results.append(search_dataset(shopee_df, "translation_output", search_query_en))
    results.append(search_dataset(italian_df, "title", search_query_en))

    combined = pd.concat(results)
    if combined.empty:
        print("âŒ No matching results found.")
        continue

    print("âœ… Search Results:")
    print(combined.head())

    if detected_lang != "en":
        def get_display_title(row):
            return row["title"] if "title" in row and pd.notna(row["title"]) else row.get("translation_output", "")

        display_titles = [get_display_title(row) for _, row in combined.head().iterrows()]
        translated_titles = [translate(title, f"enâ†’{detected_lang}") for title in display_titles]

        print("\nğŸŒ Translated Results:")
        for original, translated in zip(display_titles, translated_titles):
            print(f"- {original} â†’ {translated}")
    else:
        print("\nğŸŒ All results already in English.")
