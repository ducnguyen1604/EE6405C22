import pandas as pd
from transformers import MarianMTModel, MarianTokenizer
from langdetect import detect

# ğŸ” Load environment variables from Api.env
from dotenv import load_dotenv
import os
import openai

load_dotenv(dotenv_path="Api.env")  # Load your DeepSeek key securely
openai.api_key = os.getenv("DEEPSEEK_API_KEY")
openai.api_base = "https://api.deepseek.com/v1"

# Auto-install spellchecker if not present
try:
    from spellchecker import SpellChecker
except ModuleNotFoundError:
    import subprocess
    import sys
    subprocess.check_call([sys.executable, "-m", "pip", "install", "pyspellchecker"])
    from spellchecker import SpellChecker

# Spell checker setup
spell = SpellChecker()

# Load dataset
amazon_df = pd.read_csv("C:\\Users\\65988\\Documents\\GitHub\\EE6405C22\\NLP\\dataset\\Amazon_en_to_es.csv")

# Load MarianMT English-Spanish models
models = {
    "enâ†’es": "Helsinki-NLP/opus-mt-en-es",
    "esâ†’en": "Helsinki-NLP/opus-mt-es-en"
}

translation_pipelines = {}
for direction, model_name in models.items():
    print(f"ğŸ”„ Loading model: {direction}")
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    model = MarianMTModel.from_pretrained(model_name)
    translation_pipelines[direction] = (tokenizer, model)

# Translation function
def translate(text, direction):
    tokenizer, model = translation_pipelines[direction]
    inputs = tokenizer(text, return_tensors="pt", padding=True)
    outputs = model.generate(**inputs)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# Semantic rephrasing with DeepSeek
def semantic_rephrase_deepseek(query):
    prompt = f"""You are a helpful assistant that improves e-commerce search queries.
Given the user's search input: "{query}", rephrase or expand it into a more descriptive English query that helps retrieve more relevant product titles from a catalog.

Only output the improved query, no explanation."""
    
    response = openai.ChatCompletion.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=100
    )
    return response["choices"][0]["message"]["content"].strip()

# Search function
def search_dataset(df, column, query):
    return df[df[column].str.contains(query, case=False, na=False)]

# Main loop
while True:
    user_input = input("\nEnter your product search query (English/Spanish, or type 'exit' to quit): ")
    if user_input.lower() in ["exit", "quit"]:
        print("ğŸ‘‹ Exiting search. Goodbye!")
        break

    # Spell correct input
    corrected_input = " ".join([spell.correction(w) or w for w in user_input.split()])
    if corrected_input.lower() != user_input.lower():
        print(f"ğŸ“ Corrected input: {corrected_input}")
    else:
        corrected_input = user_input

    # Detect language
    detected_lang = detect(corrected_input)
    print(f"ğŸ” Detected language: {detected_lang}")

    # Fallback logic if detection is off but input is ASCII-like
    if detected_lang not in ["en", "es"]:
        if all(c.isascii() and (c.isalpha() or c.isspace()) for c in corrected_input):
            print(f"âš ï¸ Detected '{detected_lang}', trying both English and Spanish due to input format.")

            # Try both interpretations
            en_results = search_dataset(amazon_df, "title", corrected_input)
            es_to_en_query = translate(corrected_input, "esâ†’en")
            es_results = search_dataset(amazon_df, "title", es_to_en_query)

            if not en_results.empty:
                print("âœ… Interpreted as English.")
                search_query_en = corrected_input
                detected_lang = "en"
                results = en_results
            elif not es_results.empty:
                print("âœ… Interpreted as Spanish.")
                search_query_en = es_to_en_query
                detected_lang = "es"
                results = es_results
            else:
                print("âŒ No matching results found in either English or Spanish.")
                continue
        else:
            print("âš ï¸ Only English or Spanish are supported. Try again.")
            continue
    else:
        # Normal translation flow
        if detected_lang == "es":
            search_query_en = translate(corrected_input, "esâ†’en")
        else:
            search_query_en = corrected_input

        # Semantic enhancement
        print("ğŸ§  Enhancing query with semantic understanding via DeepSeek...")
        semantic_query = semantic_rephrase_deepseek(search_query_en)

        # Show and log DeepSeek rephrased query
        if semantic_query.lower().strip() != search_query_en.lower().strip():
            print(f"ğŸ” Original query       : {search_query_en}")
            print(f"ğŸ§  DeepSeek-enhanced    : {semantic_query}")
        else:
            print(f"â„¹ï¸ DeepSeek returned the same query: {semantic_query}")

        with open("deepseek_log.txt", "a", encoding="utf-8") as log:
            log.write(f"Original: {search_query_en} | Rephrased: {semantic_query}\n")

        # Perform search
        results = search_dataset(amazon_df, "title", semantic_query)
        if results.empty:
            print("âŒ No matching results found.")
            continue

    # Show results
    print("âœ… Search Results:")
    print(results.head())

    # Translate results back to Spanish
    if detected_lang == "es":
        print("\nğŸŒ Translated Results:")
        translated_titles = [translate(title, "enâ†’es") for title in results["title"].head()]
        for original, translated in zip(results["title"].head(), translated_titles):
            print(f"- {original} â†’ {translated}")
    else:
        print("\nğŸŒ All results already in English.")
