{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second phase of the NLP Capstone focuses on Hybrid Retrieval Search. This phase focuses on comparing the performances in search retrieval models between sparse retrieval techniques using term weighting schemes such as BM25 and TF-IDF against hybrid search retrieval methods which incorporates dense retrieval from embeddings generated using BAAI BGE-M3 sentence transformer combined with the sparse retrieval methods. The models explored are BM25 Alone, TF-IDF Alone, BM25 + BGE, and TFIDF + BGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "CHARRAN_API = os.getenv('CHARRAN_API')\n",
    "CHERYL_API = os.getenv('CHERYL_API')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langdetect import detect\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hybrid Retrieval Phase for Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_italian</th>\n",
       "      <th>english_embedding</th>\n",
       "      <th>italian_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zwilling pro 2pc prep knife set</td>\n",
       "      <td>Zwilling pro 2pc set coltello prep</td>\n",
       "      <td>[-0.07585622, -0.006632321, -0.039237764, 0.04...</td>\n",
       "      <td>[-0.058768444, 0.012960452, -0.029929288, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>womens slim fit drape wrap tshirt  a new day</td>\n",
       "      <td>donne slim fit drappeggio avvolgere tshirt un ...</td>\n",
       "      <td>[-0.023722176, -0.02756558, -0.07540757, 0.011...</td>\n",
       "      <td>[-0.056372743, -0.038858823, -0.07786548, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mens teenage mutant ninja turtles group shot l...</td>\n",
       "      <td>mens adolescente mutante ninja tartarughe grup...</td>\n",
       "      <td>[-0.02781372, 0.004972987, -0.055929173, 0.013...</td>\n",
       "      <td>[-0.004044311, 0.008419336, -0.05591273, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mens wwe triple h the game logo tshirt</td>\n",
       "      <td>mens wwe triplo h il gioco logo tshirt</td>\n",
       "      <td>[-0.037347108, -0.009183998, -0.082188, 0.0122...</td>\n",
       "      <td>[-0.03912319, -0.015832098, -0.07382396, 0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>purina fancy feast grilled gravy delights feas...</td>\n",
       "      <td>purina fantasia festa grigliato sugo delizie f...</td>\n",
       "      <td>[-0.0551254, 0.024768988, -0.02036258, -0.0108...</td>\n",
       "      <td>[-0.0431343, 0.017949222, -0.023515861, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>multi collagen protein powder types i ii  ii b...</td>\n",
       "      <td>proteine multi collageno in polvere ii ii ii o...</td>\n",
       "      <td>[-0.007071648, 0.013024846, -0.026673753, -0.0...</td>\n",
       "      <td>[0.036605842, 0.03628495, -0.027457794, -0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>hope  henry mens waffle knit pullover sweater</td>\n",
       "      <td>speranza henry uomo waffle maglia pullover mag...</td>\n",
       "      <td>[-0.026264952, -0.008562797, -0.05641582, -0.0...</td>\n",
       "      <td>[-0.0020557789, -0.0039152885, -0.04709097, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>noritake colortrio 16piece coupe dinnerware set</td>\n",
       "      <td>noritake colortio 16 pezzi coup√© set per la cena</td>\n",
       "      <td>[-0.0055267178, -0.03823672, -0.024558328, 0.0...</td>\n",
       "      <td>[0.0011833841, -0.014286156, -0.01681679, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>hope  henry mens fine gauge vneck pullover swe...</td>\n",
       "      <td>speranza henry mens maglione pullover fine gau...</td>\n",
       "      <td>[-0.03244666, -0.026627203, -0.07740165, 0.004...</td>\n",
       "      <td>[-0.017570777, -0.00990813, -0.071718924, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>double strength larginine 1000 mg by now foods...</td>\n",
       "      <td>larginina 1000 mg a doppia resistenza ormai al...</td>\n",
       "      <td>[-0.032500178, 0.013463285, -0.05747889, -0.04...</td>\n",
       "      <td>[-0.010276856, 0.006340458, -0.052428123, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                      zwilling pro 2pc prep knife set   \n",
       "1         womens slim fit drape wrap tshirt  a new day   \n",
       "2    mens teenage mutant ninja turtles group shot l...   \n",
       "3               mens wwe triple h the game logo tshirt   \n",
       "4    purina fancy feast grilled gravy delights feas...   \n",
       "..                                                 ...   \n",
       "868  multi collagen protein powder types i ii  ii b...   \n",
       "869      hope  henry mens waffle knit pullover sweater   \n",
       "870    noritake colortrio 16piece coupe dinnerware set   \n",
       "871  hope  henry mens fine gauge vneck pullover swe...   \n",
       "872  double strength larginine 1000 mg by now foods...   \n",
       "\n",
       "                                         title_italian  \\\n",
       "0                   Zwilling pro 2pc set coltello prep   \n",
       "1    donne slim fit drappeggio avvolgere tshirt un ...   \n",
       "2    mens adolescente mutante ninja tartarughe grup...   \n",
       "3               mens wwe triplo h il gioco logo tshirt   \n",
       "4    purina fantasia festa grigliato sugo delizie f...   \n",
       "..                                                 ...   \n",
       "868  proteine multi collageno in polvere ii ii ii o...   \n",
       "869  speranza henry uomo waffle maglia pullover mag...   \n",
       "870   noritake colortio 16 pezzi coup√© set per la cena   \n",
       "871  speranza henry mens maglione pullover fine gau...   \n",
       "872  larginina 1000 mg a doppia resistenza ormai al...   \n",
       "\n",
       "                                     english_embedding  \\\n",
       "0    [-0.07585622, -0.006632321, -0.039237764, 0.04...   \n",
       "1    [-0.023722176, -0.02756558, -0.07540757, 0.011...   \n",
       "2    [-0.02781372, 0.004972987, -0.055929173, 0.013...   \n",
       "3    [-0.037347108, -0.009183998, -0.082188, 0.0122...   \n",
       "4    [-0.0551254, 0.024768988, -0.02036258, -0.0108...   \n",
       "..                                                 ...   \n",
       "868  [-0.007071648, 0.013024846, -0.026673753, -0.0...   \n",
       "869  [-0.026264952, -0.008562797, -0.05641582, -0.0...   \n",
       "870  [-0.0055267178, -0.03823672, -0.024558328, 0.0...   \n",
       "871  [-0.03244666, -0.026627203, -0.07740165, 0.004...   \n",
       "872  [-0.032500178, 0.013463285, -0.05747889, -0.04...   \n",
       "\n",
       "                                     italian_embedding  \n",
       "0    [-0.058768444, 0.012960452, -0.029929288, 0.05...  \n",
       "1    [-0.056372743, -0.038858823, -0.07786548, 0.00...  \n",
       "2    [-0.004044311, 0.008419336, -0.05591273, 0.015...  \n",
       "3    [-0.03912319, -0.015832098, -0.07382396, 0.008...  \n",
       "4    [-0.0431343, 0.017949222, -0.023515861, -0.024...  \n",
       "..                                                 ...  \n",
       "868  [0.036605842, 0.03628495, -0.027457794, -0.008...  \n",
       "869  [-0.0020557789, -0.0039152885, -0.04709097, -0...  \n",
       "870  [0.0011833841, -0.014286156, -0.01681679, 0.03...  \n",
       "871  [-0.017570777, -0.00990813, -0.071718924, 0.01...  \n",
       "872  [-0.010276856, 0.006340458, -0.052428123, -0.0...  \n",
       "\n",
       "[873 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the Italy Embeddings\n",
    "italian_embeddings = pd.read_pickle(\"en_to_it_embeddings.pkl\")\n",
    "italian_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting English and Italian product titles from the dataset\n",
    "entoit_english_titles = italian_embeddings['title']\n",
    "entoit_italian_titles = italian_embeddings['title_italian']\n",
    "\n",
    "#Tokenize the english and italian titles by splitting on whitespaces\n",
    "entoit_tokenized_en = [title.split() for title in entoit_english_titles]\n",
    "entoit_tokenized_it = [title.split() for title in entoit_italian_titles]\n",
    "\n",
    "#Create a BM25 index for each language titles\n",
    "bm25_en = BM25Okapi(entoit_tokenized_en)\n",
    "bm25_it = BM25Okapi(entoit_tokenized_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even though the BM25 could be modularised by declaring the BM25 indexes in a dictionary, \n",
    "#it has not be done so that each language can be shown visually\n",
    "\n",
    "\"\"\"\" \n",
    "This function performs a BM25-based search for a given query and language. \n",
    "   Parameters:\n",
    "        query (str): The input search string.\n",
    "        lang (str): The language of the search corpus ('en' or 'it').\n",
    "        top_k (int): The number of top matching results to return. Default is 5.\n",
    "\n",
    "    Returns:\n",
    "        top_k_ids (List[int]): Indices of the top_k most relevant documents.\n",
    "        top_k_scores (List[float]): Corresponding BM25 relevance scores.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def search(query, lang='en', top_k=5):\n",
    "    tokens = query.lower().split() #Tokenize and lowercase the query\n",
    "\n",
    "    #Compute BM25 relevance scores using the appropriate model\n",
    "    if lang == 'en':\n",
    "        scores = bm25_en.get_scores(tokens)\n",
    "    else:\n",
    "        scores = bm25_it.get_scores(tokens)\n",
    "    \n",
    "    #Rank results by score and get indices of top_k matches\n",
    "    top_k_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "\n",
    "    # Return both the document indices and their scores\n",
    "    return top_k_ids, [scores[i] for i in top_k_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is similar to the previous code, but it has the autodetection of english or italian queries using the langdetect library\n",
    "def search_bm25(query, top_k=5):\n",
    "    lang = detect(query)  # auto-detect 'en', 'it', etc.\n",
    "    tokens = query.lower().split()  # simple tokenization\n",
    "\n",
    "    if lang == 'it':\n",
    "        scores = bm25_it.get_scores(tokens)\n",
    "    else:\n",
    "        scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # Get top-k ranked indices\n",
    "    top_k_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "    return top_k_ids, [scores[i] for i in top_k_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1469 | lands end womens anyweather fleece adjustable earmuffs\n",
      "4.9215 | girls39 fleece footless tights  cat 38 jack8482\n",
      "4.6791 | womens short sleeve vneck seamless tshirt  wild fable\n",
      "4.6791 | womens seamless short sleeve shirt  all in motion\n",
      "4.4594 | lands end womens no iron supima cotton long sleeve shirt\n"
     ]
    }
   ],
   "source": [
    "#Performs a BM25 search for the italian query \n",
    "results, scores = search_bm25(\"cuffie senza fili\")\n",
    "\n",
    "# Loop through the top results and print each score with its corresponding English product title\n",
    "for i, score in zip(results, scores):\n",
    "    print(f\"{score:.4f} | {italian_embeddings['title'][i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading PineCone vectordatabase library\n",
    "pc = Pinecone(api_key=CHARRAN_API)\n",
    "\n",
    "#Initialising Pinecone index\n",
    "#This is the Index for the English to Italian vector database\n",
    "index = pc.Index('product-title-embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to batch upsert\n",
    "def batch_upsert(index, vectors, batch_size=50):\n",
    "    \"\"\"\n",
    "    Helper function to upsert (insert or update) vectors into a vector index in batches.\n",
    "\n",
    "    Parameters:\n",
    "        index: The vector index (e.g., Pinecone index or FAISS wrapper) supporting the `upsert` method.\n",
    "        vectors (list): A list of vector records, typically in the format expected by the index (e.g., [{\"id\": ..., \"values\": [...]}]).\n",
    "        batch_size (int): Number of vectors to upsert in each batch. Default is 50.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i+batch_size] #Slicing the current  batch\n",
    "        index.upsert(vectors=batch) #Upsert the batch into index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique IDs for English embeddings in the format: en-0, en-1, ..., en-N\n",
    "en_ids = [f\"en-{i}\" for i in range(len(italian_embeddings['english_embedding']))]\n",
    "\n",
    "# Generate unique IDs for Italian embeddings in the format: it-0, it-1, ..., it-N\n",
    "it_ids = [f\"it-{i}\" for i in range(len(italian_embeddings['italian_embedding']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine English + Italian vectors with unique IDs\n",
    "# Each tuple is in the form (id, embedding)\n",
    "combined_vectors = (\n",
    "    list(zip(en_ids, italian_embeddings['english_embedding'])) +\n",
    "    list(zip(it_ids, italian_embeddings['italian_embedding']))\n",
    ")\n",
    "\n",
    "#Convert each tuple to the expected format for upsert\n",
    "# Required format: {\"id\": str, \"values\": List[float]}\n",
    "to_upsert = [{\"id\": id, \"values\": vector} for id, vector in combined_vectors]\n",
    "\n",
    "# Step 3: Upsert to index in batches\n",
    "batch_upsert(index, to_upsert, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine English + Italian vectors with unique IDs\n",
    "# Each tuple is in the form (id, embedding)\n",
    "to_upsert = list(zip(en_ids, italian_embeddings['english_embedding'])) + \\\n",
    "            list(zip(it_ids, italian_embeddings['italian_embedding']))\n",
    "\n",
    "# Run batch upload\n",
    "batch_upsert(index, to_upsert, batch_size=50)\n",
    "\n",
    "\n",
    "#With this code, the vectorDB has been established for en to it.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the vectorDB has been established for english and italian vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since BM25 is working, the next step is to proceed building a hybrid retrieval of BM25 + BGE-M3 search engine\n",
    "for the product titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_to_ranking(scores: list[float]) -> list[int]:\n",
    "    \"\"\"\n",
    "    Converts a list of float scores into integer rankings.\n",
    "\n",
    "    Higher scores get better (lower) ranks ‚Äî e.g., the highest score gets rank 1.\n",
    "\n",
    "    Args:\n",
    "        scores (list[float]): List of similarity or relevance scores.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: List of ranks where 1 is the highest rank.\n",
    "    \"\"\"\n",
    "    # argsort returns indices that would sort the array ‚Äî we reverse to get descending order\n",
    "    return list(np.argsort(scores)[::-1] + 1)  # Ranks start at 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf(keyword_rank: int, semantic_rank: int, k: int = 60) -> float:\n",
    "    \"\"\"\n",
    "    Computes a Reciprocal Rank Fusion (RRF) score from keyword and semantic ranks.\n",
    "\n",
    "    RRF helps combine multiple ranking signals (e.g., BM25 + embeddings) into a single score\n",
    "    that rewards high rank in either list.\n",
    "\n",
    "    Args:\n",
    "        keyword_rank (int): Rank from keyword-based retrieval (e.g., BM25).\n",
    "        semantic_rank (int): Rank from semantic search (e.g., BGE/LaBSE embeddings).\n",
    "        k (int, optional): Smoothing constant to dampen large ranks. Default is 60.\n",
    "\n",
    "    Returns:\n",
    "        float: The combined RRF score (higher is better).\n",
    "    \"\"\"\n",
    "    return 1 / (k + keyword_rank) + 1 / (k + semantic_rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 BM25 + BGE Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search_rrf(query, top_k=5):\n",
    "\n",
    "    #To detect the language from the query\n",
    "    from langdetect import detect\n",
    "\n",
    "    lang = detect(query)\n",
    "    #tokenising the query to be suitable for BM25\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # --- BM25 Retrieval ---(Routes the tokenized query to the appropiate BM25 engine)\n",
    "    if lang == 'it':\n",
    "        bm25_scores = bm25_it.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens) #returns a list of scores, one for each document in the dataset\n",
    "\n",
    "    bm25_ranks = scores_to_ranking(bm25_scores)  #Converts the float BM25 scores to rankings for Reciprocal rank fusion(rrf)\n",
    "\n",
    "    # --- Semantic Retrieval (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist() #generate the query's embedding and convert it a list\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k, include_metadata=False) #Submits the query vector to Pinecone to retrieve top-k similar vectors, based on cosine similarity\n",
    "\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']] #extracts og row index from pinecone's ID\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']] #Obtain cosine similarity scores from pinecone\n",
    "    semantic_ranks = scores_to_ranking(pinecone_scores) #Converting pinecone scores to ranks (lower rank = better match)\n",
    "\n",
    "    # --- Combine using RRF ---\n",
    "    combined_scores = {} #placeholder to store RRF combined scores for each shortlisted document\n",
    "    for idx in pinecone_ids:\n",
    "        #For each doc idx returned by pinecone\n",
    "        # Retrieve the BM25 rank and semantic rank, and using rrf function defined on prev cell to combine them into one score\n",
    "        rrf_score = rrf(\n",
    "            keyword_rank=bm25_ranks[idx],\n",
    "            semantic_rank=semantic_ranks[pinecone_ids.index(idx)]\n",
    "        )\n",
    "        combined_scores[idx] = rrf_score\n",
    "\n",
    "    # Sort by RRF score\n",
    "    ranked = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)  #Sorting the docs by their RRF score, with the highest first.\n",
    "\n",
    "    return ranked[:top_k]  # list of (doc_id, final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_to_ranking' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33216\\1625477608.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Testing phase for hybrid (Italian to English)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhybrid_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhybrid_search_rrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"giacca da donna\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhybrid_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33216\\1664990870.py\u001b[0m in \u001b[0;36mhybrid_search_rrf\u001b[1;34m(query, top_k)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mbm25_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbm25_en\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#returns a list of scores, one for each document in the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mbm25_ranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores_to_ranking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbm25_scores\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#Converts the float BM25 scores to rankings for Reciprocal rank fusion(rrf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# --- Semantic Retrieval (Pinecone) ---\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scores_to_ranking' is not defined"
     ]
    }
   ],
   "source": [
    "#Testing phase for hybrid (Italian to English)\n",
    "\n",
    "hybrid_results = hybrid_search_rrf(\"giacca da donna\")\n",
    "\n",
    "for idx, score in hybrid_results:\n",
    "    print(f\"{score:.4f} | {italian_embeddings['title'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0203 | ragazze39 solido giacca trapuntato gatto 38 jack8482\n",
      "0.0200 | ragazze puffer giacca tutto in movimento\n",
      "0.0184 | jockey generazione donne cotone biologico stretch cropped tshirt\n",
      "0.0178 | wink pro donne snap giacca di riscaldamento anteriore\n",
      "0.0173 | ragazze solido puffer giacca classe d'arte\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for hybrid (English to Italian)\n",
    "\n",
    "hybrid_results = hybrid_search_rrf(\"women jacket\")\n",
    "\n",
    "for idx, score in hybrid_results:\n",
    "    print(f\"{score:.4f} | {italian_embeddings['title_italian'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 BM25 Alone Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform BM25 keyword search based on query language.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's search query.\n",
    "        top_k (int): Number of top documents to return.\n",
    "\n",
    "    Returns:\n",
    "        list of (doc_id, bm25_score)\n",
    "    \"\"\"\n",
    "    #To detect the language from the query\n",
    "    from langdetect import detect\n",
    "    lang = detect(query)\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # Score retrieval\n",
    "    if lang == 'it':\n",
    "        bm25_scores = bm25_it.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # Get top-k doc IDs based on raw BM25 scores\n",
    "    top_k_ids = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:top_k]\n",
    "    \n",
    "    return [(i, bm25_scores[i]) for i in top_k_ids] #Returns a list of (document ID, score) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1452 | womens highrise straight jeans  universal thread\n",
      "6.4611 | womens linen short sleeve buttondown camp shirt  a new day\n",
      "6.4048 | hanes comfort fit scrubs womens scrub pants\n",
      "6.4048 | timberland womens dunstan short sleeve tshirt\n",
      "6.0893 | womens fitted short sleeve tshirt  universal thread\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for BM25 alone\n",
    "\n",
    "results = BM25(\"giacca da donna\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {italian_embeddings['title'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4298 | ragazze puffer giacca tutto in movimento\n",
      "5.4298 | ragazze solido puffer giacca classe d'arte\n",
      "5.1272 | Bambini39 giacca gonfiabile solida tutto in movimento8482\n",
      "5.1272 | ragazze39 solido giacca trapuntato gatto 38 jack8482\n",
      "5.1272 | wink pro donne snap giacca di riscaldamento anteriore\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for BM25 alone\n",
    "results = BM25(\"women jacket\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {italian_embeddings['title_italian'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 TF-IDF + BGE Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For both Sparse and Sparse + Dense\n",
    "tfidf_vectorizer_en = TfidfVectorizer()\n",
    "tfidf_matrix_en = tfidf_vectorizer_en.fit_transform(italian_embeddings['title'])\n",
    "\n",
    "tfidf_vectorizer_it = TfidfVectorizer()\n",
    "tfidf_matrix_it = tfidf_vectorizer_it.fit_transform(italian_embeddings['title_italian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search_tfidf(query, top_k=5):\n",
    "\n",
    "    # To detect the language from the query\n",
    "    from langdetect import detect\n",
    "    lang = detect(query)\n",
    "    \n",
    "    # Ensure correct tf-idf matrix based on language\n",
    "    if lang == 'it':\n",
    "        query_vec = tfidf_vectorizer_it.transform([query])  # Spanish vectorizer\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_it)[0]  # Cosine similarity for Spanish\n",
    "    else:\n",
    "        query_vec = tfidf_vectorizer_en.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_en)[0]  # Cosine similarity for English\n",
    "\n",
    "    # Rank documents by similarity\n",
    "    ranked_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Return top_k document indices with their similarity scores\n",
    "    tfidf_rank_map = {int(idx): rank for rank, idx in enumerate(ranked_indices[:top_k], start=1)}\n",
    "\n",
    "\n",
    "    # --- Semantic Retrieval (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist()  # Generate the query's embedding and convert it to a list\n",
    "\n",
    "    # Submits the query vector to Pinecone to retrieve top-k similar vectors\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k * 2, include_metadata=False)\n",
    "\n",
    "    # Extracts original row index from Pinecone's vector ID (e.g., \"en-123\" ‚Üí 123)\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']]\n",
    "\n",
    "    # Obtain cosine similarity scores from Pinecone\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']]\n",
    "\n",
    "    # Converting Pinecone scores to ranks (lower rank = better match)\n",
    "    semantic_ranks = scores_to_ranking(pinecone_scores)\n",
    "\n",
    "    # Create a mapping from document index to semantic rank for fast lookup (converted to dictionary)\n",
    "    semantic_rank_map = {idx: rank for idx, rank in zip(pinecone_ids, semantic_ranks)}\n",
    "\n",
    "    # --- Combine using RRF ---\n",
    "    combined_scores = {}\n",
    "\n",
    "    # For each doc idx returned by Pinecone\n",
    "    # Retrieve the BM25 rank and semantic rank, and use rrf() to combine them into a hybrid score\n",
    "    for idx in pinecone_ids:\n",
    "        rrf_score = rrf(\n",
    "            keyword_rank=tfidf_rank_map.get(idx, top_k + 1),  # Fallback rank if not found in BM25\n",
    "            semantic_rank=semantic_rank_map.get(idx, top_k + 1)  # Fallback rank if not found in semantic\n",
    "        )\n",
    "        combined_scores[idx] = rrf_score  # Store the fused score\n",
    "\n",
    "    # Sort the docs by their RRF score, with the highest first\n",
    "    ranked = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return ranked[:top_k]  # Return top-k results as a list of (doc_id, final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0313 | toddler girls printed short sleeve tshirt  cat  jack\n",
      "0.0310 | girls disney princess friends make everything better short sleeve graphic tshirt  black\n",
      "0.0308 | wink pro womens snap front warmup jacket\n",
      "0.0305 | toddler boys39 dino graphic short sleeve graphic tshirt  cat 38 jack8482\n",
      "0.0303 | womens teddy bear pumpkin short sleeve graphic boyfriend tshirt  beige\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for TFIDF \n",
    "results = hybrid_search_tfidf(\"giacca da donna\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {italian_embeddings['title_italian'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 TF-IDF Alone Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "    \n",
    "    if lang == 'it':\n",
    "        query_vec = tfidf_vectorizer_it.transform([query])  # query vector\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_it)[0]  # cosine similarity with each doc\n",
    "    else:\n",
    "        query_vec = tfidf_vectorizer_en.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_en)[0]\n",
    "\n",
    "    # Rank documents by similarity\n",
    "    ranked_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Return top_k document indices with their similarity scores\n",
    "    top_results = [(int(idx), float(similarities[idx])) for idx in ranked_indices[:top_k]]\n",
    "    \n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3772 | timberland womens dunstan short sleeve tshirt\n",
      "0.3743 | womens linen short sleeve buttondown camp shirt  a new day\n",
      "0.3412 | womens fitted short sleeve tshirt  universal thread\n",
      "0.3339 | mens rocky mobilite waterproof work boot\n",
      "0.3271 | girls puffer jacket  all in motion\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for TFIDF alone\n",
    "results = TFIDF(\"giacca da donna\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {italian_embeddings['title'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Comparison of scores obtained using BM25 vs. Hybrid Retrieval Using NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_queries = [\n",
    "    \"men's white dress shirt\",\n",
    "    \"women's floral summer dress\",\n",
    "    \"black women's ankle boots\",\n",
    "    \"men's crewneck t-shirt\",\n",
    "    \"women's cropped denim jacket\"\n",
    "]\n",
    "\n",
    "italian_queries = [\n",
    "    \"camicia bianca da uomo\",                  # men's white dress shirt\n",
    "    \"vestito estivo floreale da donna\",        # women's floral summer dress\n",
    "    \"stivaletti neri da donna\",                # black women's ankle boots\n",
    "    \"maglietta girocollo uomo\",                # men's crewneck t-shirt\n",
    "    \"giacca di jeans corta da donna\"           # women's cropped denim jacket\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ground_truth_fashion.json\", \"r\") as f:\n",
    "    ground_truth = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Import NumPy for efficient numerical operations\n",
    "\n",
    "# --- Function to calculate Discounted Cumulative Gain (DCG) ---\n",
    "# DCG measures how good a ranked list is by rewarding relevant documents appearing earlier in the list\n",
    "def dcg(relevances):\n",
    "    # For each position i, divide the relevance score by log2(i+2) to apply discounting\n",
    "    # i + 2 ensures that the first position is divided by log2(2) = 1\n",
    "    return sum(rel / np.log2(i + 2) for i, rel in enumerate(relevances))\n",
    "\n",
    "# --- Function to calculate Normalized Discounted Cumulative Gain (NDCG) ---\n",
    "# NDCG compares the DCG of a predicted ranking to the ideal ranking\n",
    "def ndcg(ranked_ids, relevance_dict, k=5):\n",
    "    # Retrieve the relevance score for each of the top-k ranked document IDs\n",
    "    # If a doc ID is not in the relevance_dict, assume relevance = 0\n",
    "    relevances = [relevance_dict.get(str(doc_id), 0) for doc_id in ranked_ids[:k]]\n",
    "    \n",
    "    # Sort all known relevance scores in descending order to get the ideal ranking\n",
    "    ideal_relevances = sorted(relevance_dict.values(), reverse=True)[:k]\n",
    "    \n",
    "    # Compute NDCG as the ratio of actual DCG to ideal DCG\n",
    "    # If there are no ideal relevances (e.g., empty dict), return 0.0 to avoid division by zero\n",
    "    return dcg(relevances) / dcg(ideal_relevances) if ideal_relevances else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç NDCG Comparison (BM25 vs Hybrid RRF)\n",
      "\n",
      "Query: men's white dress shirt\n",
      "  NDCG@10 - BM25   : 0.0000\n",
      "  NDCG@10 - Hybrid : 0.1210\n",
      "----------------------------------------\n",
      "Query: women's floral summer dress\n",
      "  NDCG@10 - BM25   : 0.0692\n",
      "  NDCG@10 - Hybrid : 0.3230\n",
      "----------------------------------------\n",
      "Query: black women's ankle boots\n",
      "  NDCG@10 - BM25   : 0.0316\n",
      "  NDCG@10 - Hybrid : 0.0000\n",
      "----------------------------------------\n",
      "Query: men's crewneck t-shirt\n",
      "  NDCG@10 - BM25   : 0.0000\n",
      "  NDCG@10 - Hybrid : 0.0000\n",
      "----------------------------------------\n",
      "Query: women's cropped denim jacket\n",
      "  NDCG@10 - BM25   : 0.0000\n",
      "  NDCG@10 - Hybrid : 0.0000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of test queries from the ground truth dictionary\n",
    "test_queries = list(ground_truth.keys())\n",
    "\n",
    "# Evaluation depth: compute NDCG@10\n",
    "k = 10\n",
    "\n",
    "print(\" NDCG Comparison (BM25 vs Hybrid RRF)\\n\")\n",
    "\n",
    "# Loop through each test query\n",
    "for query in test_queries:\n",
    "    # gt: the ground truth relevance scores for documents related to this query\n",
    "    gt = ground_truth[query]\n",
    "    \n",
    "    # Get top-k ranked document IDs from BM25 (ignore scores)\n",
    "    bm25_ids = [doc_id for doc_id, _ in BM25(query, top_k=k)]\n",
    "\n",
    "    # Get top-k ranked document IDs from the hybrid RRF system\n",
    "    hybrid_ids = [doc_id for doc_id, _ in hybrid_search_rrf(query, top_k=k)]\n",
    "\n",
    "    # Compute NDCG score for BM25 rankings using the ground truth\n",
    "    score_bm25 = ndcg(bm25_ids, gt, k)\n",
    "\n",
    "    # Compute NDCG score for Hybrid (BM25 + semantic) rankings\n",
    "    score_hybrid = ndcg(hybrid_ids, gt, k)\n",
    "\n",
    "    # Print the results for this query\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"  NDCG@{k} - BM25   : {score_bm25:.4f}\")\n",
    "    print(f\"  NDCG@{k} - Hybrid : {score_hybrid:.4f}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hybrid Retrieval Phase for Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_spanish</th>\n",
       "      <th>english_embedding</th>\n",
       "      <th>spanish_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brother genuine high yield toner cartridge tn4...</td>\n",
       "      <td>hermano genuino cartucho t√≥ner de alto rendimi...</td>\n",
       "      <td>[-0.03431117, 0.025899883, -0.00967014, -0.019...</td>\n",
       "      <td>[0.012239528, 0.02652684, 0.002397126, -0.0288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fitbit inspire 3 health and fitness tracker wi...</td>\n",
       "      <td>fitbit inspirar 3 seguimiento de salud y fitne...</td>\n",
       "      <td>[-0.0016011602, -0.002595037, -0.07348455, 0.0...</td>\n",
       "      <td>[-0.011861571, -0.009732766, -0.06545575, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mikes hot honey americas 1 brand of hot honey ...</td>\n",
       "      <td>mikes miel caliente am√©ricas 1 marca de miel c...</td>\n",
       "      <td>[-0.0004525112, -0.009976895, -0.015700651, 0....</td>\n",
       "      <td>[-0.031901788, 0.017521167, -0.04371976, 0.039...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>krema kr√©ma red fruits 100 recyclable 240g</td>\n",
       "      <td>krema kr√©ma frutos rojos 100 reciclables 240g</td>\n",
       "      <td>[-0.011189645, 0.033041686, -0.005376764, -0.0...</td>\n",
       "      <td>[-0.013215443, 0.0015486346, -0.020853952, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drsalts calming therapy epsom salts  soothing ...</td>\n",
       "      <td>drsalts calmante terapia epsom sales calmantes...</td>\n",
       "      <td>[0.018024862, -0.015684763, -0.062142983, -0.0...</td>\n",
       "      <td>[0.008137982, 0.009916707, -0.07349886, -0.013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>ruimen smart watches for men women answermake ...</td>\n",
       "      <td>ruimen relojes inteligentes para hombres mujer...</td>\n",
       "      <td>[-0.022698322, 0.004262252, -0.06492456, -0.01...</td>\n",
       "      <td>[-0.015060791, 0.010321501, -0.057668064, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>musicozy sleep headphones bluetooth 54 headban...</td>\n",
       "      <td>auriculares musicozy sue√±o bluetooth 54 diadem...</td>\n",
       "      <td>[-0.0110038, 0.028441783, -0.065515295, 0.0328...</td>\n",
       "      <td>[0.006726083, 0.042338137, -0.0548927, 0.00642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>sun ninja pop up beach tent sun shelter upf50 ...</td>\n",
       "      <td>sun ninja pop up playa refugio de sol upf50 co...</td>\n",
       "      <td>[-0.018024122, -0.008911157, -0.09137453, 0.00...</td>\n",
       "      <td>[-0.0045234896, 0.003032705, -0.079418756, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>rhino usa trailer hitch pin 2 inch patented 58...</td>\n",
       "      <td>enganche de remolque de rinoceronte usa pin de...</td>\n",
       "      <td>[-0.011390688, -0.004701349, -0.009233302, 0.0...</td>\n",
       "      <td>[0.023057196, 0.013233271, 0.0004464224, 0.017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>sun ninja pop up beach tent sun shelter upf50 ...</td>\n",
       "      <td>sun ninja pop up playa tienda refugio de sol u...</td>\n",
       "      <td>[-0.010519517, -0.017002273, -0.08655271, 0.01...</td>\n",
       "      <td>[-0.0049236235, -0.005282401, -0.06757761, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    brother genuine high yield toner cartridge tn4...   \n",
       "1    fitbit inspire 3 health and fitness tracker wi...   \n",
       "2    mikes hot honey americas 1 brand of hot honey ...   \n",
       "3           krema kr√©ma red fruits 100 recyclable 240g   \n",
       "4    drsalts calming therapy epsom salts  soothing ...   \n",
       "..                                                 ...   \n",
       "991  ruimen smart watches for men women answermake ...   \n",
       "992  musicozy sleep headphones bluetooth 54 headban...   \n",
       "993  sun ninja pop up beach tent sun shelter upf50 ...   \n",
       "994  rhino usa trailer hitch pin 2 inch patented 58...   \n",
       "995  sun ninja pop up beach tent sun shelter upf50 ...   \n",
       "\n",
       "                                         title_spanish  \\\n",
       "0    hermano genuino cartucho t√≥ner de alto rendimi...   \n",
       "1    fitbit inspirar 3 seguimiento de salud y fitne...   \n",
       "2    mikes miel caliente am√©ricas 1 marca de miel c...   \n",
       "3        krema kr√©ma frutos rojos 100 reciclables 240g   \n",
       "4    drsalts calmante terapia epsom sales calmantes...   \n",
       "..                                                 ...   \n",
       "991  ruimen relojes inteligentes para hombres mujer...   \n",
       "992  auriculares musicozy sue√±o bluetooth 54 diadem...   \n",
       "993  sun ninja pop up playa refugio de sol upf50 co...   \n",
       "994  enganche de remolque de rinoceronte usa pin de...   \n",
       "995  sun ninja pop up playa tienda refugio de sol u...   \n",
       "\n",
       "                                     english_embedding  \\\n",
       "0    [-0.03431117, 0.025899883, -0.00967014, -0.019...   \n",
       "1    [-0.0016011602, -0.002595037, -0.07348455, 0.0...   \n",
       "2    [-0.0004525112, -0.009976895, -0.015700651, 0....   \n",
       "3    [-0.011189645, 0.033041686, -0.005376764, -0.0...   \n",
       "4    [0.018024862, -0.015684763, -0.062142983, -0.0...   \n",
       "..                                                 ...   \n",
       "991  [-0.022698322, 0.004262252, -0.06492456, -0.01...   \n",
       "992  [-0.0110038, 0.028441783, -0.065515295, 0.0328...   \n",
       "993  [-0.018024122, -0.008911157, -0.09137453, 0.00...   \n",
       "994  [-0.011390688, -0.004701349, -0.009233302, 0.0...   \n",
       "995  [-0.010519517, -0.017002273, -0.08655271, 0.01...   \n",
       "\n",
       "                                     spanish_embedding  \n",
       "0    [0.012239528, 0.02652684, 0.002397126, -0.0288...  \n",
       "1    [-0.011861571, -0.009732766, -0.06545575, -0.0...  \n",
       "2    [-0.031901788, 0.017521167, -0.04371976, 0.039...  \n",
       "3    [-0.013215443, 0.0015486346, -0.020853952, -0....  \n",
       "4    [0.008137982, 0.009916707, -0.07349886, -0.013...  \n",
       "..                                                 ...  \n",
       "991  [-0.015060791, 0.010321501, -0.057668064, -0.0...  \n",
       "992  [0.006726083, 0.042338137, -0.0548927, 0.00642...  \n",
       "993  [-0.0045234896, 0.003032705, -0.079418756, 0.0...  \n",
       "994  [0.023057196, 0.013233271, 0.0004464224, 0.017...  \n",
       "995  [-0.0049236235, -0.005282401, -0.06757761, 0.0...  \n",
       "\n",
       "[996 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the Spanish Embeddings\n",
    "spanish_embeddings = pd.read_pickle(\"en_to_sp_embeddings.pkl\")\n",
    "spanish_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building BM25 for Spanish\n",
    "entoes_english_titles = spanish_embeddings['title']\n",
    "entoes_spanish_titles = spanish_embeddings['title_spanish']\n",
    "\n",
    "entoes_tokenized_en = [title.split() for title in entoes_english_titles]\n",
    "entoes_tokenized_es = [title.split() for title in entoes_spanish_titles]\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "bm25_en = BM25Okapi(entoes_tokenized_en)\n",
    "bm25_es = BM25Okapi(entoes_tokenized_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is especially made for en and es, need to be redeclared for en and es\n",
    "def search(query, lang='en', top_k=5):\n",
    "    tokens = query.lower().split()\n",
    "    if lang == 'en':\n",
    "        scores = bm25_en.get_scores(tokens)\n",
    "    else:\n",
    "        scores = bm25_es.get_scores(tokens)\n",
    "    \n",
    "    top_k_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "    return top_k_ids, [scores[i] for i in top_k_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is made for en and es\n",
    "def search_bm25(query, top_k=5):\n",
    "    lang = detect(query)  # auto-detect 'en', 'es', etc.\n",
    "    tokens = query.lower().split()  # simple tokenization\n",
    "\n",
    "    if lang == 'es':\n",
    "        scores = bm25_es.get_scores(tokens)\n",
    "    else:\n",
    "        scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # Get top-k ranked indices\n",
    "    top_k_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "    return top_k_ids, [scores[i] for i in top_k_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4874 | brother genuine high yield toner cartridge tn450 replacement black toner page yield up to 2600 pages\n",
      "17.1048 | brother genuine tn436 super high yield toner black\n",
      "13.1930 | compatible toner cartridge replacement for brother tn770 tn770 toner for brother printer hll2370dw l2370dwxl mfcl2750dw l2750dwxl 4500 page black 2 pack\n",
      "6.3196 | lxtek compatible toner cartridge replacement for canon 137 black toner cartridge 137 crg137 to use with imageclass d570 mf232w mf242dw mf240 mf230 mf216n mf236n2 pack 137 black\n",
      "5.8940 | tokyoink 232xl ink cartridges combo pack replacement for epson 232 xl t232 ink cartridge for expression home xp4200 xp4205 workforce wf2930 wf2950 printer ink cartridge cyan magenta yellow black\n"
     ]
    }
   ],
   "source": [
    "results, scores = search_bm25(\"hermano genuino cartucho\")\n",
    "\n",
    "for i, score in zip(results, scores):\n",
    "    print(f\"{score:.4f} | {spanish_embeddings['title'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=CHERYL_API)\n",
    "#Initialising Pinecone index\n",
    "#This is the Index for entoes\n",
    "index = pc.Index('entoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids = [f\"en-{i}\" for i in range(len(spanish_embeddings['english_embedding']))]\n",
    "es_ids = [f\"es-{i}\" for i in range(len(spanish_embeddings['spanish_embedding']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine English + Spanish as before\n",
    "to_upsert = list(zip(en_ids, spanish_embeddings['english_embedding'])) + \\\n",
    "            list(zip(es_ids, spanish_embeddings['spanish_embedding']))\n",
    "\n",
    "# Run batch upload\n",
    "batch_upsert(index, to_upsert, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_to_ranking(scores: list[float]) -> list[int]:\n",
    "    \"\"\"Convert float scores into int rankings (1 = best).\"\"\"\n",
    "    return np.argsort(scores)[::-1] + 1  # ranks start at 1\n",
    "\n",
    "def rrf(keyword_rank: int, semantic_rank: int, k: int = 60) -> float:\n",
    "    \"\"\"Combine keyword rank and semantic rank into a hybrid score using RRF.\"\"\"\n",
    "    return 1 / (k + keyword_rank) + 1 / (k + semantic_rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 BM25 + BGE Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search_rrf(query, top_k=5):\n",
    "\n",
    "    #To detect the language from the query\n",
    "    from langdetect import detect\n",
    "\n",
    "    lang = detect(query)\n",
    "    #tokenising the query to be suitable for BM25\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # --- BM25 Retrieval ---(Routes the tokenized query to the appropiate BM25 engine)\n",
    "    if lang == 'es':\n",
    "        bm25_scores = bm25_es.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens) #returns a list of scores, one for each document in the dataset\n",
    "\n",
    "    bm25_ranks = scores_to_ranking(bm25_scores)  #Converts the float BM25 scores to rankings for Reciprocal rank fusion(rrf)\n",
    "\n",
    "    # --- Semantic Retrieval (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist() #generate the query's embedding and convert it a list\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k, include_metadata=False) #Submits the query vector to Pinecone to retrieve top-k similar vectors, based on cosine similarity\n",
    "\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']] #extracts og row index from pinecone's ID\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']] #Obtain cosine similarity scores from pinecone\n",
    "    semantic_ranks = scores_to_ranking(pinecone_scores) #Converting pinecone scores to ranks (lower rank = better match)\n",
    "\n",
    "    # --- Combine using RRF ---\n",
    "    combined_scores = {} #placeholder to store RRF combined scores for each shortlisted document\n",
    "    for idx in pinecone_ids:\n",
    "        #For each doc idx returned by pinecone\n",
    "        # Retrieve the BM25 rank and semantic rank, and using rrf function defined on prev cell to combine them into one score\n",
    "        rrf_score = rrf(\n",
    "            keyword_rank=bm25_ranks[idx],\n",
    "            semantic_rank=semantic_ranks[pinecone_ids.index(idx)]\n",
    "        )\n",
    "        combined_scores[idx] = rrf_score\n",
    "\n",
    "    # Sort by RRF score\n",
    "    ranked = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)  #Sorting the docs by their RRF score, with the highest first.\n",
    "\n",
    "    return ranked[:top_k]  # list of (doc_id, final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0194 | simplicity creative patterns sleeves for tops vest jackets coats a 10121416182022\n",
      "0.0189 | fit  fresh lunch bag for women insulated womens lunch bag for work leakproof  stainresistant large lunch box for women with containers tumbler  ice pack zipper closure wichita bag palm leaves\n",
      "0.0166 | artelaris lunch backpack for women stylish insulated backpack for women waterproof travel backpack lunch bag womens cooler backpack lunchbox backpack for teacher nurse work picnic book bag\n"
     ]
    }
   ],
   "source": [
    "#Testing phase\n",
    "results = hybrid_search_rrf(\"chaqueta de mujer\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {spanish_embeddings['title'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 BM25 Alone Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(query, top_k=5):\n",
    "    #To detect the language from the query\n",
    "    lang = detect(query)\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # Score retrieval\n",
    "    if lang == 'es':\n",
    "        bm25_scores = bm25_es.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    bm25_ranks = scores_to_ranking(bm25_scores)  #Converts the float BM25 scores to rankings for Reciprocal rank fusion(rrf)\n",
    "\n",
    "    # Sort by RRF score\n",
    "    top_k_ids = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:top_k]  #Sorting the docs by their RRF score, with the highest first.\n",
    "\n",
    "    return [(i, bm25_scores[i]) for i in top_k_ids]  #Returns a list of (document ID, score) pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BM25(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform BM25 keyword search based on query language.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's search query.\n",
    "        top_k (int): Number of top documents to return.\n",
    "\n",
    "    Returns:\n",
    "        list of (doc_id, bm25_score)\n",
    "    \"\"\"\n",
    "    #To detect the language from the query\n",
    "    from langdetect import detect\n",
    "    lang = detect(query)\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # Score retrieval\n",
    "    if lang == 'es':\n",
    "        bm25_scores = bm25_es.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # Get top-k doc IDs based on raw BM25 scores\n",
    "    top_k_ids = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:top_k]\n",
    "    \n",
    "    return [(i, bm25_scores[i]) for i in top_k_ids] #Returns a list of (document ID, score) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.6092 | christian art gifts wide mouth bpafree reusable plastic sports water bottle for men  women inspirational scripture wlocking fliptop lid  carry strap 28 oz\n",
      "6.4951 | one a day womens active metabolism multivitamin supplement with vitamin a c d e and zinc for immune health support iron calcium folic acid  more 50 count\n",
      "6.3409 | huefull gua sha facial tools  jade roller set for skin care reduce puffiness and improve wrinkles guasha tool for face gua sha stone self care gift for woman man christmas gifts\n",
      "6.1578 | smartypants womens multivitamin gummies sugar free biotin methylfolate omega 3 ala vitamin d3 c vitamin b12 b6 vitamin a k  zinc gluten free 60 count 20 day supply\n",
      "4.8513 | skg smart watch for men women android iphone with alexa builtin  bluetooth callanswermake call 169 fitness tracker with ip68 waterproof 60 sports heart rate spo2 monitor v7 pro\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for BM25\n",
    "results = BM25(\"chaqueta de mujer\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {spanish_embeddings['title'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 TF-IDF + BGE Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For both Sparse and Sparse + Dense\n",
    "tfidf_vectorizer_en = TfidfVectorizer()\n",
    "tfidf_matrix_en = tfidf_vectorizer_en.fit_transform(spanish_embeddings['title'])\n",
    "\n",
    "tfidf_vectorizer_es = TfidfVectorizer()\n",
    "tfidf_matrix_es = tfidf_vectorizer_es.fit_transform(spanish_embeddings['title_spanish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search_tfidf(query, top_k=5):\n",
    "\n",
    "    from langdetect import detect\n",
    "    lang = detect(query)\n",
    "    \n",
    "    if lang == 'es':\n",
    "        query_vec = tfidf_vectorizer_es.transform([query])  # query vector\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_es)[0]  # cosine similarity with each doc\n",
    "    else:\n",
    "        query_vec = tfidf_vectorizer_en.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_en)[0]  # Cosine similarity for English\n",
    "\n",
    "    ranked_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Return top_k document indices with their similarity scores\n",
    "    tfidf_rank_map = {int(idx): rank for rank, idx in enumerate(ranked_indices[:top_k], start=1)}\n",
    "\n",
    "    # --- Semantic Retrieval (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist() \n",
    "\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k * 2, include_metadata=False)\n",
    "\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']]\n",
    "\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']]\n",
    "\n",
    "    semantic_ranks = scores_to_ranking(pinecone_scores)\n",
    "\n",
    "    semantic_rank_map = {idx: rank for idx, rank in zip(pinecone_ids, semantic_ranks)}\n",
    "\n",
    "    # --- Combine using RRF ---\n",
    "    combined_scores = {}\n",
    "\n",
    "    for idx in pinecone_ids:\n",
    "        rrf_score = rrf(\n",
    "            keyword_rank=tfidf_rank_map.get(idx, top_k + 1),  # Fallback rank if not found in BM25\n",
    "            semantic_rank=semantic_rank_map.get(idx, top_k + 1)  # Fallback rank if not found in semantic\n",
    "        )\n",
    "        combined_scores[idx] = rrf_score  # Store the fused score\n",
    "\n",
    "    ranked = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return ranked[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0310 | simplicity creative patterns sleeves for tops vest jackets coats a 10121416182022\n",
      "0.0305 | fit  fresh lunch bag for women insulated womens lunch bag for work leakproof  stainresistant large lunch box for women with containers tumbler  ice pack zipper closure wichita bag palm leaves\n",
      "0.0301 | artelaris lunch backpack for women stylish insulated backpack for women waterproof travel backpack lunch bag womens cooler backpack lunchbox backpack for teacher nurse work picnic book bag\n",
      "0.0299 | vlando viaggio small jewelry case box travel essential accessories for women gifts for travelers couples mom friends bridesmaid\n",
      "0.0296 | indressme cotton basket 17¬æ x 15¬æ x 13¬æ inches woven hamper pink girl basket for gift toy blanket corner basket in living room\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for TFIDF\n",
    "\n",
    "results = hybrid_search_tfidf(\"chaqueta de mujer\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {spanish_embeddings['title'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 TFIDF Alone Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "    \n",
    "    if lang == 'es':\n",
    "        query_vec = tfidf_vectorizer_es.transform([query])  # query vector\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_es)[0]  # cosine similarity with each doc\n",
    "    else:\n",
    "        query_vec = tfidf_vectorizer_en.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_en)[0]\n",
    "\n",
    "    # Rank documents by similarity\n",
    "    ranked_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Return top_k document indices with their similarity scores\n",
    "    top_results = [(int(idx), float(similarities[idx])) for idx in ranked_indices[:top_k]]\n",
    "    \n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2474 | suplemento multivitam√≠nico del metabolismo activo de una mujer al d√≠a con vitamina a c d e y zinc para el apoyo de la salud inmune hierro calcio √°cido f√≥lico m√°s 50 recuento\n",
      "0.2248 | skg reloj inteligente para hombres mujer iphone android con alexa incorporado bluetooth callanswermake llamada 169 fitness tracker con ip68 impermeable 60 deportes frecuencia card√≠aca spo2 monitor v7 pro\n",
      "0.2248 | arte cristiano regalos boca ancha bpafree reutilizable pl√°stico deportes botella de agua para los hombres mujer inspiraci√≥n escritura wlocking fliptop tapa llevar correa 28 oz\n",
      "0.2034 | smartypants mujer gomas multivitam√≠nicas az√∫car libre de biotina metilfolato omega 3 ala vitamina d3 c vitamina b12 b6 vitamina a k zinc sin gluten 60 cuenta 20 d√≠as suministro\n",
      "0.1855 | huefull gua sha herramientas faciales jade juego de rodillos para el cuidado de la piel reducir la hinchaz√≥n y mejorar las arrugas guasha herramienta para cara gua sha piedra auto cuidado regalo para mujer hombre regalos de Navidad\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for TFIDF\n",
    "\n",
    "results = TFIDF(\"chaqueta de mujer\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {spanish_embeddings['title_spanish'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hybrid Retrieval Phase for CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>chinese translation</th>\n",
       "      <th>english_embedding</th>\n",
       "      <th>chinese_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oppo A75 A75S A73 Phone Case Soft Rabbit Silic...</td>\n",
       "      <td>OPPO A75 A75s A73 ÊâãÊú∫Â£≥ ËΩØÂ£≥ ÊåÇÁª≥Â£≥ Â§ßÁúºÂÖîÁ°ÖËÉ∂Â£≥</td>\n",
       "      <td>[-0.030606616, 0.010501585, -0.04400219, -0.00...</td>\n",
       "      <td>[-0.020788355, 0.032136466, -0.03952156, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOFT 99 Coating Car Wax Strong Water Watt</td>\n",
       "      <td>SOFT 99 ÈççËÜúËªäË†ü(Âº∑ÂäõÊí•Ê∞¥Âûã)</td>\n",
       "      <td>[-0.02521394, -0.0062141055, -0.02523462, -0.0...</td>\n",
       "      <td>[-0.013580757, -0.013445883, 0.013568486, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Low Sugar Mango Dry 250g Be The Royal</td>\n",
       "      <td>‰ΩéÁ≥ñËäíÊûú‰πæ 250g ËáªÂæ°Ë°å</td>\n",
       "      <td>[-0.06998538, 0.025515176, -0.006934945, -0.02...</td>\n",
       "      <td>[-0.056555215, 0.015317621, 0.0015813652, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* the culture Japan Imported Round Top Space C...</td>\n",
       "      <td>ÔºäÂ∞èÂæëÊñáÂåñÔºäÊó•Êú¨ÈÄ≤Âè£ROUND TOP space craft - diamond (SC-...</td>\n",
       "      <td>[-0.003708915, 0.024768945, -0.062792934, 0.02...</td>\n",
       "      <td>[-0.018781146, 0.033165023, -0.05913993, 0.019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello Kitty Sandals Shoes White/Red Children n...</td>\n",
       "      <td>Hello Kitty Âá±ËíÇË≤ì KITTY Ê∂ºÈûã Á´•Èûã ÁôΩ/Á¥ÖËâ≤ Â∞èÁ´• no739</td>\n",
       "      <td>[-0.019042147, 0.031313036, -0.06666778, 0.049...</td>\n",
       "      <td>[-0.043943617, 0.021419879, -0.059569906, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Hippored Torn Fun Unique Style Straight Jeans ...</td>\n",
       "      <td>„ÄêHippoRed„ÄëÊíïÁ†¥‰πêË∂£‚òÖÁã¨ÁâπÈ£éÊ†º‚òÖ‰∏≠Áõ¥Á≠íÁâõ‰ªîË£§ O591_445</td>\n",
       "      <td>[-0.015312562, 0.002696402, -0.046150953, 0.00...</td>\n",
       "      <td>[-0.04397009, -0.013235806, -0.034632586, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Kids Set Table Bay - Thin Long Sleeve Home Sui...</td>\n",
       "      <td>ÂÖíÁ´•Â•óË£ù Âè∞ÁÅ£Ë£ΩËñÑÈï∑Ë¢ñÂ±ÖÂÆ∂Â•óË£ù È≠îÊ≥ïBaby~k60092</td>\n",
       "      <td>[-0.00460147, 0.029976973, -0.080628425, 0.003...</td>\n",
       "      <td>[0.00086109334, 0.012746421, -0.04744607, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>LONGCHAMP Le Pliage Neo High Density Nylon Bac...</td>\n",
       "      <td>LONGCHAMP Le Pliage NeoÈ´òÂØÜÂ∞ºÈæçÂæåËÉåÂåÖ(‰∏≠Âûã)</td>\n",
       "      <td>[-0.025269749, -0.050276544, -0.059641942, -0....</td>\n",
       "      <td>[-0.0399163, -0.031578567, -0.04178574, 0.0254...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>IFairies Opening Adjustable Ring ifairies [564...</td>\n",
       "      <td>iFairies ÈñãÂè£ÂèØË™øÁØÄÊàíÊåá‚òÖifairies„Äê56472„Äë„Äê56472„Äë</td>\n",
       "      <td>[0.018464142, 0.016518341, -0.034174442, 0.007...</td>\n",
       "      <td>[0.029656759, 0.03718795, -0.042785533, -0.027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>PolarStar Women Sweat Quick Dry T-shirt Black ...</td>\n",
       "      <td>PolarStar Â•≥ ÊéíÊ±óÂø´Âπ≤TÊÅ§„ÄéÈªë„ÄèP18102</td>\n",
       "      <td>[-0.015415181, 0.011347521, -0.09535644, -0.01...</td>\n",
       "      <td>[0.029322254, -0.00047185787, -0.0952496, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Oppo A75 A75S A73 Phone Case Soft Rabbit Silic...   \n",
       "1            SOFT 99 Coating Car Wax Strong Water Watt   \n",
       "2                Low Sugar Mango Dry 250g Be The Royal   \n",
       "3    * the culture Japan Imported Round Top Space C...   \n",
       "4    Hello Kitty Sandals Shoes White/Red Children n...   \n",
       "..                                                 ...   \n",
       "995  Hippored Torn Fun Unique Style Straight Jeans ...   \n",
       "996  Kids Set Table Bay - Thin Long Sleeve Home Sui...   \n",
       "997  LONGCHAMP Le Pliage Neo High Density Nylon Bac...   \n",
       "998  IFairies Opening Adjustable Ring ifairies [564...   \n",
       "999  PolarStar Women Sweat Quick Dry T-shirt Black ...   \n",
       "\n",
       "                                   chinese translation  \\\n",
       "0                  OPPO A75 A75s A73 ÊâãÊú∫Â£≥ ËΩØÂ£≥ ÊåÇÁª≥Â£≥ Â§ßÁúºÂÖîÁ°ÖËÉ∂Â£≥   \n",
       "1                                  SOFT 99 ÈççËÜúËªäË†ü(Âº∑ÂäõÊí•Ê∞¥Âûã)   \n",
       "2                                       ‰ΩéÁ≥ñËäíÊûú‰πæ 250g ËáªÂæ°Ë°å   \n",
       "3    ÔºäÂ∞èÂæëÊñáÂåñÔºäÊó•Êú¨ÈÄ≤Âè£ROUND TOP space craft - diamond (SC-...   \n",
       "4            Hello Kitty Âá±ËíÇË≤ì KITTY Ê∂ºÈûã Á´•Èûã ÁôΩ/Á¥ÖËâ≤ Â∞èÁ´• no739   \n",
       "..                                                 ...   \n",
       "995                „ÄêHippoRed„ÄëÊíïÁ†¥‰πêË∂£‚òÖÁã¨ÁâπÈ£éÊ†º‚òÖ‰∏≠Áõ¥Á≠íÁâõ‰ªîË£§ O591_445   \n",
       "996                      ÂÖíÁ´•Â•óË£ù Âè∞ÁÅ£Ë£ΩËñÑÈï∑Ë¢ñÂ±ÖÂÆ∂Â•óË£ù È≠îÊ≥ïBaby~k60092   \n",
       "997                 LONGCHAMP Le Pliage NeoÈ´òÂØÜÂ∞ºÈæçÂæåËÉåÂåÖ(‰∏≠Âûã)   \n",
       "998            iFairies ÈñãÂè£ÂèØË™øÁØÄÊàíÊåá‚òÖifairies„Äê56472„Äë„Äê56472„Äë   \n",
       "999                        PolarStar Â•≥ ÊéíÊ±óÂø´Âπ≤TÊÅ§„ÄéÈªë„ÄèP18102   \n",
       "\n",
       "                                     english_embedding  \\\n",
       "0    [-0.030606616, 0.010501585, -0.04400219, -0.00...   \n",
       "1    [-0.02521394, -0.0062141055, -0.02523462, -0.0...   \n",
       "2    [-0.06998538, 0.025515176, -0.006934945, -0.02...   \n",
       "3    [-0.003708915, 0.024768945, -0.062792934, 0.02...   \n",
       "4    [-0.019042147, 0.031313036, -0.06666778, 0.049...   \n",
       "..                                                 ...   \n",
       "995  [-0.015312562, 0.002696402, -0.046150953, 0.00...   \n",
       "996  [-0.00460147, 0.029976973, -0.080628425, 0.003...   \n",
       "997  [-0.025269749, -0.050276544, -0.059641942, -0....   \n",
       "998  [0.018464142, 0.016518341, -0.034174442, 0.007...   \n",
       "999  [-0.015415181, 0.011347521, -0.09535644, -0.01...   \n",
       "\n",
       "                                     chinese_embedding  \n",
       "0    [-0.020788355, 0.032136466, -0.03952156, -0.04...  \n",
       "1    [-0.013580757, -0.013445883, 0.013568486, -0.0...  \n",
       "2    [-0.056555215, 0.015317621, 0.0015813652, -0.0...  \n",
       "3    [-0.018781146, 0.033165023, -0.05913993, 0.019...  \n",
       "4    [-0.043943617, 0.021419879, -0.059569906, 0.03...  \n",
       "..                                                 ...  \n",
       "995  [-0.04397009, -0.013235806, -0.034632586, 0.03...  \n",
       "996  [0.00086109334, 0.012746421, -0.04744607, 0.00...  \n",
       "997  [-0.0399163, -0.031578567, -0.04178574, 0.0254...  \n",
       "998  [0.029656759, 0.03718795, -0.042785533, -0.027...  \n",
       "999  [0.029322254, -0.00047185787, -0.0952496, -0.0...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the Chinese Embeddings\n",
    "chinese_embeddings = pd.read_pickle(\"en_to_cn_embeddings.pkl\")\n",
    "chinese_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building BM25 for Chinese\n",
    "entocn_english_titles = chinese_embeddings['title']\n",
    "entocn_chinese_titles = chinese_embeddings['chinese translation']\n",
    "\n",
    "entocn_tokenized_en = [title.split() for title in entocn_english_titles]\n",
    "#entocn_tokenized_cn = [title.split() for title in entocn_chinese_titles]\n",
    "\n",
    "#Using jieba for Chinese tokenization\n",
    "import jieba\n",
    "#entocn_tokenized_en = [list(jieba.cut(title)) for title in entocn_english_titles]\n",
    "entocn_tokenized_cn = [list(jieba.cut(title)) for title in entocn_chinese_titles]\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "bm25_en = BM25Okapi(entocn_tokenized_en)\n",
    "bm25_cn = BM25Okapi(entocn_tokenized_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaner\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"[^\\u4e00-\\u9fa5a-zA-Z0-9]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# Clean + tokenize\n",
    "entocn_chinese_titles = chinese_embeddings['chinese translation'].apply(clean_text)\n",
    "entocn_tokenized_cn = [list(jieba.cut(title)) for title in entocn_chinese_titles]\n",
    "\n",
    "# Build BM25 index\n",
    "bm25_cn = BM25Okapi(entocn_tokenized_cn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is especially made for en and it, need to be redeclared for cn\n",
    "def search(query, lang='en', top_k=5):\n",
    "    tokens = query.lower().split()\n",
    "    if lang == 'en':\n",
    "        scores = bm25_en.get_scores(tokens)\n",
    "    else:\n",
    "        scores = bm25_cn.get_scores(tokens)\n",
    "    \n",
    "    top_k_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "    return top_k_ids, [scores[i] for i in top_k_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_bm25(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "\n",
    "    # Tokenize appropriately based on detected language\n",
    "    if lang in ['zh', 'zh-cn', 'cn']:\n",
    "        tokens = list(jieba.cut(query))\n",
    "        scores = bm25_cn.get_scores(tokens)\n",
    "    else:\n",
    "        tokens = query.lower().split()\n",
    "        scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # Get top-k ranked document indices\n",
    "    top_k_ids = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "\n",
    "    return top_k_ids, [scores[i] for i in top_k_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000 | Oppo A75 A75S A73 Phone Case Soft Rabbit Silicone Case\n",
      "0.0000 | SOFT 99 Coating Car Wax Strong Water Watt\n",
      "0.0000 | Low Sugar Mango Dry 250g Be The Royal\n",
      "0.0000 | * the culture Japan Imported Round Top Space Craft - Diamond SC - MK - 010\n",
      "0.0000 | Hello Kitty Sandals Shoes White/Red Children no739\n"
     ]
    }
   ],
   "source": [
    "results, scores = search_bm25(\"Â•≥ ÊéíÊ±ó\")\n",
    "\n",
    "for i, score in zip(results, scores):\n",
    "    print(f\"{score:.4f} | {chinese_embeddings['title'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "#This is Cheryl's API\n",
    "pc = Pinecone(api_key=CHERYL_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising Pinecone index\n",
    "#This is the Index for the ENTOIT\n",
    "index = pc.Index('entocn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids = [f\"en-{i}\" for i in range(len(chinese_embeddings['english_embedding']))]\n",
    "cn_ids = [f\"cn-{i}\" for i in range(len(chinese_embeddings['chinese_embedding']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine English + Chinese as before\n",
    "to_upsert = list(zip(en_ids, chinese_embeddings['english_embedding'])) + \\\n",
    "            list(zip(cn_ids, chinese_embeddings['chinese_embedding']))\n",
    "\n",
    "# Run batch upload\n",
    "batch_upsert(index, to_upsert, batch_size=50)\n",
    "\n",
    "\n",
    "#With this code, the vectorDB has been established for en to cn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def scores_to_ranking(scores: list[float]) -> list[int]:\n",
    "    \"\"\"Convert float scores into int rankings (1 = best).\"\"\"\n",
    "    return np.argsort(scores)[::-1] + 1  # ranks start at 1\n",
    "\n",
    "def rrf(keyword_rank: int, semantic_rank: int, k: int = 60) -> float:\n",
    "    \"\"\"Combine keyword rank and semantic rank into a hybrid score using RRF.\"\"\"\n",
    "    return 1 / (k + keyword_rank) + 1 / (k + semantic_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 BM25 + BGE Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search_rrf(query, top_k=5):\n",
    "\n",
    "    #To detect the language from the query\n",
    "    from langdetect import detect\n",
    "\n",
    "    lang = detect(query)\n",
    "    #tokenising the query to be suitable for BM25\n",
    "    tokens = list(jieba.cut(query))\n",
    "\n",
    "    # --- BM25 Retrieval ---(Routes the tokenized query to the appropiate BM25 engine)\n",
    "    if lang == 'cn':\n",
    "        bm25_scores = bm25_cn.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens) #returns a list of scores, one for each document in the dataset\n",
    "\n",
    "    bm25_ranks = scores_to_ranking(bm25_scores)  #Converts the float BM25 scores to rankings for Reciprocal rank fusion(rrf)\n",
    "\n",
    "    # --- Semantic Retrieval (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist() #generate the query's embedding and convert it a list\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k, include_metadata=False) #Submits the query vector to Pinecone to retrieve top-k similar vectors, based on cosine similarity\n",
    "\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']] #extracts og row index from pinecone's ID\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']] #Obtain cosine similarity scores from pinecone\n",
    "    semantic_ranks = scores_to_ranking(pinecone_scores) #Converting pinecone scores to ranks (lower rank = better match)\n",
    "\n",
    "    # --- Combine using RRF ---\n",
    "    combined_scores = {} #placeholder to store RRF combined scores for each shortlisted document\n",
    "    for idx in pinecone_ids:\n",
    "        #For each doc idx returned by pinecone\n",
    "        # Retrieve the BM25 rank and semantic rank, and using rrf function defined on prev cell to combine them into one score\n",
    "        rrf_score = rrf(\n",
    "            keyword_rank=bm25_ranks[idx],\n",
    "            semantic_rank=semantic_ranks[pinecone_ids.index(idx)]\n",
    "        )\n",
    "        combined_scores[idx] = rrf_score\n",
    "\n",
    "    # Sort by RRF score\n",
    "    ranked = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)  #Sorting the docs by their RRF score, with the highest first.\n",
    "\n",
    "    return ranked[:top_k]  # list of (doc_id, final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0246 | College Sexy Pleated Culottes\n",
      "0.0237 | Long version Pocket Cardigan Knit Coat\n",
      "0.0192 | Korean Made. Thick Straps Cross Vest\n",
      "0.0170 | Two-piece Set Thick Thread Coat + Skirt M - XXL\n"
     ]
    }
   ],
   "source": [
    "#Testing phase\n",
    "\n",
    "results = hybrid_search_rrf(\"Â•≥ÂºèÂ§πÂÖã\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {chinese_embeddings['title'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 BM25 Alone Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(query, top_k=5):\n",
    "\n",
    "    #To detect the language from the query\n",
    "    from langdetect import detect\n",
    "\n",
    "    lang = detect(query)\n",
    "    #tokenising the query to be suitable for BM25\n",
    "    tokens = list(jieba.cut(query))\n",
    "\n",
    "    # --- BM25 Retrieval ---(Routes the tokenized query to the appropiate BM25 engine)\n",
    "    if lang == 'cn':\n",
    "        bm25_scores = bm25_cn.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens) #returns a list of scores, one for each document in the dataset\n",
    "\n",
    "    bm25_ranks = {i: rank for rank, i in enumerate(np.argsort(bm25_scores)[::-1], start=1)} #Converts the float BM25 scores to rankings for Reciprocal rank fusion(rrf)\n",
    "\n",
    "    # Sort by RRF score\n",
    "    ranked = sorted(bm25_ranks.items(), key=lambda x: x[1], reverse=True)  #Sorting the docs by their RRF score, with the highest first.\n",
    "\n",
    "    return ranked[:top_k]  # list of (doc_id, final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0000 | Oppo A75 A75S A73 Phone Case Soft Rabbit Silicone Case\n",
      "999.0000 | Tree De Sc Multifunctional Locker - Scm3 - 3M6S\n",
      "998.0000 | COGHLANS Canada 0044 Finger Compass Thermometer Whistle\n",
      "997.0000 | [With Incense] Jujube Pack 5 Pc / Pack (2 Pack) „Äê\n",
      "996.0000 | Japan gex schisandra Kittens Water Dispenser 900Ml GE2316\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for BM 25\n",
    "\n",
    "results = BM25(\"Â•≥ÂºèÂ§πÂÖã\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {chinese_embeddings['title'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 TFIDF + BGE Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For both Sparse and Sparse + Dense\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer_en = TfidfVectorizer()\n",
    "tfidf_matrix_en = tfidf_vectorizer_en.fit_transform(chinese_embeddings['title'])\n",
    "\n",
    "tfidf_vectorizer_cn = TfidfVectorizer()\n",
    "tfidf_matrix_cn = tfidf_vectorizer_cn.fit_transform(chinese_embeddings['chinese translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search_tfidf(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "\n",
    "    # --- TF-IDF Query Vectorization ---\n",
    "    if lang in ['zh', 'zh-cn', 'cn']:\n",
    "        tokens = list(jieba.cut(query))\n",
    "        query_joined = \" \".join(tokens)  # convert token list to string input\n",
    "        query_vec = tfidf_vectorizer_cn.transform([query_joined])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_cn)[0]\n",
    "    else:\n",
    "        query_vec = tfidf_vectorizer_en.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_en)[0]\n",
    "\n",
    "    # --- TF-IDF Ranking Map (doc_id ‚Üí rank) ---\n",
    "    ranked_indices = np.argsort(similarities)[::-1]\n",
    "    tfidf_rank_map = {int(idx): rank for rank, idx in enumerate(ranked_indices[:top_k], start=1)}\n",
    "\n",
    "    # --- Semantic Retrieval (Pinecone) ---\n",
    "    query_vec_dense = model.encode(query).tolist()\n",
    "    pinecone_results = index.query(vector=query_vec_dense, top_k=top_k * 2, include_metadata=False)\n",
    "\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']]\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']]\n",
    "\n",
    "    # Convert scores to semantic ranks (lower = better)\n",
    "    semantic_ranks = scores_to_ranking(pinecone_scores)\n",
    "    semantic_rank_map = {idx: rank for idx, rank in zip(pinecone_ids, semantic_ranks)}\n",
    "\n",
    "    # --- Reciprocal Rank Fusion (RRF) ---\n",
    "    combined_scores = {}\n",
    "    for idx in pinecone_ids:\n",
    "        rrf_score = rrf(\n",
    "            keyword_rank=tfidf_rank_map.get(idx, top_k + 1),\n",
    "            semantic_rank=semantic_rank_map.get(idx, top_k + 1)\n",
    "        )\n",
    "        combined_scores[idx] = rrf_score\n",
    "\n",
    "    # Sort by final RRF score\n",
    "    ranked = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return ranked[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0313 | Èü©Âà∂„ÄÇÁ≤óËÇ©Â∏¶‰∫§ÂèâËÉåÂøÉ\n",
      "0.0308 | Â≠¶Èô¢ÊÑüÁôæË§∂Ë£§Ë£ô\n",
      "0.0305 | ÁèæË≤®-ÂÖ©‰ª∂ÂºèÂ•óË£ùÂä†ÂéöËû∫Á¥ãÂ§ñÂ•ó+Èï∑Ë£ô M-XXL\n",
      "0.0303 | üéÄÁúüÁöÆÂ•≥Áî®Â∞èÊâãÊèê/ÊñúËÉå‰∫åÁî®ÂåÖüéÄ\n",
      "0.0301 | Èï∑ÁâàÂè£Ë¢ãÈñãË•üÈáùÁπîÂ§ñÂ•ó\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for TFIDF + BGE\n",
    "\n",
    "results = hybrid_search_tfidf(\"Â•≥ÂºèÂ§πÂÖã\")\n",
    "\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {chinese_embeddings['chinese translation'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 TF-IDF Alone Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "\n",
    "    # --- TF-IDF Query Vectorization ---\n",
    "    if lang in ['zh', 'zh-cn', 'cn']:\n",
    "        tokens = list(jieba.cut(query))\n",
    "        query_joined = \" \".join(tokens)  # convert token list to string input\n",
    "        query_vec = tfidf_vectorizer_cn.transform([query_joined])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_cn)[0]\n",
    "    else:\n",
    "        query_vec = tfidf_vectorizer_en.transform([query])\n",
    "        similarities = cosine_similarity(query_vec, tfidf_matrix_en)[0]\n",
    "\n",
    "    # --- TF-IDF Ranking Map (doc_id ‚Üí rank) ---\n",
    "    ranked_indices = np.argsort(similarities)[::-1]\n",
    "    tfidf_rank_map = {int(idx): rank for rank, idx in enumerate(ranked_indices[:top_k], start=1)}\n",
    "    \n",
    "    return tfidf_rank_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000 | PolarStar Â•≥ ÊéíÊ±óÂø´Âπ≤TÊÅ§„ÄéÈªë„ÄèP18102\n",
      "2.0000 | ALPINE PARTY PLUG PRO È†ÇÁ¥ö Èü≥Ê®ÇËÄ≥Â°û ËÅ≤Èü≥ÊøæÊ≥¢Âô® Ëç∑Ëò≠ÈÄ≤Âè£ 20816\n",
      "3.0000 | ÊôÇÂ∞öÁ∞°Á¥ÑÂØ¶Áî®Êä±Êûï109 Èù†Â¢ä Ê≤ôÁôºË£ùÈ£æÈù†Êûï\n",
      "4.0000 | ÂØ∂ÂØ∂Â§ñÂ•ó ÊØõÂúàÊãâÈçä‰ºëÈñíÂ§ñÂ•óÂ§æÂÖã UG13220 Â•ΩÂ®ÉÂ®É\n",
      "5.0000 | Ëá™Âº∑Áâå A480 Ë≥áÊñôÂ§æ / ÁÆ±\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for TFIDF + BGE\n",
    "\n",
    "results = TFIDF(\"Â•≥ÂºèÂ§πÂÖã\")\n",
    "\n",
    "for idx, score in results.items():\n",
    "    print(f\"{score:.4f} | {chinese_embeddings['chinese translation'][idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
