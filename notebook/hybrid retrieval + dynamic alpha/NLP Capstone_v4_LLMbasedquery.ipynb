{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this phase is to deploy Dynamic Alpha Tuning, which is a Novel framework that adaptively adjusts the retrieval weighting coefficient based on \n",
    "query-specific characteristics.\n",
    "\n",
    "It contains a hybrid weighting parameter alpha, for each query that should reflect the relative effectiveness of sparse and dense methods.\n",
    "\n",
    "We have done the LLM-Based retrieval effectiveness scoring for all 3 languages, but reference to be taken from the Italian Language, which has been integrated in the main solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Phase 3 (Chinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "CHARRAN_API = os.getenv('CHARRAN_API')\n",
    "CHERYL_API = os.getenv('CHERYL_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>chinese translation</th>\n",
       "      <th>english_embedding</th>\n",
       "      <th>chinese_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oppo A75 A75S A73 Phone Case Soft Rabbit Silic...</td>\n",
       "      <td>OPPO A75 A75s A73 æ‰‹æœºå£³ è½¯å£³ æŒ‚ç»³å£³ å¤§çœ¼å…”ç¡…èƒ¶å£³</td>\n",
       "      <td>[-0.030606616, 0.010501585, -0.04400219, -0.00...</td>\n",
       "      <td>[-0.020788355, 0.032136466, -0.03952156, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOFT 99 Coating Car Wax Strong Water Watt</td>\n",
       "      <td>SOFT 99 éè†œè»Šè Ÿ(å¼·åŠ›æ’¥æ°´å‹)</td>\n",
       "      <td>[-0.02521394, -0.0062141055, -0.02523462, -0.0...</td>\n",
       "      <td>[-0.013580757, -0.013445883, 0.013568486, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Low Sugar Mango Dry 250g Be The Royal</td>\n",
       "      <td>ä½ç³–èŠ’æœä¹¾ 250g è‡»å¾¡è¡Œ</td>\n",
       "      <td>[-0.06998538, 0.025515176, -0.006934945, -0.02...</td>\n",
       "      <td>[-0.056555215, 0.015317621, 0.0015813652, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* the culture Japan Imported Round Top Space C...</td>\n",
       "      <td>ï¼Šå°å¾‘æ–‡åŒ–ï¼Šæ—¥æœ¬é€²å£ROUND TOP space craft - diamond (SC-...</td>\n",
       "      <td>[-0.003708915, 0.024768945, -0.062792934, 0.02...</td>\n",
       "      <td>[-0.018781146, 0.033165023, -0.05913993, 0.019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello Kitty Sandals Shoes White/Red Children n...</td>\n",
       "      <td>Hello Kitty å‡±è’‚è²“ KITTY æ¶¼é‹ ç«¥é‹ ç™½/ç´…è‰² å°ç«¥ no739</td>\n",
       "      <td>[-0.019042147, 0.031313036, -0.06666778, 0.049...</td>\n",
       "      <td>[-0.043943617, 0.021419879, -0.059569906, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Hippored Torn Fun Unique Style Straight Jeans ...</td>\n",
       "      <td>ã€HippoRedã€‘æ’•ç ´ä¹è¶£â˜…ç‹¬ç‰¹é£æ ¼â˜…ä¸­ç›´ç­’ç‰›ä»”è£¤ O591_445</td>\n",
       "      <td>[-0.015312562, 0.002696402, -0.046150953, 0.00...</td>\n",
       "      <td>[-0.04397009, -0.013235806, -0.034632586, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Kids Set Table Bay - Thin Long Sleeve Home Sui...</td>\n",
       "      <td>å…’ç«¥å¥—è£ å°ç£è£½è–„é•·è¢–å±…å®¶å¥—è£ é­”æ³•Baby~k60092</td>\n",
       "      <td>[-0.00460147, 0.029976973, -0.080628425, 0.003...</td>\n",
       "      <td>[0.00086109334, 0.012746421, -0.04744607, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>LONGCHAMP Le Pliage Neo High Density Nylon Bac...</td>\n",
       "      <td>LONGCHAMP Le Pliage Neoé«˜å¯†å°¼é¾å¾ŒèƒŒåŒ…(ä¸­å‹)</td>\n",
       "      <td>[-0.025269749, -0.050276544, -0.059641942, -0....</td>\n",
       "      <td>[-0.0399163, -0.031578567, -0.04178574, 0.0254...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>IFairies Opening Adjustable Ring ifairies [564...</td>\n",
       "      <td>iFairies é–‹å£å¯èª¿ç¯€æˆ’æŒ‡â˜…ifairiesã€56472ã€‘ã€56472ã€‘</td>\n",
       "      <td>[0.018464142, 0.016518341, -0.034174442, 0.007...</td>\n",
       "      <td>[0.029656759, 0.03718795, -0.042785533, -0.027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>PolarStar Women Sweat Quick Dry T-shirt Black ...</td>\n",
       "      <td>PolarStar å¥³ æ’æ±—å¿«å¹²Tæ¤ã€é»‘ã€P18102</td>\n",
       "      <td>[-0.015415181, 0.011347521, -0.09535644, -0.01...</td>\n",
       "      <td>[0.029322254, -0.00047185787, -0.0952496, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Oppo A75 A75S A73 Phone Case Soft Rabbit Silic...   \n",
       "1            SOFT 99 Coating Car Wax Strong Water Watt   \n",
       "2                Low Sugar Mango Dry 250g Be The Royal   \n",
       "3    * the culture Japan Imported Round Top Space C...   \n",
       "4    Hello Kitty Sandals Shoes White/Red Children n...   \n",
       "..                                                 ...   \n",
       "995  Hippored Torn Fun Unique Style Straight Jeans ...   \n",
       "996  Kids Set Table Bay - Thin Long Sleeve Home Sui...   \n",
       "997  LONGCHAMP Le Pliage Neo High Density Nylon Bac...   \n",
       "998  IFairies Opening Adjustable Ring ifairies [564...   \n",
       "999  PolarStar Women Sweat Quick Dry T-shirt Black ...   \n",
       "\n",
       "                                   chinese translation  \\\n",
       "0                  OPPO A75 A75s A73 æ‰‹æœºå£³ è½¯å£³ æŒ‚ç»³å£³ å¤§çœ¼å…”ç¡…èƒ¶å£³   \n",
       "1                                  SOFT 99 éè†œè»Šè Ÿ(å¼·åŠ›æ’¥æ°´å‹)   \n",
       "2                                       ä½ç³–èŠ’æœä¹¾ 250g è‡»å¾¡è¡Œ   \n",
       "3    ï¼Šå°å¾‘æ–‡åŒ–ï¼Šæ—¥æœ¬é€²å£ROUND TOP space craft - diamond (SC-...   \n",
       "4            Hello Kitty å‡±è’‚è²“ KITTY æ¶¼é‹ ç«¥é‹ ç™½/ç´…è‰² å°ç«¥ no739   \n",
       "..                                                 ...   \n",
       "995                ã€HippoRedã€‘æ’•ç ´ä¹è¶£â˜…ç‹¬ç‰¹é£æ ¼â˜…ä¸­ç›´ç­’ç‰›ä»”è£¤ O591_445   \n",
       "996                      å…’ç«¥å¥—è£ å°ç£è£½è–„é•·è¢–å±…å®¶å¥—è£ é­”æ³•Baby~k60092   \n",
       "997                 LONGCHAMP Le Pliage Neoé«˜å¯†å°¼é¾å¾ŒèƒŒåŒ…(ä¸­å‹)   \n",
       "998            iFairies é–‹å£å¯èª¿ç¯€æˆ’æŒ‡â˜…ifairiesã€56472ã€‘ã€56472ã€‘   \n",
       "999                        PolarStar å¥³ æ’æ±—å¿«å¹²Tæ¤ã€é»‘ã€P18102   \n",
       "\n",
       "                                     english_embedding  \\\n",
       "0    [-0.030606616, 0.010501585, -0.04400219, -0.00...   \n",
       "1    [-0.02521394, -0.0062141055, -0.02523462, -0.0...   \n",
       "2    [-0.06998538, 0.025515176, -0.006934945, -0.02...   \n",
       "3    [-0.003708915, 0.024768945, -0.062792934, 0.02...   \n",
       "4    [-0.019042147, 0.031313036, -0.06666778, 0.049...   \n",
       "..                                                 ...   \n",
       "995  [-0.015312562, 0.002696402, -0.046150953, 0.00...   \n",
       "996  [-0.00460147, 0.029976973, -0.080628425, 0.003...   \n",
       "997  [-0.025269749, -0.050276544, -0.059641942, -0....   \n",
       "998  [0.018464142, 0.016518341, -0.034174442, 0.007...   \n",
       "999  [-0.015415181, 0.011347521, -0.09535644, -0.01...   \n",
       "\n",
       "                                     chinese_embedding  \n",
       "0    [-0.020788355, 0.032136466, -0.03952156, -0.04...  \n",
       "1    [-0.013580757, -0.013445883, 0.013568486, -0.0...  \n",
       "2    [-0.056555215, 0.015317621, 0.0015813652, -0.0...  \n",
       "3    [-0.018781146, 0.033165023, -0.05913993, 0.019...  \n",
       "4    [-0.043943617, 0.021419879, -0.059569906, 0.03...  \n",
       "..                                                 ...  \n",
       "995  [-0.04397009, -0.013235806, -0.034632586, 0.03...  \n",
       "996  [0.00086109334, 0.012746421, -0.04744607, 0.00...  \n",
       "997  [-0.0399163, -0.031578567, -0.04178574, 0.0254...  \n",
       "998  [0.029656759, 0.03718795, -0.042785533, -0.027...  \n",
       "999  [0.029322254, -0.00047185787, -0.0952496, -0.0...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the Chinese Embeddings\n",
    "import pandas as pd\n",
    "chinese_embeddings = pd.read_pickle(\"en_to_cn_embeddings.pkl\")\n",
    "chinese_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building BM25\n",
    "\n",
    "english_titles = chinese_embeddings['title']\n",
    "chinese_titles = chinese_embeddings['chinese translation']\n",
    "\n",
    "tokenized_en = [title.split() for title in english_titles]\n",
    "tokenized_cn = [title.split() for title in chinese_titles]\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "bm25_en = BM25Okapi(tokenized_en)\n",
    "bm25_cn = BM25Okapi(tokenized_cn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(query, top_k=5):\n",
    "\n",
    "    #To detect the language from the query\n",
    "    from langdetect import detect\n",
    "\n",
    "    lang = detect(query)\n",
    "    #tokenising the query to be suitable for BM25\n",
    "    tokens = list(jieba.cut(query))\n",
    "\n",
    "    # --- BM25 Retrieval ---(Routes the tokenized query to the appropiate BM25 engine)\n",
    "    if lang == 'cn':\n",
    "        bm25_scores = bm25_cn.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens) #returns a list of scores, one for each document in the dataset\n",
    "\n",
    "    bm25_ranks = {i: rank for rank, i in enumerate(np.argsort(bm25_scores)[::-1], start=1)} #Converts the float BM25 scores to rankings for Reciprocal rank fusion(rrf)\n",
    "\n",
    "    # Sort by RRF score\n",
    "    ranked = sorted(bm25_ranks.items(), key=lambda x: x[1], reverse=True)  #Sorting the docs by their RRF score, with the highest first.\n",
    "\n",
    "    return ranked[:top_k]  # list of (doc_id, final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(query, top_k=5):\n",
    "    # To detect the language from the query\n",
    "    from langdetect import detect\n",
    "\n",
    "    lang = detect(query)\n",
    "    # Tokenizing the query to be suitable for BM25\n",
    "    tokens = list(jieba.cut(query))\n",
    "\n",
    "    # --- BM25 Retrieval ---\n",
    "    if lang == 'cn':\n",
    "        bm25_scores = bm25_cn.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # Get top-k document IDs based on BM25 scores\n",
    "    top_k_ids = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:top_k]\n",
    "\n",
    "    # Return the document IDs and their corresponding BM25 scores\n",
    "    return [(doc_id, bm25_scores[doc_id]) for doc_id in top_k_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8797 | ADIDAS æ„›è¿ªé” D ROSE ENGLEWOOD IV TD ç±ƒçƒé‹ ç”· S85564\n",
      "5.3842 | New Balance 247 é‹å‹•é‹ è·‘é‹ é»‘è‰² ä¸­ç«¥ ç«¥é‹ KA247T2P no338\n",
      "5.3842 | NIKE è€å‰ WMNS NIKE AIR ZOOM PEGASUS 34 é«˜éšæ…¢è·‘é‹ å¥³ 880560001\n",
      "5.1665 | native JEFFERSON BLOCK æ´æ´é‹ ç™½è‰² ç”·å¥³é‹ 11100102-8559 no410\n",
      "0.0000 | OPPO A75 A75s A73 æ‰‹æœºå£³ è½¯å£³ æŒ‚ç»³å£³ å¤§çœ¼å…”ç¡…èƒ¶å£³\n"
     ]
    }
   ],
   "source": [
    "results = BM25(\"men running shoe\")\n",
    "\n",
    "for doc_id, score in results:\n",
    "    print(f\"{score:.4f} | {chinese_embeddings['chinese translation'][doc_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0000 | Oppo A75 A75S A73 Phone Case Soft Rabbit Silicone Case\n",
      "999.0000 | Tree De Sc Multifunctional Locker - Scm3 - 3M6S\n",
      "998.0000 | COGHLANS Canada 0044 Finger Compass Thermometer Whistle\n",
      "997.0000 | [With Incense] Jujube Pack 5 Pc / Pack (2 Pack) ã€\n",
      "996.0000 | Japan gex schisandra Kittens Water Dispenser 900Ml GE2316\n"
     ]
    }
   ],
   "source": [
    "results = BM25(\"å¥³å¼çš®å¤¹å…‹\")\n",
    "\n",
    "for doc_id, score in results:\n",
    "    print(f\"{score:.4f} | {chinese_embeddings['title'][doc_id]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=CHERYL_API)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising Pinecone index\n",
    "index = pc.Index('entocn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate IDs\n",
    "en_ids = [f\"en-{i}\" for i in range(len(chinese_embeddings['english_embedding']))]\n",
    "cn_ids = [f\"cn-{i}\" for i in range(len(chinese_embeddings['chinese_embedding']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to batch upsert\n",
    "def batch_upsert(index, vectors, batch_size=50):\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        index.upsert(vectors=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine English + Chinese as before\n",
    "to_upsert = list(zip(en_ids, chinese_embeddings['english_embedding'])) + \\\n",
    "            list(zip(cn_ids, chinese_embeddings['chinese_embedding']))\n",
    "\n",
    "# Run batch upload\n",
    "batch_upsert(index, to_upsert, batch_size=50)\n",
    "\n",
    "\n",
    "#With this code, the vectorDB has been established for en to cn.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of New Parts of the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Charran\\anaconda3\\envs\\pytorch_cuda\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client = OpenAI(api_key=\"deepseek_API_KEY\", base_url=\"https://openrouter.ai/api/v1\")\n",
    "\n",
    "def get_dynamic_alpha(question, dense_result, bm25_result):\n",
    "    prompt = f\"\"\"You are an multilingual evaluator assessing the retrieval effectiveness of dense\n",
    "retrieval (Cosine Distance) and BM25 retrieval for finding the correct product title of the corresponding target language, which is Chinese.\n",
    "\n",
    "## Task:\n",
    "Given a question and two top1 search results (one from dense retrieval,\n",
    "one from BM25 retrieval), score each retrieval method from **0 to 5** based on whether the correct answer is likely to appear in top2, top3, etc.\n",
    "\n",
    "### **Scoring Criteria:**\n",
    "1. **Direct hit --> 5 points**\n",
    "- If the retrieved document directly answers the question, assign **5 points**.\n",
    "2. **Good wrong result (High likelihood correct answer is nearby) --> 3-4 points**\n",
    "3. **Bad wrong result (Low likelihood correct answer is nearby) --> 1-2 points**\n",
    "4. **Completely off-track --> 0 points**\n",
    "\n",
    "### **Given Data:**\n",
    "- **Question:** \"{question}\"\n",
    "\n",
    "- **dense retrieval Top1 Result:** \"{dense_result}\"\n",
    "- **BM25 retrieval Top1 Result:** \"{bm25_result}\"\n",
    "\n",
    "### **Output Format:**\n",
    "Return two integers separated by a space:\n",
    "- **First number:** dense retrieval score.\n",
    "- **Second number:** BM25 retrieval score.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-chat-v3-0324:free\",  \n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        dense_score, bm25_score = map(int, output.split())\n",
    "    except:\n",
    "        dense_score = bm25_score = 3  # default fallback\n",
    "\n",
    "    if dense_score == 5 and bm25_score != 5:\n",
    "        return 1.0\n",
    "    elif bm25_score == 5 and dense_score != 5:\n",
    "        return 0.0\n",
    "    elif dense_score == 0 and bm25_score == 0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return dense_score / (dense_score + bm25_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Main hybrid retrieval with dynamic alpha (OG code)\n",
    "def hybrid_search_dat(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # --- BM25 Search ---\n",
    "    if lang == 'cn':\n",
    "        bm25_scores = bm25_cn.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # --- Semantic Search (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist()\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k, include_metadata=False)\n",
    "\n",
    "    # Parse Pinecone results\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']]\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']]\n",
    "\n",
    "    # Get top-1 text from both for alpha calculation\n",
    "    bm25_top_idx = int(np.argmax(bm25_scores))\n",
    "    dense_top_idx = pinecone_ids[0]\n",
    "    bm25_text = chinese_embeddings['title'][bm25_top_idx]\n",
    "    dense_text = chinese_embeddings['title'][dense_top_idx]\n",
    "\n",
    "    # --- Get dynamic alpha from GPT ---\n",
    "    start = time.time()\n",
    "    alpha = get_dynamic_alpha(query, dense_text, bm25_text)\n",
    "    print(f\"Alpha fetched: {alpha} in {time.time() - start:.2f}s\")\n",
    "\n",
    "    # --- Normalize Scores ---\n",
    "    scaler = MinMaxScaler()\n",
    "    bm25_norm = scaler.fit_transform(np.array(bm25_scores).reshape(-1, 1)).flatten()\n",
    "    pinecone_norm = scaler.fit_transform(np.array(pinecone_scores).reshape(-1, 1)).flatten()\n",
    "\n",
    "    # --- Combine scores using dynamic alpha ---\n",
    "    hybrid_results = []\n",
    "    for idx, semantic_score in zip(pinecone_ids, pinecone_norm):\n",
    "        final_score = alpha * semantic_score + (1 - alpha) * bm25_norm[idx]\n",
    "        hybrid_results.append((idx, final_score))\n",
    "\n",
    "    # Sort by hybrid score\n",
    "    hybrid_results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # --- Prepare detailed results ---\n",
    "    detailed_results = []\n",
    "    for idx, hybrid_score in hybrid_results[:top_k]:\n",
    "        bm25_score = round(bm25_norm[idx], 4)\n",
    "        semantic_score = round(pinecone_norm[pinecone_ids.index(idx)], 4)\n",
    "        detailed_results.append((idx, round(hybrid_score, 4), bm25_score, semantic_score))\n",
    "\n",
    "    return detailed_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 11.90s\n",
      "0.5000 | 0.0000 | 1.0000 | Taste Sweet Soft Satin Sleep Shirt Blue - First Love Vibrato ã€ Ab02355 - 1 ã€‘\n",
      "0.4695 | 0.0000 | 0.9391 | Polarstar Windproof Warm Jacket Blue Green\n",
      "0.1271 | 0.0000 | 0.9391 | Polarstar Windproof Warm Jacket Blue Green\n",
      "0.1233 | 0.0000 | 0.2466 | KIKIKO Action Professional Sport Swimming Goggles (Blue)\n",
      "0.0000 | 0.0000 | 0.0000 | Panties Cotton Cartoon Triangle Panties 5 Pcs Set - Blue Car ã€ A257 ã€‘\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"I want a blue shirt\")\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    print(f\"{hybrid:.4f} | {bm25:.4f} | {semantic:.4f} | {chinese_embeddings['title'][idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 6.99s\n",
      "0.5000 | 0.0000 | 1.0000 | ğŸ€çœŸçš®å¥³ç”¨å°æ‰‹æ/æ–œèƒŒäºŒç”¨åŒ…ğŸ€\n",
      "0.0966 | 0.0000 | 0.1932 | æ­£éŸ“ ç´ é¢è³ªæ„Ÿç¾½çµ¨æ£‰å¤–å¥— è‰¾çˆ¾èã€TA570100ã€‘\n",
      "0.0720 | 0.0000 | 0.1441 | Montane å¥³ è¼•é‡é˜²æ½‘æ°´ç¾½çµ¨ é€£å¸½å¤–å¥— å­”é›€è— FFEDJ\n",
      "0.0364 | 0.0000 | 1.0000 | ğŸ€çœŸçš®å¥³ç”¨å°æ‰‹æ/æ–œèƒŒäºŒç”¨åŒ…ğŸ€\n",
      "0.0000 | 0.0000 | 0.0000 | ä¹ç¦é‹å¥³é‹æ˜¥å­£å•é‹å¥³å¹³åº•è‹±ä¼¦é£ç™¾æ­å°çš®é‹å¥³\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"Woman leather jacket\")\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    print(f\"{hybrid:.4f} | {bm25:.4f} | {semantic:.4f} | {df_embeddings['chinese translation'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Using LLMs to improve search query (Spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langdetect import detect\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from rank_bm25 import BM25Okapi\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.read_pickle(\"en_to_sp_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_spanish</th>\n",
       "      <th>english_embedding</th>\n",
       "      <th>spanish_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brother genuine high yield toner cartridge tn4...</td>\n",
       "      <td>hermano genuino cartucho tÃ³ner de alto rendimi...</td>\n",
       "      <td>[-0.03431117, 0.025899883, -0.00967014, -0.019...</td>\n",
       "      <td>[0.012239528, 0.02652684, 0.002397126, -0.0288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fitbit inspire 3 health and fitness tracker wi...</td>\n",
       "      <td>fitbit inspirar 3 seguimiento de salud y fitne...</td>\n",
       "      <td>[-0.0016011602, -0.002595037, -0.07348455, 0.0...</td>\n",
       "      <td>[-0.011861571, -0.009732766, -0.06545575, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mikes hot honey americas 1 brand of hot honey ...</td>\n",
       "      <td>mikes miel caliente amÃ©ricas 1 marca de miel c...</td>\n",
       "      <td>[-0.0004525112, -0.009976895, -0.015700651, 0....</td>\n",
       "      <td>[-0.031901788, 0.017521167, -0.04371976, 0.039...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>krema krÃ©ma red fruits 100 recyclable 240g</td>\n",
       "      <td>krema krÃ©ma frutos rojos 100 reciclables 240g</td>\n",
       "      <td>[-0.011189645, 0.033041686, -0.005376764, -0.0...</td>\n",
       "      <td>[-0.013215443, 0.0015486346, -0.020853952, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drsalts calming therapy epsom salts  soothing ...</td>\n",
       "      <td>drsalts calmante terapia epsom sales calmantes...</td>\n",
       "      <td>[0.018024862, -0.015684763, -0.062142983, -0.0...</td>\n",
       "      <td>[0.008137982, 0.009916707, -0.07349886, -0.013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>ruimen smart watches for men women answermake ...</td>\n",
       "      <td>ruimen relojes inteligentes para hombres mujer...</td>\n",
       "      <td>[-0.022698322, 0.004262252, -0.06492456, -0.01...</td>\n",
       "      <td>[-0.015060791, 0.010321501, -0.057668064, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>musicozy sleep headphones bluetooth 54 headban...</td>\n",
       "      <td>auriculares musicozy sueÃ±o bluetooth 54 diadem...</td>\n",
       "      <td>[-0.0110038, 0.028441783, -0.065515295, 0.0328...</td>\n",
       "      <td>[0.006726083, 0.042338137, -0.0548927, 0.00642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>sun ninja pop up beach tent sun shelter upf50 ...</td>\n",
       "      <td>sun ninja pop up playa refugio de sol upf50 co...</td>\n",
       "      <td>[-0.018024122, -0.008911157, -0.09137453, 0.00...</td>\n",
       "      <td>[-0.0045234896, 0.003032705, -0.079418756, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>rhino usa trailer hitch pin 2 inch patented 58...</td>\n",
       "      <td>enganche de remolque de rinoceronte usa pin de...</td>\n",
       "      <td>[-0.011390688, -0.004701349, -0.009233302, 0.0...</td>\n",
       "      <td>[0.023057196, 0.013233271, 0.0004464224, 0.017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>sun ninja pop up beach tent sun shelter upf50 ...</td>\n",
       "      <td>sun ninja pop up playa tienda refugio de sol u...</td>\n",
       "      <td>[-0.010519517, -0.017002273, -0.08655271, 0.01...</td>\n",
       "      <td>[-0.0049236235, -0.005282401, -0.06757761, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    brother genuine high yield toner cartridge tn4...   \n",
       "1    fitbit inspire 3 health and fitness tracker wi...   \n",
       "2    mikes hot honey americas 1 brand of hot honey ...   \n",
       "3           krema krÃ©ma red fruits 100 recyclable 240g   \n",
       "4    drsalts calming therapy epsom salts  soothing ...   \n",
       "..                                                 ...   \n",
       "991  ruimen smart watches for men women answermake ...   \n",
       "992  musicozy sleep headphones bluetooth 54 headban...   \n",
       "993  sun ninja pop up beach tent sun shelter upf50 ...   \n",
       "994  rhino usa trailer hitch pin 2 inch patented 58...   \n",
       "995  sun ninja pop up beach tent sun shelter upf50 ...   \n",
       "\n",
       "                                         title_spanish  \\\n",
       "0    hermano genuino cartucho tÃ³ner de alto rendimi...   \n",
       "1    fitbit inspirar 3 seguimiento de salud y fitne...   \n",
       "2    mikes miel caliente amÃ©ricas 1 marca de miel c...   \n",
       "3        krema krÃ©ma frutos rojos 100 reciclables 240g   \n",
       "4    drsalts calmante terapia epsom sales calmantes...   \n",
       "..                                                 ...   \n",
       "991  ruimen relojes inteligentes para hombres mujer...   \n",
       "992  auriculares musicozy sueÃ±o bluetooth 54 diadem...   \n",
       "993  sun ninja pop up playa refugio de sol upf50 co...   \n",
       "994  enganche de remolque de rinoceronte usa pin de...   \n",
       "995  sun ninja pop up playa tienda refugio de sol u...   \n",
       "\n",
       "                                     english_embedding  \\\n",
       "0    [-0.03431117, 0.025899883, -0.00967014, -0.019...   \n",
       "1    [-0.0016011602, -0.002595037, -0.07348455, 0.0...   \n",
       "2    [-0.0004525112, -0.009976895, -0.015700651, 0....   \n",
       "3    [-0.011189645, 0.033041686, -0.005376764, -0.0...   \n",
       "4    [0.018024862, -0.015684763, -0.062142983, -0.0...   \n",
       "..                                                 ...   \n",
       "991  [-0.022698322, 0.004262252, -0.06492456, -0.01...   \n",
       "992  [-0.0110038, 0.028441783, -0.065515295, 0.0328...   \n",
       "993  [-0.018024122, -0.008911157, -0.09137453, 0.00...   \n",
       "994  [-0.011390688, -0.004701349, -0.009233302, 0.0...   \n",
       "995  [-0.010519517, -0.017002273, -0.08655271, 0.01...   \n",
       "\n",
       "                                     spanish_embedding  \n",
       "0    [0.012239528, 0.02652684, 0.002397126, -0.0288...  \n",
       "1    [-0.011861571, -0.009732766, -0.06545575, -0.0...  \n",
       "2    [-0.031901788, 0.017521167, -0.04371976, 0.039...  \n",
       "3    [-0.013215443, 0.0015486346, -0.020853952, -0....  \n",
       "4    [0.008137982, 0.009916707, -0.07349886, -0.013...  \n",
       "..                                                 ...  \n",
       "991  [-0.015060791, 0.010321501, -0.057668064, -0.0...  \n",
       "992  [0.006726083, 0.042338137, -0.0548927, 0.00642...  \n",
       "993  [-0.0045234896, 0.003032705, -0.079418756, 0.0...  \n",
       "994  [0.023057196, 0.013233271, 0.0004464224, 0.017...  \n",
       "995  [-0.0049236235, -0.005282401, -0.06757761, 0.0...  \n",
       "\n",
       "[996 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building BM25\n",
    "\n",
    "english_titles = df_embeddings['title']\n",
    "spanish_titles = df_embeddings['title_spanish']\n",
    "\n",
    "tokenized_en = [title.split() for title in english_titles]\n",
    "tokenized_es = [title.split() for title in spanish_titles]\n",
    "\n",
    "\n",
    "\n",
    "bm25_en = BM25Okapi(tokenized_en)\n",
    "bm25_es = BM25Okapi(tokenized_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=CHERYL_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising Pinecone index\n",
    "index = pc.Index('entoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client = OpenAI(api_key=\"deepseek_API_KEY\", base_url=\"https://openrouter.ai/api/v1\")\n",
    "\n",
    "def get_dynamic_alpha(question, dense_result, bm25_result):\n",
    "    prompt = f\"\"\"You are an multilingual evaluator assessing the retrieval effectiveness of dense\n",
    "retrieval (Cosine Distance) and BM25 retrieval for finding the correct product title of the corresponding target language, which is italian.\n",
    "\n",
    "## Task:\n",
    "Given a question and two top1 search results (one from dense retrieval,\n",
    "one from BM25 retrieval), score each retrieval method from **0 to 5** based on whether the correct answer is likely to appear in top2, top3, etc.\n",
    "\n",
    "### **Scoring Criteria:**\n",
    "1. **Direct hit --> 5 points**\n",
    "- If the retrieved document directly answers the question, assign **5 points**.\n",
    "2. **Good wrong result (High likelihood correct answer is nearby) --> 3-4 points**\n",
    "3. **Bad wrong result (Low likelihood correct answer is nearby) --> 1-2 points**\n",
    "4. **Completely off-track --> 0 points**\n",
    "\n",
    "### **Given Data:**\n",
    "- **Question:** \"{question}\"\n",
    "\n",
    "- **dense retrieval Top1 Result:** \"{dense_result}\"\n",
    "- **BM25 retrieval Top1 Result:** \"{bm25_result}\"\n",
    "\n",
    "### **Output Format:**\n",
    "Return two integers separated by a space:\n",
    "- **First number:** dense retrieval score.\n",
    "- **Second number:** BM25 retrieval score.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-chat-v3-0324:free\",  \n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        dense_score, bm25_score = map(int, output.split())\n",
    "    except:\n",
    "        dense_score = bm25_score = 3  # default fallback\n",
    "\n",
    "    if dense_score == 5 and bm25_score != 5:\n",
    "        return 1.0\n",
    "    elif bm25_score == 5 and dense_score != 5:\n",
    "        return 0.0\n",
    "    elif dense_score == 0 and bm25_score == 0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return dense_score / (dense_score + bm25_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Main hybrid retrieval with dynamic alpha\n",
    "def hybrid_search_dat(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # --- BM25 Search ---\n",
    "    if lang == 'es':\n",
    "        bm25_scores = bm25_es.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # --- Semantic Search (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist()\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k, include_metadata=False)\n",
    "\n",
    "    # Parse Pinecone results\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']]\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']]\n",
    "\n",
    "    # Get top-1 text from both for alpha calculation\n",
    "    bm25_top_idx = int(np.argmax(bm25_scores))\n",
    "    dense_top_idx = pinecone_ids[0]\n",
    "    bm25_text = df_embeddings['title_spanish'][bm25_top_idx]\n",
    "    dense_text = df_embeddings['title_spanish'][dense_top_idx]\n",
    "\n",
    "    # --- Get dynamic alpha from GPT ---\n",
    "    start = time.time()\n",
    "    alpha = get_dynamic_alpha(query, dense_text, bm25_text)\n",
    "    print(f\"Alpha fetched: {alpha} in {time.time() - start:.2f}s\")\n",
    "\n",
    "    # --- Normalize Scores ---\n",
    "    scaler = MinMaxScaler()\n",
    "    bm25_norm = scaler.fit_transform(np.array(bm25_scores).reshape(-1, 1)).flatten()\n",
    "    pinecone_norm = scaler.fit_transform(np.array(pinecone_scores).reshape(-1, 1)).flatten()\n",
    "\n",
    "    # --- Combine scores using dynamic alpha ---\n",
    "    hybrid_results = []\n",
    "    for idx, semantic_score in zip(pinecone_ids, pinecone_norm):\n",
    "        final_score = alpha * semantic_score + (1 - alpha) * bm25_norm[idx]\n",
    "        hybrid_results.append((idx, final_score))\n",
    "\n",
    "    # Sort by hybrid score\n",
    "    hybrid_results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # --- Prepare detailed results ---\n",
    "    detailed_results = []\n",
    "    for idx, hybrid_score in hybrid_results[:top_k]:\n",
    "        bm25_score = round(bm25_norm[idx], 4)\n",
    "        semantic_score = round(pinecone_norm[pinecone_ids.index(idx)], 4)\n",
    "        detailed_results.append((idx, round(hybrid_score, 4), bm25_score, semantic_score))\n",
    "\n",
    "    return detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Main hybrid retrieval with dynamic alpha (OG code)\n",
    "def hybrid_search_dat(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # --- BM25 Search ---\n",
    "    if lang == 'es':\n",
    "        bm25_scores = bm25_es.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # --- Semantic Search (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist()\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k, include_metadata=False)\n",
    "\n",
    "    # Parse Pinecone results\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']]\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']]\n",
    "\n",
    "    # Get top-1 text from both for alpha calculation\n",
    "    bm25_top_idx = int(np.argmax(bm25_scores))\n",
    "    dense_top_idx = pinecone_ids[0]\n",
    "    bm25_text = df_embeddings['title'][bm25_top_idx]\n",
    "    dense_text = df_embeddings['title'][dense_top_idx]\n",
    "\n",
    "    # --- Get dynamic alpha from GPT ---\n",
    "    start = time.time()\n",
    "    alpha = get_dynamic_alpha(query, dense_text, bm25_text)\n",
    "    print(f\"Alpha fetched: {alpha} in {time.time() - start:.2f}s\")\n",
    "\n",
    "    # --- Normalize Scores ---\n",
    "    scaler = MinMaxScaler()\n",
    "    bm25_norm = scaler.fit_transform(np.array(bm25_scores).reshape(-1, 1)).flatten()\n",
    "    pinecone_norm = scaler.fit_transform(np.array(pinecone_scores).reshape(-1, 1)).flatten()\n",
    "\n",
    "    # --- Combine scores using dynamic alpha ---\n",
    "    hybrid_results = []\n",
    "    for idx, semantic_score in zip(pinecone_ids, pinecone_norm):\n",
    "        final_score = alpha * semantic_score + (1 - alpha) * bm25_norm[idx]\n",
    "        hybrid_results.append((idx, final_score))\n",
    "\n",
    "    # Sort by hybrid score\n",
    "    hybrid_results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # --- Prepare detailed results ---\n",
    "    detailed_results = []\n",
    "    for idx, hybrid_score in hybrid_results[:top_k]:\n",
    "        bm25_score = round(bm25_norm[idx], 4)\n",
    "        semantic_score = round(pinecone_norm[pinecone_ids.index(idx)], 4)\n",
    "        detailed_results.append((idx, round(hybrid_score, 4), bm25_score, semantic_score))\n",
    "\n",
    "    return detailed_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 6.93s\n",
      "0.6194 | 0.8298 | 0.4089 | rugshop dublin contemporary abstract stain resistant soft runner rug 2 x 7 blue\n",
      "0.5000 | 0.0000 | 1.0000 | lindor shaped ball bag dark\n",
      "0.4883 | 0.9456 | 0.0309 | simplicity creative patterns sleeves for tops vest jackets coats a 10121416182022\n",
      "0.1717 | 0.0000 | 1.0000 | lindor shaped ball bag dark\n",
      "0.0000 | 0.0000 | 0.0000 | tiblue insulated lunch bag  leakproof freezable cooler for office school picnics  adjustable strap for adults  kids\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"I want a blue shirt\")\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    print(f\"{hybrid:.4f} | {bm25:.4f} | {semantic:.4f} | {df_embeddings['title'][idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 5.53s\n",
      "1.0000 | 1.0000 | 1.0000 | megagear slr dslr sierra serie autÃ©ntica cÃ¡mara de cuero hombro o correa de cuello negro\n",
      "0.1814 | 0.0000 | 0.3628 | mochila de almuerzo de artelaris para las mujeres mochila aislante elegante para las mujeres mochila de viaje impermeable mochila de almuerzo de las mujeres mochila mÃ¡s frÃ­a mochila de la lonchera mochila para profesor enfermera trabajo picnic book bag\n",
      "0.1665 | 0.0000 | 0.3330 | znsayotx 1 pieza sillÃ³n jacquard slipcovers para salÃ³n sillÃ³n alto cubre con brazos anti slip mascotas agradable sofÃ¡ sofÃ¡ sillÃ³n cubierta muebles protector silla gris claro\n",
      "0.1396 | 0.0000 | 0.2793 | ajuste bolsa de almuerzo fresco para mujeres aisladas bolsa de almuerzo para el trabajo resistente a las manchas caja de almuerzo grande para las mujeres con contenedores vaso de hielo cierre cremallera bolsa de wichita hojas de palma\n",
      "0.0000 | 0.0000 | 0.0000 | simpleza patrones creativos mangas para tops chaleco chaquetas abrigos un 10121416182022\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"Woman leather jacket\")\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    print(f\"{hybrid:.4f} | {bm25:.4f} | {semantic:.4f} | {df_embeddings['title_spanish'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 15.83s\n",
      "1.0000 | 1.0000 | 1.0000 | megagear slr dslr sierra serie autÃ©ntica cÃ¡mara de cuero hombro o correa de cuello negro\n",
      "0.1814 | 0.0000 | 0.3628 | mochila de almuerzo de artelaris para las mujeres mochila aislante elegante para las mujeres mochila de viaje impermeable mochila de almuerzo de las mujeres mochila mÃ¡s frÃ­a mochila de la lonchera mochila para profesor enfermera trabajo picnic book bag\n",
      "0.1665 | 0.0000 | 0.3330 | znsayotx 1 pieza sillÃ³n jacquard slipcovers para salÃ³n sillÃ³n alto cubre con brazos anti slip mascotas agradable sofÃ¡ sofÃ¡ sillÃ³n cubierta muebles protector silla gris claro\n",
      "0.1396 | 0.0000 | 0.2793 | ajuste bolsa de almuerzo fresco para mujeres aisladas bolsa de almuerzo para el trabajo resistente a las manchas caja de almuerzo grande para las mujeres con contenedores vaso de hielo cierre cremallera bolsa de wichita hojas de palma\n",
      "0.0000 | 0.0000 | 0.0000 | simpleza patrones creativos mangas para tops chaleco chaquetas abrigos un 10121416182022\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"Woman leather jacket\")\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    print(f\"{hybrid:.4f} | {bm25:.4f} | {semantic:.4f} | {df_embeddings['title_spanish'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(180, 0.9242, 0.8485, 1.0), (985, 0.9242, 0.8485, 1.0), (174, 0.5, 1.0, 0.0), (407, 0.2279, 0.0, 0.4559), (407, 0.2279, 0.0, 0.4559)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to evaluate the top most result with the input query uusing evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting comet-ml\n",
      "  Downloading comet_ml-3.49.7-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (2.5.1)\n",
      "Collecting dulwich!=0.20.33,>=0.20.6 (from comet-ml)\n",
      "  Downloading dulwich-0.22.8-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet-ml)\n",
      "  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from comet-ml) (4.23.0)\n",
      "Requirement already satisfied: psutil>=5.6.3 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from comet-ml) (5.9.0)\n",
      "Collecting python-box<7.0.0 (from comet-ml)\n",
      "  Downloading python_box-6.1.0-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting requests-toolbelt>=0.8.0 (from comet-ml)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from comet-ml) (2.32.3)\n",
      "Collecting rich>=13.3.2 (from comet-ml)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting semantic-version>=2.8.0 (from comet-ml)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from comet-ml) (2.20.0)\n",
      "Collecting simplejson (from comet-ml)\n",
      "  Downloading simplejson-3.20.1-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from comet-ml) (2.2.3)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from comet-ml) (1.17.2)\n",
      "Collecting wurlitzer>=1.0.2 (from comet-ml)\n",
      "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: portalocker in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu) (3.1.1)\n",
      "Requirement already satisfied: regex in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu) (1.26.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu) (5.3.1)\n",
      "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet-ml)\n",
      "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from requests>=2.18.4->comet-ml) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from requests>=2.18.4->comet-ml) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from requests>=2.18.4->comet-ml) (2024.8.30)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.3.2->comet-ml)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from rich>=13.3.2->comet-ml) (2.18.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from portalocker->sacrebleu) (305.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading comet_ml-3.49.7-py3-none-any.whl (726 kB)\n",
      "   ---------------------------------------- 0.0/726.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 726.7/726.7 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading dulwich-0.22.8-cp311-cp311-win_amd64.whl (609 kB)\n",
      "   ---------------------------------------- 0.0/609.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 609.1/609.1 kB 11.2 MB/s eta 0:00:00\n",
      "Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
      "Downloading python_box-6.1.0-cp311-cp311-win_amd64.whl (957 kB)\n",
      "   ---------------------------------------- 0.0/957.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 957.4/957.4 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
      "Downloading simplejson-3.20.1-cp311-cp311-win_amd64.whl (75 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: everett, wurlitzer, simplejson, semantic-version, python-box, mdurl, dulwich, configobj, requests-toolbelt, markdown-it-py, rich, comet-ml\n",
      "Successfully installed comet-ml-3.49.7 configobj-5.0.9 dulwich-0.22.8 everett-3.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 python-box-6.1.0 requests-toolbelt-1.0.0 rich-14.0.0 semantic-version-2.10.0 simplejson-3.20.1 wurlitzer-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install comet-ml sacrebleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unbabel-comet\n",
      "  Downloading unbabel_comet-2.2.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting entmax<2.0,>=1.1 (from unbabel-comet)\n",
      "  Downloading entmax-1.3-py3-none-any.whl.metadata (348 bytes)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from unbabel-comet) (0.26.5)\n",
      "Collecting jsonargparse==3.13.1 (from unbabel-comet)\n",
      "  Downloading jsonargparse-3.13.1-py3-none-any.whl.metadata (55 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from unbabel-comet) (1.26.3)\n",
      "Requirement already satisfied: pandas>=1.4.1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from unbabel-comet) (2.2.3)\n",
      "Collecting protobuf<5.0.0,>=4.24.4 (from unbabel-comet)\n",
      "  Downloading protobuf-4.25.6-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting pytorch-lightning<3.0.0,>=2.0.0 (from unbabel-comet)\n",
      "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from unbabel-comet) (2.5.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from unbabel-comet) (1.13.1)\n",
      "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from unbabel-comet) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from unbabel-comet) (2.0.1+cu118)\n",
      "Collecting torchmetrics<0.11.0,>=0.10.2 (from unbabel-comet)\n",
      "  Downloading torchmetrics-0.10.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: transformers<5.0,>=4.17 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from unbabel-comet) (4.45.2)\n",
      "Requirement already satisfied: PyYAML>=3.13 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from pandas>=1.4.1->unbabel-comet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from pandas>=1.4.1->unbabel-comet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from pandas>=1.4.1->unbabel-comet) (2024.2)\n",
      "Collecting torch>=1.6.0 (from unbabel-comet)\n",
      "  Downloading torch-2.6.0-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: portalocker in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (3.1.1)\n",
      "Requirement already satisfied: regex in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (5.3.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from torch>=1.6.0->unbabel-comet) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from torch>=1.6.0->unbabel-comet) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from torch>=1.6.0->unbabel-comet) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.20.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.11.11)\n",
      "Requirement already satisfied: setuptools in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (75.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from jinja2->torch>=1.6.0->unbabel-comet) (2.1.3)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from portalocker->sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (305.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\charran\\anaconda3\\envs\\pytorch_cuda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.18.3)\n",
      "Downloading unbabel_comet-2.2.5-py3-none-any.whl (96 kB)\n",
      "Downloading jsonargparse-3.13.1-py3-none-any.whl (101 kB)\n",
      "Downloading entmax-1.3-py3-none-any.whl (13 kB)\n",
      "Downloading protobuf-4.25.6-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
      "   ---------------------------------------- 0.0/823.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 823.0/823.0 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading torch-2.6.0-cp311-cp311-win_amd64.whl (204.2 MB)\n",
      "   ---------------------------------------- 0.0/204.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/204.2 MB 12.2 MB/s eta 0:00:17\n",
      "    --------------------------------------- 3.9/204.2 MB 9.4 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 6.6/204.2 MB 10.6 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 9.7/204.2 MB 11.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 12.6/204.2 MB 12.0 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 14.9/204.2 MB 11.7 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 17.3/204.2 MB 11.8 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 19.7/204.2 MB 11.8 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 22.3/204.2 MB 11.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 24.9/204.2 MB 11.8 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 27.0/204.2 MB 11.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 28.6/204.2 MB 11.3 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 29.6/204.2 MB 10.9 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 30.7/204.2 MB 10.4 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 31.5/204.2 MB 10.0 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 32.5/204.2 MB 9.8 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 34.1/204.2 MB 9.6 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 35.7/204.2 MB 9.4 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.2/204.2 MB 9.4 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 38.5/204.2 MB 9.1 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 40.1/204.2 MB 9.0 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 40.1/204.2 MB 9.0 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 41.7/204.2 MB 8.6 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 42.7/204.2 MB 8.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 43.3/204.2 MB 8.3 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 44.0/204.2 MB 8.0 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 44.6/204.2 MB 7.9 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 44.8/204.2 MB 7.6 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 45.6/204.2 MB 7.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 46.1/204.2 MB 7.4 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 47.2/204.2 MB 7.3 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 47.7/204.2 MB 7.1 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 48.2/204.2 MB 7.1 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 49.3/204.2 MB 6.9 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 50.3/204.2 MB 6.8 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 50.9/204.2 MB 6.8 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 51.9/204.2 MB 6.6 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 53.0/204.2 MB 6.6 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 53.2/204.2 MB 6.5 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 55.1/204.2 MB 6.5 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 56.4/204.2 MB 6.5 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 57.1/204.2 MB 6.5 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 58.7/204.2 MB 6.5 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 60.0/204.2 MB 6.5 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 60.6/204.2 MB 6.4 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 61.9/204.2 MB 6.4 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 62.9/204.2 MB 6.4 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 63.4/204.2 MB 6.3 MB/s eta 0:00:23\n",
      "   ------------ --------------------------- 64.5/204.2 MB 6.3 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 66.6/204.2 MB 6.3 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 67.9/204.2 MB 6.3 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 69.7/204.2 MB 6.4 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 71.8/204.2 MB 6.4 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 73.9/204.2 MB 6.5 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 75.8/204.2 MB 6.5 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 77.9/204.2 MB 6.6 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 80.0/204.2 MB 6.6 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 81.5/204.2 MB 6.7 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 83.6/204.2 MB 6.7 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 85.7/204.2 MB 6.8 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 88.1/204.2 MB 6.8 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 90.7/204.2 MB 6.9 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 92.5/204.2 MB 7.0 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 94.6/204.2 MB 7.0 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 97.0/204.2 MB 7.1 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 98.8/204.2 MB 7.1 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 101.4/204.2 MB 7.2 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 104.1/204.2 MB 7.3 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 107.0/204.2 MB 7.4 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 108.8/204.2 MB 7.4 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 111.7/204.2 MB 7.5 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 114.3/204.2 MB 7.5 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 116.7/204.2 MB 7.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 118.5/204.2 MB 7.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 120.8/204.2 MB 7.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 122.9/204.2 MB 7.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 125.0/204.2 MB 7.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 127.1/204.2 MB 7.8 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 129.8/204.2 MB 7.8 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 132.4/204.2 MB 7.9 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 134.5/204.2 MB 7.9 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 136.8/204.2 MB 7.9 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 138.4/204.2 MB 8.0 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 140.2/204.2 MB 7.9 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 142.3/204.2 MB 8.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 144.4/204.2 MB 8.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 146.5/204.2 MB 8.0 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 148.4/204.2 MB 8.0 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 151.5/204.2 MB 8.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 153.6/204.2 MB 8.1 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 155.5/204.2 MB 8.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 157.8/204.2 MB 8.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 159.9/204.2 MB 8.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 161.7/204.2 MB 8.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.4/204.2 MB 8.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 166.7/204.2 MB 8.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 168.8/204.2 MB 8.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 170.9/204.2 MB 8.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 173.3/204.2 MB 8.3 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 175.9/204.2 MB 8.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 178.8/204.2 MB 8.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 181.7/204.2 MB 8.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 184.5/204.2 MB 8.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 186.6/204.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 188.7/204.2 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 191.1/204.2 MB 8.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 194.0/204.2 MB 8.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 197.1/204.2 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.5/204.2 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.1/204.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  203.9/204.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 204.2/204.2 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "   ---------------------------------------- 0.0/529.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 529.7/529.7 kB 17.8 MB/s eta 0:00:00\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: protobuf, lightning-utilities, jsonargparse, torch, torchmetrics, entmax, pytorch-lightning, unbabel-comet\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.1\n",
      "    Uninstalling protobuf-5.29.1:\n",
      "      Successfully uninstalled protobuf-5.29.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1+cu118\n",
      "    Uninstalling torch-2.0.1+cu118:\n",
      "      Successfully uninstalled torch-2.0.1+cu118\n",
      "Successfully installed entmax-1.3 jsonargparse-3.13.1 lightning-utilities-0.14.3 protobuf-4.25.6 pytorch-lightning-2.5.1 torch-2.6.0 torchmetrics-0.10.3 unbabel-comet-2.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Charran\\anaconda3\\envs\\pytorch_cuda\\Lib\\site-packages\\~vfuser'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Charran\\anaconda3\\envs\\pytorch_cuda\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.6.0 which is incompatible.\n",
      "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 2.6.0 which is incompatible.\n",
      "trankit 1.1.2 requires torch<=2.0.1,>=1.6.0, but you have torch 2.6.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install unbabel-comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "top_idx = results[0][0]  # index of top-1 result\n",
    "\n",
    "reference_query = \"Woman leather jacket\"\n",
    "predicted_title = df_embeddings['title_spanish'][top_idx]\n",
    "\n",
    "# Tokenize both properly\n",
    "reference_tokens = word_tokenize(reference_query)\n",
    "predicted_tokens = word_tokenize(predicted_title)\n",
    "\n",
    "# Pass the reference as a *list of references* (each is token list)\n",
    "meteor = meteor_score([reference_tokens], predicted_tokens)\n",
    "\n",
    "print(f\"METEOR Score: {meteor:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore-F1: 0.6420\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Inputs\n",
    "reference_query = \"Woman leather jacket\"\n",
    "predicted_title = df_embeddings['title_spanish'][top_idx]\n",
    "\n",
    "# BERTScore evaluation\n",
    "P, R, F1 = score([predicted_title], [reference_query], lang=\"multilingual\", verbose=False)\n",
    "\n",
    "print(f\"BERTScore-F1: {F1[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Using LLMs to improve search query (Italian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#TFIDF and BM25\n",
    "from langdetect import detect\n",
    "from rank_bm25 import BM25Okapi\n",
    "#env\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "#pinecone\n",
    "from pinecone import Pinecone\n",
    "#sentence transformer model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the APIs\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "CHARRAN_API = os.getenv('CHARRAN_API')\n",
    "CHERYL_API = os.getenv('CHERYL_API')\n",
    "deepseek_API_KEY = os.getenv('deepseek_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_italian</th>\n",
       "      <th>english_embedding</th>\n",
       "      <th>italian_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zwilling pro 2pc prep knife set</td>\n",
       "      <td>Zwilling pro 2pc set coltello prep</td>\n",
       "      <td>[-0.07585622, -0.006632321, -0.039237764, 0.04...</td>\n",
       "      <td>[-0.058768444, 0.012960452, -0.029929288, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>womens slim fit drape wrap tshirt  a new day</td>\n",
       "      <td>donne slim fit drappeggio avvolgere tshirt un ...</td>\n",
       "      <td>[-0.023722176, -0.02756558, -0.07540757, 0.011...</td>\n",
       "      <td>[-0.056372743, -0.038858823, -0.07786548, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mens teenage mutant ninja turtles group shot l...</td>\n",
       "      <td>mens adolescente mutante ninja tartarughe grup...</td>\n",
       "      <td>[-0.02781372, 0.004972987, -0.055929173, 0.013...</td>\n",
       "      <td>[-0.004044311, 0.008419336, -0.05591273, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mens wwe triple h the game logo tshirt</td>\n",
       "      <td>mens wwe triplo h il gioco logo tshirt</td>\n",
       "      <td>[-0.037347108, -0.009183998, -0.082188, 0.0122...</td>\n",
       "      <td>[-0.03912319, -0.015832098, -0.07382396, 0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>purina fancy feast grilled gravy delights feas...</td>\n",
       "      <td>purina fantasia festa grigliato sugo delizie f...</td>\n",
       "      <td>[-0.0551254, 0.024768988, -0.02036258, -0.0108...</td>\n",
       "      <td>[-0.0431343, 0.017949222, -0.023515861, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>multi collagen protein powder types i ii  ii b...</td>\n",
       "      <td>proteine multi collageno in polvere ii ii ii o...</td>\n",
       "      <td>[-0.007071648, 0.013024846, -0.026673753, -0.0...</td>\n",
       "      <td>[0.036605842, 0.03628495, -0.027457794, -0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>hope  henry mens waffle knit pullover sweater</td>\n",
       "      <td>speranza henry uomo waffle maglia pullover mag...</td>\n",
       "      <td>[-0.026264952, -0.008562797, -0.05641582, -0.0...</td>\n",
       "      <td>[-0.0020557789, -0.0039152885, -0.04709097, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>noritake colortrio 16piece coupe dinnerware set</td>\n",
       "      <td>noritake colortio 16 pezzi coupÃ© set per la cena</td>\n",
       "      <td>[-0.0055267178, -0.03823672, -0.024558328, 0.0...</td>\n",
       "      <td>[0.0011833841, -0.014286156, -0.01681679, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>hope  henry mens fine gauge vneck pullover swe...</td>\n",
       "      <td>speranza henry mens maglione pullover fine gau...</td>\n",
       "      <td>[-0.03244666, -0.026627203, -0.07740165, 0.004...</td>\n",
       "      <td>[-0.017570777, -0.00990813, -0.071718924, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>double strength larginine 1000 mg by now foods...</td>\n",
       "      <td>larginina 1000 mg a doppia resistenza ormai al...</td>\n",
       "      <td>[-0.032500178, 0.013463285, -0.05747889, -0.04...</td>\n",
       "      <td>[-0.010276856, 0.006340458, -0.052428123, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                      zwilling pro 2pc prep knife set   \n",
       "1         womens slim fit drape wrap tshirt  a new day   \n",
       "2    mens teenage mutant ninja turtles group shot l...   \n",
       "3               mens wwe triple h the game logo tshirt   \n",
       "4    purina fancy feast grilled gravy delights feas...   \n",
       "..                                                 ...   \n",
       "868  multi collagen protein powder types i ii  ii b...   \n",
       "869      hope  henry mens waffle knit pullover sweater   \n",
       "870    noritake colortrio 16piece coupe dinnerware set   \n",
       "871  hope  henry mens fine gauge vneck pullover swe...   \n",
       "872  double strength larginine 1000 mg by now foods...   \n",
       "\n",
       "                                         title_italian  \\\n",
       "0                   Zwilling pro 2pc set coltello prep   \n",
       "1    donne slim fit drappeggio avvolgere tshirt un ...   \n",
       "2    mens adolescente mutante ninja tartarughe grup...   \n",
       "3               mens wwe triplo h il gioco logo tshirt   \n",
       "4    purina fantasia festa grigliato sugo delizie f...   \n",
       "..                                                 ...   \n",
       "868  proteine multi collageno in polvere ii ii ii o...   \n",
       "869  speranza henry uomo waffle maglia pullover mag...   \n",
       "870   noritake colortio 16 pezzi coupÃ© set per la cena   \n",
       "871  speranza henry mens maglione pullover fine gau...   \n",
       "872  larginina 1000 mg a doppia resistenza ormai al...   \n",
       "\n",
       "                                     english_embedding  \\\n",
       "0    [-0.07585622, -0.006632321, -0.039237764, 0.04...   \n",
       "1    [-0.023722176, -0.02756558, -0.07540757, 0.011...   \n",
       "2    [-0.02781372, 0.004972987, -0.055929173, 0.013...   \n",
       "3    [-0.037347108, -0.009183998, -0.082188, 0.0122...   \n",
       "4    [-0.0551254, 0.024768988, -0.02036258, -0.0108...   \n",
       "..                                                 ...   \n",
       "868  [-0.007071648, 0.013024846, -0.026673753, -0.0...   \n",
       "869  [-0.026264952, -0.008562797, -0.05641582, -0.0...   \n",
       "870  [-0.0055267178, -0.03823672, -0.024558328, 0.0...   \n",
       "871  [-0.03244666, -0.026627203, -0.07740165, 0.004...   \n",
       "872  [-0.032500178, 0.013463285, -0.05747889, -0.04...   \n",
       "\n",
       "                                     italian_embedding  \n",
       "0    [-0.058768444, 0.012960452, -0.029929288, 0.05...  \n",
       "1    [-0.056372743, -0.038858823, -0.07786548, 0.00...  \n",
       "2    [-0.004044311, 0.008419336, -0.05591273, 0.015...  \n",
       "3    [-0.03912319, -0.015832098, -0.07382396, 0.008...  \n",
       "4    [-0.0431343, 0.017949222, -0.023515861, -0.024...  \n",
       "..                                                 ...  \n",
       "868  [0.036605842, 0.03628495, -0.027457794, -0.008...  \n",
       "869  [-0.0020557789, -0.0039152885, -0.04709097, -0...  \n",
       "870  [0.0011833841, -0.014286156, -0.01681679, 0.03...  \n",
       "871  [-0.017570777, -0.00990813, -0.071718924, 0.01...  \n",
       "872  [-0.010276856, 0.006340458, -0.052428123, -0.0...  \n",
       "\n",
       "[873 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the Italian Embeddings\n",
    "italian_embeddings = pd.read_pickle(\"en_to_it_embeddings.pkl\")\n",
    "italian_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Obtaining the respective BM25 (Sparse) and Dense (Pinecone) Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building BM25\n",
    "english_titles = italian_embeddings['title']\n",
    "italian_titles = italian_embeddings['title_italian']\n",
    "\n",
    "tokenized_en = [title.split() for title in english_titles]\n",
    "tokenized_it = [title.split() for title in italian_titles]\n",
    "\n",
    "bm25_en = BM25Okapi(tokenized_en)\n",
    "bm25_it = BM25Okapi(tokenized_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BM25 Function for Italian\n",
    "def BM25(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # Score retrieval\n",
    "    if lang == 'it':\n",
    "        bm25_scores = bm25_it.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # Get top-k doc IDs based on raw BM25 scores\n",
    "    top_k_ids = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:top_k]\n",
    "    \n",
    "    return [(i, bm25_scores[i]) for i in top_k_ids] #Returns a list of (document ID, score) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Score for Italian to English\n",
      "\n",
      "7.1452 | womens highrise straight jeans  universal thread\n",
      "6.4611 | womens linen short sleeve buttondown camp shirt  a new day\n",
      "6.4048 | hanes comfort fit scrubs womens scrub pants\n",
      "6.4048 | timberland womens dunstan short sleeve tshirt\n",
      "6.0893 | womens fitted short sleeve tshirt  universal thread\n",
      "\n",
      "\n",
      "BM25 Score for English to Italian\n",
      "\n",
      "5.4298 | ragazze puffer giacca tutto in movimento\n",
      "5.4298 | ragazze solido puffer giacca classe d'arte\n",
      "5.1272 | Bambini39 giacca gonfiabile solida tutto in movimento8482\n",
      "5.1272 | ragazze39 solido giacca trapuntato gatto 38 jack8482\n",
      "5.1272 | wink pro donne snap giacca di riscaldamento anteriore\n"
     ]
    }
   ],
   "source": [
    "#Testing phase for BM25 alone for Italian. This will not be included in the .py model\n",
    "results = BM25(\"giacca da donna\")\n",
    "\n",
    "print(\"BM25 Score for Italian to English\\n\")\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {italian_embeddings['title'][idx]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "#Testing phase for BM25 alone for English. This \n",
    "results = BM25(\"women jacket\")\n",
    "\n",
    "print(\"BM25 Score for English to Italian\\n\")\n",
    "for idx, score in results:\n",
    "    print(f\"{score:.4f} | {italian_embeddings['title_italian'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above the code, we can see that the BM25 is working well for both English and Italian with the scores being relatively high for the top 5 results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below 4 cells display the upsertting of Italian embeddings generated using the BAAI BGE-M3 into the pinecone vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising Pinecone index\n",
    "pc = Pinecone(api_key=CHARRAN_API)\n",
    "index = pc.Index('italian-db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 1746 vectors in batches of 50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [01:39<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying index alignment...\n",
      "âœ… Pinecone index is aligned with BM25 corpus.\n"
     ]
    }
   ],
   "source": [
    "# Enhanced batch upsert function with alignment assertion\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "\n",
    "def batch_upsert(index, vectors, expected_total, batch_size=50):\n",
    "    \"\"\"\n",
    "    Upsert vectors to a Pinecone index in batches and assert alignment after completion.\n",
    "\n",
    "    Parameters:\n",
    "        index: Pinecone Index object\n",
    "        vectors (list): List of dicts in format {\"id\": ..., \"values\": [...]}\n",
    "        expected_total (int): Expected total number of vectors in the index after upload\n",
    "        batch_size (int): Number of vectors per batch (default 50)\n",
    "\n",
    "    Raises:\n",
    "        AssertionError if the final count in Pinecone does not match expected_total\n",
    "    \"\"\"\n",
    "    print(f\"Uploading {len(vectors)} vectors in batches of {batch_size}...\")\n",
    "    for i in tqdm(range(0, len(vectors), batch_size)):\n",
    "        # Upsert a batch of vectors to the Pinecone index\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        index.upsert(vectors=batch)\n",
    "    #verify the alignment of the index with the expected total\n",
    "    # This is done by checking the total number of vectors in the index after upload.\n",
    "    print(\"Verifying index alignment...\")\n",
    "    stats = index.describe_index_stats()\n",
    "    total_vectors = stats.get('total_vector_count', -1)\n",
    "\n",
    "    # Assert that the total number of vectors in Pinecone matches the expected total, which is the sum of English and Italian embeddings obtained from the dataset.\n",
    "    assert total_vectors == expected_total, (\n",
    "        f\"Vector count mismatch: expected {expected_total}, found {total_vectors}\")\n",
    "    print(\"âœ… Pinecone index is aligned with BM25 corpus.\")\n",
    "\n",
    "\n",
    "# Generate aligned IDs for English and Italian embeddings\n",
    "en_ids = [f\"en-{i}\" for i in range(len(italian_embeddings['english_embedding']))]\n",
    "it_ids = [f\"it-{i}\" for i in range(len(italian_embeddings['italian_embedding']))]\n",
    "\n",
    "# Combine vectors for English and Italian embeddings where embeddings are aligned. ZIP function\n",
    "combined_vectors = (\n",
    "    list(zip(en_ids, italian_embeddings['english_embedding'])) +\n",
    "    list(zip(it_ids, italian_embeddings['italian_embedding']))\n",
    ")\n",
    "\n",
    "# Convert to Pinecone format\n",
    "to_upsert = [{\"id\": id, \"values\": vector} for id, vector in combined_vectors]\n",
    "\n",
    "# Total expected = English + Italian\n",
    "expected_total = len(en_ids) + len(it_ids)\n",
    "\n",
    "# Upload and validate\n",
    "batch_upsert(index, to_upsert, expected_total, batch_size=50)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Alignment Verification Utility ----\n",
    "def test_alignment(index, bm25_en, query, top_k=5):\n",
    "    lang = detect(query)\n",
    "    bm25 = bm25_en if lang == \"en\" else bm25_it\n",
    "\n",
    "    # Run Pinecone semantic search\n",
    "    query_vec = model.encode(query).tolist()\n",
    "    results = index.query(vector=query_vec, top_k=top_k, include_metadata=False)\n",
    "\n",
    "    for match in results['matches']:\n",
    "        id_str = match['id']\n",
    "        idx = int(id_str.split('-')[1])\n",
    "        prefix = id_str.split('-')[0]\n",
    "\n",
    "        # Check if BM25 score is accessible\n",
    "        if prefix == \"en\":\n",
    "            try:\n",
    "                score = bm25.get_scores(query.lower().split())[idx]\n",
    "                print(f\"{id_str} â†’ BM25 score: {score:.4f}\")\n",
    "                print(\"BM25 title:\", italian_embeddings['title'][idx])\n",
    "            except IndexError:\n",
    "                print(f\"{id_str} is out of range for BM25\")\n",
    "        else:\n",
    "            print(f\"Skipping {id_str} (non-English match)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en-360 â†’ BM25 score: 0.0000\n",
      "BM25 title: girls puffer jacket  all in motion\n",
      "en-698 â†’ BM25 score: 0.0000\n",
      "BM25 title: wink pro womens snap front warmup jacket\n",
      "en-383 â†’ BM25 score: 0.0000\n",
      "BM25 title: girls39 solid quilted jacket  cat 38 jack8482\n",
      "en-690 â†’ BM25 score: 0.0000\n",
      "BM25 title: girls solid puffer jacket  art class\n",
      "en-59 â†’ BM25 score: 0.0000\n",
      "BM25 title: jockey generation womens organic cotton stretch cropped tshirt\n"
     ]
    }
   ],
   "source": [
    "# Test the alignment function\n",
    "test_alignment(index, bm25_en, query=\"women jacket\", top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Define the prompt function for dynamic alpha calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 Improved prompt for dynamic alpha calculation\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client = OpenAI(api_key=deepseek_API_KEY, base_url=\"https://openrouter.ai/api/v1\")\n",
    "\n",
    "def get_dynamic_alpha(question, dense_result, bm25_result):\n",
    "    system_prompt = \"\"\"You are a multilingual evaluator in an Italian e-commerce site assessing the retrieval effectiveness of dense\n",
    "retrieval (Cosine Distance) and BM25 retrieval for finding the correct Italian product title given an English-language query.\n",
    "\n",
    "## Task:\n",
    "Given a query and two top-1 search results (one from dense retrieval, one from BM25 retrieval), score each method from **0 to 5** based on how likely the correct result is retrieved or nearby.\n",
    "\n",
    "### Scoring Criteria:\n",
    "1. **Direct hit â†’ 5 points**\n",
    "   - If the retrieved result directly answers the question.\n",
    "2. **Good wrong result â†’ 3-4 points**\n",
    "   - Answer is not exact, but closely related; likely the correct one is nearby.\n",
    "3. **Bad wrong result â†’ 1-2 points**\n",
    "   - Loosely related or general, unlikely correct answer is nearby.\n",
    "4. **Completely off-track â†’ 0 points**\n",
    "   - Retrieval is unrelated.\n",
    "\n",
    "### Output Format:\n",
    "Return two integers separated by a space:\n",
    "- First number: dense retrieval score.\n",
    "- Second number: BM25 retrieval score.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"### Given Data:\n",
    "- Question: \"{question}\"\n",
    "- dense retrieval Top1 Result: \"{dense_result}\"\n",
    "- BM25 retrieval Top1 Result: \"{bm25_result}\"\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    # response.choices[0] means the first choice of the model's response .message.content is the actual content of the response.\n",
    "    # .strip() removes any leading or trailing whitespace from the response.\n",
    "    output = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        #The mapping function below does is that it splits the output string into two parts based on whitespace and converts them to integers and assigns them to dense_score and bm25_score respectively.\n",
    "        dense_score, bm25_score = map(int, output.split())\n",
    "    except:\n",
    "        dense_score = bm25_score = 3  # fallback if parsing fails\n",
    "\n",
    "    # The following conditions are used to determine the final score based on the dense and BM25 scores.\n",
    "    if dense_score == 5 and bm25_score != 5:\n",
    "        return 1.0\n",
    "    elif bm25_score == 5 and dense_score != 5:\n",
    "        return 0.0\n",
    "    elif dense_score == 0 and bm25_score == 0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return dense_score / (dense_score + bm25_score) # This is returned to the hybrid_search function to be used as the alpha value for the hybrid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old Step 1\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client = OpenAI(api_key=\"deepseek_API_KEY\", base_url=\"https://openrouter.ai/api/v1\")\n",
    "\n",
    "def get_dynamic_alpha(question, dense_result, bm25_result):\n",
    "    prompt = f\"\"\"You are a multilingual evaluator in a italian ecommerce site assessing the retrieval effectiveness of dense\n",
    "retrieval (Cosine Distance) and BM25 retrieval for finding the correct italian product title with respect to the english query. \n",
    "\n",
    "## Task:\n",
    "Given a question and two top1 search results (one from dense retrieval,\n",
    "one from BM25 retrieval), score each retrieval method from **0 to 5** based on whether the correct answer is likely to appear in top2, top3, etc.\n",
    "\n",
    "### **Scoring Criteria:**\n",
    "1. **Direct hit --> 5 points**\n",
    "- If the retrieved document directly answers the question, assign **5 points**.\n",
    "2. **Good wrong result (High likelihood correct answer is nearby) --> 3-4 points**\n",
    "3. **Bad wrong result (Low likelihood correct answer is nearby) --> 1-2 points**\n",
    "4. **Completely off-track --> 0 points**\n",
    "\n",
    "### **Given Data:**\n",
    "- **Question:** \"{question}\"\n",
    "\n",
    "- **dense retrieval Top1 Result:** \"{dense_result}\"\n",
    "- **BM25 retrieval Top1 Result:** \"{bm25_result}\"\n",
    "\n",
    "### **Output Format:**\n",
    "Return two integers separated by a space:\n",
    "- **First number:** dense retrieval score.\n",
    "- **Second number:** BM25 retrieval score.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-chat-v3-0324:free\",  \n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        dense_score, bm25_score = map(int, output.split())\n",
    "    except:\n",
    "        dense_score = bm25_score = 3  # default fallback\n",
    "\n",
    "    if dense_score == 5 and bm25_score != 5:\n",
    "        return 1.0\n",
    "    elif bm25_score == 5 and dense_score != 5:\n",
    "        return 0.0\n",
    "    elif dense_score == 0 and bm25_score == 0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return dense_score / (dense_score + bm25_score) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Define the new hybrid search function by taking only the top 1 or 2 result from each type of search retrieval and pass it to the prompt function in step 2 to return the score.\n",
    "\n",
    "The hybrid search function will hen use the scores from the prompting function to compute a dynamic alpha parameter which is then passed into the normalised scores of dense and spare retrievals obtained earlier and eventually sorting the scores and outputting the top 5 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Main hybrid retrieval with dynamic alpha by getting top 2 from both BM25 and Pinecone\n",
    "def hybrid_search_dat(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # --- BM25 Search ---\n",
    "    if lang == 'it':\n",
    "        bm25_scores = bm25_it.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # --- Semantic Search (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist() #Encoding the query using the BGE-M3 sentence transformer model to obtain a vector representation of the query.\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k, include_metadata=False) #Querying the Pinecone index for the top-k results based on the query vector.\n",
    "\n",
    "    # Parse Pinecone results\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']]    #Extracting the IDs from the Pinecone results.\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']]     #Extracting the IDs and scores from the Pinecone results.\n",
    "\n",
    "    # Get top-2 text from both for alpha calculation\n",
    "    bm25_top_2_idx = np.argsort(bm25_scores)[-2:][::-1]  #  Obtaining the top 2 indices of the BM25 scores using numpy argsort function.\n",
    "    dense_top_2_idx = pinecone_ids[:2] #obtaining the top 2 indices of the dense scores from the Pinecone results.\n",
    "    bm25_text = \" || \".join(df_embeddings['title'][i] for i in bm25_top_2_idx) #Joining the titles of the top 2 BM25 scores with \" || \" as a separator.\n",
    "    dense_text = \" || \".join(df_embeddings['title'][i] for i in dense_top_2_idx) #Joining the titles of the top 2 dense scores with \" || \" as a separator.\n",
    "\n",
    "    # --- Get dynamic alpha from GPT ---\n",
    "    start = time.time() #this was added for debugging process to see how long the alpha fetching takes.\n",
    "    alpha = get_dynamic_alpha(query, dense_text, bm25_text)\n",
    "    print(f\"Alpha fetched: {alpha} in {time.time() - start:.2f}s\")\n",
    "\n",
    "    # --- Normalize Scores ---\n",
    "    scaler = MinMaxScaler()\n",
    "    bm25_norm = scaler.fit_transform(np.array(bm25_scores).reshape(-1, 1)).flatten() # Normalizing the BM25 scores using MinMaxScaler to scale the scores between 0 and 1 and reshape the array to be 2D for the scaler and flatten it back to 1D.\n",
    "    pinecone_norm = scaler.fit_transform(np.array(pinecone_scores).reshape(-1, 1)).flatten()  # Normalize Pinecone semantic scores similarly as above\n",
    "\n",
    "    # --- Combine scores using dynamic alpha ---\n",
    "    hybrid_results = []\n",
    "    for idx, semantic_score in zip(pinecone_ids, pinecone_norm):\n",
    "        final_score = alpha * semantic_score + (1 - alpha) * bm25_norm[idx] ## Compute weighted score using alpha (higher alpha â†’ more reliance on semantic)\n",
    "        hybrid_results.append((idx, final_score)) # Append the index and final score to the hybrid_results list.\n",
    "\n",
    "    # Sort by hybrid score\n",
    "    hybrid_results.sort(key=lambda x: x[1], reverse=True) ## Sort the hybrid results based on the final score in descending order.\n",
    "\n",
    "    # --- Prepare detailed results ---\n",
    "    detailed_results = []\n",
    "    for idx, hybrid_score in hybrid_results[:top_k]:\n",
    "        bm25_score = round(bm25_norm[idx], 4)\n",
    "        semantic_score = round(pinecone_norm[pinecone_ids.index(idx)], 4)\n",
    "        detailed_results.append((idx, round(hybrid_score, 4), bm25_score, semantic_score))\n",
    "\n",
    "    return detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Main hybrid retrieval with dynamic alpha by getting top 1 from both BM25 and Pinecone (From research paper)\n",
    "def hybrid_search_dat(query, top_k=5):\n",
    "    lang = detect(query)\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # --- BM25 Search ---\n",
    "    if lang == 'it':\n",
    "        bm25_scores = bm25_it.get_scores(tokens)\n",
    "    else:\n",
    "        bm25_scores = bm25_en.get_scores(tokens)\n",
    "\n",
    "    # --- Semantic Search (Pinecone) ---\n",
    "    query_vec = model.encode(query).tolist()\n",
    "    pinecone_results = index.query(vector=query_vec, top_k=top_k, include_metadata=False) ## Submit the dense vector to Pinecone and retrieve the top-k most similar indexed vectors\n",
    "\n",
    "    # Parse Pinecone results\n",
    "    pinecone_ids = [int(match['id'].split('-')[1]) for match in pinecone_results['matches']] #Extracting the IDs from the Pinecone results using match['id'] and splitting it to get the index of the document.\n",
    "    pinecone_scores = [match['score'] for match in pinecone_results['matches']] #Extracting the scores from the Pinecone results using match['score'] and storing them in a list.\n",
    "\n",
    "    # Get top-1 text from both for alpha calculation\n",
    "    bm25_top_idx = int(np.argmax(bm25_scores)) #obtaining the index of the top 1 BM25 score using numpy argmax function.\n",
    "    dense_top_idx = pinecone_ids[0] #obtaining the index of the top 1 dense score from the Pinecone results using the first element of the pinecone_ids list.\n",
    "    bm25_text = italian_embeddings['title'][bm25_top_idx]\n",
    "    dense_text = italian_embeddings['title'][dense_top_idx]\n",
    "\n",
    "    # --- Get dynamic alpha from GPT ---\n",
    "    start = time.time()\n",
    "    alpha = get_dynamic_alpha(query, dense_text, bm25_text)\n",
    "    print(f\"Alpha fetched: {alpha} in {time.time() - start:.2f}s\")\n",
    "\n",
    "    # --- Normalize Scores ---\n",
    "    scaler = MinMaxScaler()\n",
    "    bm25_norm = scaler.fit_transform(np.array(bm25_scores).reshape(-1, 1)).flatten() \n",
    "    pinecone_norm = scaler.fit_transform(np.array(pinecone_scores).reshape(-1, 1)).flatten()\n",
    "\n",
    "    # --- Combine scores using dynamic alpha ---\n",
    "    hybrid_results = []\n",
    "    for idx, semantic_score in zip(pinecone_ids, pinecone_norm):\n",
    "        final_score = alpha * semantic_score + (1 - alpha) * bm25_norm[idx]\n",
    "        hybrid_results.append((idx, final_score))\n",
    "\n",
    "    # Sort by hybrid score\n",
    "    hybrid_results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # --- Prepare detailed results ---\n",
    "    detailed_results = []\n",
    "    for idx, hybrid_score in hybrid_results[:top_k]:\n",
    "        bm25_score = round(bm25_norm[idx], 4)\n",
    "        semantic_score = round(pinecone_norm[pinecone_ids.index(idx)], 4)\n",
    "        detailed_results.append((idx, round(hybrid_score, 4), bm25_score, semantic_score))\n",
    "\n",
    "    return detailed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Results & conclusion section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 6.92s\n",
      "0.5000 | 0.0000 | 1.0000 | bluey bingo graphic tshirt toddler \n",
      "0.4447 | 0.5894 | 0.3000 | boys power rangers blue ranger costume tee tshirt\n",
      "0.2433 | 0.4867 | 0.0000 | toddler boys toy story friend in me short sleeve graphic tshirt  blue\n",
      "0.2014 | 0.0000 | 1.0000 | bluey bingo graphic tshirt toddler \n",
      "0.1844 | 0.0000 | 0.3687 | boys jaws shark blueprint tshirt\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"I want a blue shirt\")\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    print(f\"{hybrid:.4f} | {bm25:.4f} | {semantic:.4f} | {italian_embeddings['title'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 17.54s\n",
      "0.9248 | 0.8496 | 1.0000 | Donne donne 6 in pelle pizzo stivale ponte caviglia\n",
      "0.9248 | 0.8496 | 1.0000 | Donne donne 6 in pelle pizzo stivale ponte caviglia\n",
      "0.5000 | 1.0000 | 0.0000 | lo zaino in pelle sak womens loyola\n",
      "0.2279 | 0.0000 | 0.4559 | womens leopard print highrise leggings joylab\n",
      "0.2279 | 0.0000 | 0.4559 | womens leopard print highrise leggings joylab\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"Woman leather jacket\")\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    print(f\"{hybrid:.4f} | {bm25:.4f} | {semantic:.4f} | {italian_embeddings['title_italian'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 8.08s\n",
      "{'title_italian': 'samsung qn90d 50 4k neo qled smart tv 2024', 'hybrid_score': 0.5, 'bm25_score': 0.0, 'semantic_score': 1.0}\n",
      "{'title_italian': 'uomo neve bianco e i sette nani xmas heigh ho tshirt', 'hybrid_score': 0.4605, 'bm25_score': 0.5608, 'semantic_score': 0.3603}\n",
      "{'title_italian': 'mens rocky sport utility 600g isolato impermeabile stivale', 'hybrid_score': 0.2546, 'bm25_score': 0.0, 'semantic_score': 0.5092}\n",
      "{'title_italian': 'mens rocky sport utility 600g isolato impermeabile stivale', 'hybrid_score': 0.1801, 'bm25_score': 0.0, 'semantic_score': 0.5092}\n",
      "{'title_italian': 'ragazzi lilo punto rosso e blu gamer tshirt', 'hybrid_score': 0.0, 'bm25_score': 0.0, 'semantic_score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"Men white shirt\")\n",
    "\n",
    "output = []\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    result_entry = {\n",
    "        \"title_italian\": df_embeddings['title_italian'][idx],\n",
    "        \"hybrid_score\": round(hybrid, 4),\n",
    "        \"bm25_score\": round(bm25, 4),\n",
    "        \"semantic_score\": round(semantic, 4)\n",
    "    }\n",
    "    output.append(result_entry)\n",
    "\n",
    "# Print the list nicely\n",
    "for item in output:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 8.80s\n",
      "{'title_italian': 'batman ninja nero ninja camminare uomo bianco manica lunga camicia', 'hybrid_score': 0.9761, 'bm25_score': 0.9523, 'semantic_score': 1.0}\n",
      "{'title_italian': 'uomo neve bianco e i sette nani xmas heigh ho tshirt', 'hybrid_score': 0.5372, 'bm25_score': 0.5498, 'semantic_score': 0.5246}\n",
      "{'title_italian': 'uomo neve bianco e i sette nani xmas heigh ho tshirt', 'hybrid_score': 0.4651, 'bm25_score': 0.5498, 'semantic_score': 0.5246}\n",
      "{'title_italian': 'mens slim fit girocollo tshirt 3pk dealworthy bianco', 'hybrid_score': 0.3341, 'bm25_score': 0.6368, 'semantic_score': 0.0314}\n",
      "{'title_italian': 'mens marvel spiderman maniche corte tshirt grafica bianco', 'hybrid_score': 0.3184, 'bm25_score': 0.6368, 'semantic_score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"Men white shirt\")\n",
    "\n",
    "output = []\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    result_entry = {\n",
    "        \"title_italian\": italian_embeddings['title_italian'][idx],\n",
    "        \"hybrid_score\": round(hybrid, 4),\n",
    "        \"bm25_score\": round(bm25, 4),\n",
    "        \"semantic_score\": round(semantic, 4)\n",
    "    }\n",
    "    output.append(result_entry)\n",
    "\n",
    "# Print the list nicely\n",
    "for item in output:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "top_idx = results[0][0]  # index of top-1 result\n",
    "\n",
    "reference_query = \"Woman leather jacket\"\n",
    "predicted_title = italian_embeddings['title_italian'][top_idx]\n",
    "\n",
    "# Tokenize both properly\n",
    "reference_tokens = word_tokenize(reference_query)\n",
    "predicted_tokens = word_tokenize(predicted_title)\n",
    "\n",
    "# Pass the reference as a *list of references* (each is token list)\n",
    "meteor = meteor_score([reference_tokens], predicted_tokens)\n",
    "\n",
    "print(f\"METEOR Score: {meteor:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore-F1: 0.6655\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Inputs\n",
    "reference_query = \"Woman leather jacket\"\n",
    "predicted_title = italian_embeddings['title_italian'][top_idx]\n",
    "\n",
    "# BERTScore evaluation\n",
    "P, R, F1 = score([predicted_title], [reference_query], lang=\"multilingual\", verbose=False)\n",
    "\n",
    "print(f\"BERTScore-F1: {F1[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 7.81s\n",
      "{'title_italian': 'ragazze puffer giacca tutto in movimento', 'hybrid_score': 1.0, 'bm25_score': 1.0, 'semantic_score': 1.0}\n",
      "{'title_italian': 'wink pro donne snap giacca di riscaldamento anteriore', 'hybrid_score': 0.9293, 'bm25_score': 0.9443, 'semantic_score': 0.9144}\n",
      "{'title_italian': 'donne slim fit drappeggio avvolgere tshirt un nuovo giorno', 'hybrid_score': 0.4204, 'bm25_score': 0.0, 'semantic_score': 0.8408}\n",
      "{'title_italian': 'Donne donne 6 in pelle pizzo stivale ponte caviglia', 'hybrid_score': 0.0, 'bm25_score': 0.0, 'semantic_score': 0.0}\n",
      "{'title_italian': 'Donne donne 6 in pelle pizzo stivale ponte caviglia', 'hybrid_score': 0.0, 'bm25_score': 0.0, 'semantic_score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"Women denim jacket\")\n",
    "\n",
    "output = []\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    result_entry = {\n",
    "        \"title_italian\": italian_embeddings['title_italian'][idx],\n",
    "        \"hybrid_score\": round(hybrid, 4),\n",
    "        \"bm25_score\": round(bm25, 4),\n",
    "        \"semantic_score\": round(semantic, 4)\n",
    "    }\n",
    "    output.append(result_entry)\n",
    "\n",
    "# Print the list nicely\n",
    "for item in output:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha fetched: 0.5 in 5.72s\n",
      "{'title_italian': 'ragazze puffer giacca tutto in movimento', 'hybrid_score': 1.0, 'bm25_score': 1.0, 'semantic_score': 1.0}\n",
      "{'title_italian': 'wink pro donne snap giacca di riscaldamento anteriore', 'hybrid_score': 0.9293, 'bm25_score': 0.9443, 'semantic_score': 0.9144}\n",
      "{'title_italian': 'donne slim fit drappeggio avvolgere tshirt un nuovo giorno', 'hybrid_score': 0.4204, 'bm25_score': 0.0, 'semantic_score': 0.8408}\n",
      "{'title_italian': 'Donne donne 6 in pelle pizzo stivale ponte caviglia', 'hybrid_score': 0.0, 'bm25_score': 0.0, 'semantic_score': 0.0}\n",
      "{'title_italian': 'Donne donne 6 in pelle pizzo stivale ponte caviglia', 'hybrid_score': 0.0, 'bm25_score': 0.0, 'semantic_score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "results = hybrid_search_dat(\"Women denim jacket\")\n",
    "#with improved prompting & Top 2 search\n",
    "output = []\n",
    "\n",
    "for idx, hybrid, bm25, semantic in results:\n",
    "    result_entry = {\n",
    "        \"title_italian\": italian_embeddings['title_italian'][idx],\n",
    "        \"hybrid_score\": round(hybrid, 4),\n",
    "        \"bm25_score\": round(bm25, 4),\n",
    "        \"semantic_score\": round(semantic, 4)\n",
    "    }\n",
    "    output.append(result_entry)\n",
    "\n",
    "# Print the list nicely\n",
    "for item in output:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the impact of hybrid scores on the datasets and the varied weightage of sparse and dense retrieval for each query supports our exploration of the need to have dynamic weightage on the BM25 and the semantic scores obtained from pinecone, as certain queries might lead to the more direct keyword based search whereas certain vague queries might need semantics to help achieve the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (PyTorch CUDA)",
   "language": "python",
   "name": "pytorch_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
